<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王子泰</title>
  
  <subtitle>哭也欢乐，悲也潇洒</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wang22ti.com/"/>
  <updated>2019-01-29T04:49:35.000Z</updated>
  <id>http://wang22ti.com/</id>
  
  <author>
    <name>wang22ti</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在Ubuntu上用VSCode配置Texlive</title>
    <link href="http://wang22ti.com/2019/01/29/%E5%9C%A8Ubuntu%E4%B8%8A%E7%94%A8VSCode%E9%85%8D%E7%BD%AETexlive/"/>
    <id>http://wang22ti.com/2019/01/29/在Ubuntu上用VSCode配置Texlive/</id>
    <published>2019-01-29T10:59:01.000Z</published>
    <updated>2019-01-29T04:49:35.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>安装和配置见博文<a href="https://blog.csdn.net/engreal/article/details/80704755" target="_blank" rel="noopener">Ubuntu下 TeX Live 2018 的安装与配置</a>和<a href="https://www.jianshu.com/p/63a6873cc6a9" target="_blank" rel="noopener">Latex编辑器-TexLive-Ubuntu16.04安装指南</a>中环境变量的配置，需要注意一下TexLive的版本修改对应的文件夹</li><li>配置VSCode插件见博文<a href="https://www.jianshu.com/p/47c456572e87" target="_blank" rel="noopener">(1)Win10+TeXLive2018+VSCode+LaTexWorkshop+支持中文</a></li></ol><p>不过为了显示我不是复读机，需要指出第2布中<code>latex-workshop.latex.clean.fileTypes</code>下面的<code>&quot;*.gz&quot;</code>最好不要删去，因为这是latex源码和pdf文件之间映射关系的文件，保留它可以通过<code>Ctrl+Alt+J</code>从源码跳转到pdf对应位置，通过<code>Ctrl+左击</code>从pdf跳转到源码，十分方便。此外，<code>latex-workshop.latex.recipes</code>下面指明了默认的编译顺序，基本只用到前两个。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;安装和配置见博文&lt;a href=&quot;https://blog.csdn.net/engreal/article/details/80704755&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Ubuntu下 TeX Live 2018 的安装与配
      
    
    </summary>
    
      <category term="latex" scheme="http://wang22ti.com/categories/latex/"/>
    
    
  </entry>
  
  <entry>
    <title>解决Ubuntu根目录空间不足的方法</title>
    <link href="http://wang22ti.com/2019/01/29/%E8%A7%A3%E5%86%B3Ubuntu%E6%A0%B9%E7%9B%AE%E5%BD%95%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://wang22ti.com/2019/01/29/解决Ubuntu根目录空间不足的方法/</id>
    <published>2019-01-29T09:48:10.000Z</published>
    <updated>2019-01-29T02:48:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>装系统的时候图省事，就用了默认的分区设置，结果安装了一个texlive，才十几个G就通知根目录的空间不足啦，新建文件不给，重启后连图形界面都进不去，，， 正以为要重装系统呢，结果发现还是有很好的解决方案的：</p><ol><li>执行<code>sudo apt-get install gparted</code>安装硬盘分区管理器，并执行<code>sudo gparted</code>打开软件</li><li>调整<code>\home</code>分区的大小，比如压缩100G，可以看到在最后有100G分区没有分配</li><li>挨个把根目录<code>\</code>后分区拖动到最后，即把未分配区间移动到根目录的后面</li><li>调整根目录大小，将未分配空间分配给它</li><li>点击绿色的<code>√</code>确定操作</li></ol><p>嗯，就如此简单！事实证明，在Linux上跑对内存要求比较高的程序的时候，是需要更大一些的<code>swap</code>空间的，我用的是3T的机械硬盘，机器的内存是32G，这是最后的分区：</p><ol><li>默认的<code>\boot</code>分区，大概1G</li><li>根目录<code>\</code>分区，200多G</li><li>交换<code>\swap</code>分区，150多G</li><li>主分区，剩下的都是</li></ol><p>程序快多了！</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://blog.csdn.net/Lo_Bamboo/article/details/79443599" target="_blank" rel="noopener">ubantu利用GParted分区编辑器调整根目录分区大小</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;装系统的时候图省事，就用了默认的分区设置，结果安装了一个texlive，才十几个G就通知根目录的空间不足啦，新建文件不给，重启后连图形界面都进不去，，， 正以为要重装系统呢，结果发现还是有很好的解决方案的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行&lt;code&gt;sudo apt-get
      
    
    </summary>
    
      <category term="linux" scheme="http://wang22ti.com/categories/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>Github提交100M以上的大文件</title>
    <link href="http://wang22ti.com/2019/01/29/Github%E6%8F%90%E4%BA%A4100M%E4%BB%A5%E4%B8%8A%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6/"/>
    <id>http://wang22ti.com/2019/01/29/Github提交100M以上的大文件/</id>
    <published>2019-01-29T09:32:58.000Z</published>
    <updated>2019-01-29T01:47:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>喜大普奔，喜大普奔，GitHub于2019年1月8日宣布私有仓库免费了！这意味着几乎可以把GitHub当作云盘来用了啊！但是当我试图提交生成的数据集的时候，报了单个文件大小限制的错误。还好，有官方的解决方案：</p><ol><li>根据指导<a href="https://github.com/git-lfs/git-lfs/wiki/Installation" target="_blank" rel="noopener">安装git-lfs</a></li><li>执行指令</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find ./ -size +100M | xargs git lfs track</span><br></pre></td></tr></table></figure><p>之后就和正常提交完全一致了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add *</span><br><span class="line">git commit -m <span class="string">"this is a test"</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/qq_35842626/article/details/80014325" target="_blank" rel="noopener">解决git上传单个大文件的限制，亲测有效！</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;喜大普奔，喜大普奔，GitHub于2019年1月8日宣布私有仓库免费了！这意味着几乎可以把GitHub当作云盘来用了啊！但是当我试图提交生成的数据集的时候，报了单个文件大小限制的错误。还好，有官方的解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据指导&lt;a href=&quot;https:
      
    
    </summary>
    
      <category term="git" scheme="http://wang22ti.com/categories/git/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-latex-4-幻灯片演示</title>
    <link href="http://wang22ti.com/2019/01/14/%E7%AC%94%E8%AE%B0-latex-4-%E5%B9%BB%E7%81%AF%E7%89%87%E6%BC%94%E7%A4%BA/"/>
    <id>http://wang22ti.com/2019/01/14/笔记-latex-4-幻灯片演示/</id>
    <published>2019-01-14T06:47:14.000Z</published>
    <updated>2019-01-14T09:44:47.738Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;beamer&#125;</span><br><span class="line">\usepackage[UTF8, noindent]&#123;ctexcap&#125;</span><br><span class="line"></span><br><span class="line">\title&#123;杂谈勾股定理&#125;</span><br><span class="line">\subtitle&#123;数学史讲座之一&#125;</span><br><span class="line">\author&#123;张三&#125;</span><br><span class="line">\institute&#123;九章算术&#125;</span><br><span class="line">\date&#123;\today&#125;</span><br><span class="line"></span><br><span class="line">\usetheme&#123;PaloAlto&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;frame&#125;</span><br><span class="line">\titlepage</span><br><span class="line">\end&#123;frame&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;frame&#125;&#123;古中国数学&#125;&#123;勾股定理的发现&#125;</span><br><span class="line"></span><br><span class="line">中国在3000多年之前就知道勾股数的概念，比古希腊更早一些。</span><br><span class="line">《一本书》记载：</span><br><span class="line">\begin&#123;itemize&#125;[&lt;+-&gt;]</span><br><span class="line">\item 公元前11世纪，有人说：</span><br><span class="line">\item 还有人说</span><br><span class="line">\begin&#123;quote&#125;</span><br><span class="line">勾三，股四，径五</span><br><span class="line">\end&#123;quote&#125;</span><br><span class="line">\item 又记载了另一个更一般的形式</span><br><span class="line">\begin&#123;quote&#125;</span><br><span class="line">勾三，股四，径五</span><br><span class="line">\end&#123;quote&#125;</span><br><span class="line">\end&#123;itemize&#125;</span><br><span class="line"></span><br><span class="line">\end&#123;frame&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><p><img src="/2019/01/14/笔记-latex-4-幻灯片演示/1.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
      <category term="latex" scheme="http://wang22ti.com/categories/latex/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-latex-3-表格</title>
    <link href="http://wang22ti.com/2019/01/14/%E7%AC%94%E8%AE%B0-latex-3-%E8%A1%A8%E6%A0%BC/"/>
    <id>http://wang22ti.com/2019/01/14/笔记-latex-3-表格/</id>
    <published>2019-01-14T06:46:49.000Z</published>
    <updated>2019-01-14T09:19:29.690Z</updated>
    
    <content type="html"><![CDATA[<h1 id="带有注释的三线表"><a href="#带有注释的三线表" class="headerlink" title="带有注释的三线表"></a>带有注释的三线表</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;paper&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\usepackage&#123;geometry&#125;</span><br><span class="line">\usepackage&#123;booktabs&#125;</span><br><span class="line">\usepackage&#123;color&#125;</span><br><span class="line">\usepackage[labelfont=rm,textfont=rm]&#123;caption&#125;</span><br><span class="line">\geometry&#123;a4paper, centering , scale=0.8&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;table&#125;[]</span><br><span class="line">\setlength&#123;\abovecaptionskip&#125;&#123;0.cm&#125;</span><br><span class="line">\setlength&#123;\belowcaptionskip&#125;&#123;-0.cm&#125;</span><br><span class="line">\center</span><br><span class="line">\caption&#123;Results of NCF(Movielens, Factor=8)&#125;</span><br><span class="line">\begin&#123;tabular&#125;&#123;|c|c|c|c|c|c|c|c|c|&#125;</span><br><span class="line">\hline </span><br><span class="line">&amp; \multicolumn&#123;2&#125;&#123;c|&#125;&#123;NeuMF(pre-training)&#125; &amp; \multicolumn&#123;2&#125;&#123;c|&#125;&#123;NeuMF&#125; &amp; \multicolumn&#123;2&#125;&#123;c|&#125;&#123;MLP&#125; &amp; \multicolumn&#123;2&#125;&#123;c|&#125;&#123;GMF&#125; \\ </span><br><span class="line">\cline&#123;2-9&#125;</span><br><span class="line">&amp; HR@10 &amp; NDCG@10 &amp; HR@10 &amp; NDCG@10 &amp; HR@10 &amp; NDCG@10 &amp; HR@10 &amp; NDCG@10\\ </span><br><span class="line">\hline\hline</span><br><span class="line">NCF &amp; &#123;\color&#123;red&#125;0.684&#125; &amp; &#123;\color&#123;red&#125;0.403&#125; &amp; 0.688 &amp; &#123;\color&#123;red&#125;0.410&#125; &amp; &#123;\color&#123;red&#125;0.678&#125; &amp; &#123;\color&#123;red&#125;0.406&#125; &amp; null &amp; null \\</span><br><span class="line">\hline</span><br><span class="line">Recurrent &amp; 0.673 &amp; 0.400 &amp; 0.688 &amp; 0.409 &amp; 0.677 &amp; 0.402 &amp; 0.641 &amp; 0.372\\</span><br><span class="line">\hline</span><br><span class="line">\end&#123;tabular&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure><p><img src="/2019/01/14/笔记-latex-3-表格/1.png" alt=""></p><h1 id="用于多模型、多指标、多参数的表"><a href="#用于多模型、多指标、多参数的表" class="headerlink" title="用于多模型、多指标、多参数的表"></a>用于多模型、多指标、多参数的表</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\usepackage&#123;geometry&#125;</span><br><span class="line">\usepackage&#123;booktabs&#125;</span><br><span class="line">\usepackage&#123;color&#125;</span><br><span class="line">\usepackage[labelfont=rm,textfont=rm]&#123;caption&#125;</span><br><span class="line">\geometry&#123;a4paper, centering , scale=0.8&#125;</span><br><span class="line">\usepackage&#123;threeparttable&#125;</span><br><span class="line">\usepackage&#123;array&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\begin&#123;table&#125;[]</span><br><span class="line">\setlength&#123;\abovecaptionskip&#125;&#123;0.cm&#125;</span><br><span class="line">\setlength&#123;\belowcaptionskip&#125;&#123;-0.cm&#125;</span><br><span class="line">\center</span><br><span class="line">\caption&#123;Experiment results&#125;</span><br><span class="line">\begin&#123;threeparttable&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;tabular*&#125;&#123;400pt&#125;&#123;@&#123;\extracolsep&#123;\fill&#125;&#125;cccc&#125;</span><br><span class="line">\toprule &amp; HR@10    &amp; P@10    &amp; NDCG@10\\</span><br><span class="line">\midrule </span><br><span class="line">\multicolumn&#123;1&#125;&#123;c&#125;&#123;NCF(origin)&#125; &amp; 0.1 &amp; 0.1 &amp; 0.1 \\</span><br><span class="line">\multicolumn&#123;1&#125;&#123;c&#125;&#123;NCF(modified)&#125; &amp; 0.1 &amp; 0.1 &amp; 0.1 \\</span><br><span class="line">\multicolumn&#123;1&#125;&#123;c&#125;&#123;ICML&#125;    &amp; 0.1 &amp; 0.1 &amp; &#123;\color&#123;red&#125;0.2&#125; \\</span><br><span class="line">\bottomrule</span><br><span class="line">\end&#123;tabular*&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;tablenotes&#125;</span><br><span class="line">\item[1] test.</span><br><span class="line">\item[2] test. </span><br><span class="line">\end&#123;tablenotes&#125;</span><br><span class="line"></span><br><span class="line">\end&#123;threeparttable&#125;</span><br><span class="line">\end&#123;table&#125;</span><br></pre></td></tr></table></figure><p><img src="/2019/01/14/笔记-latex-3-表格/2.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;带有注释的三线表&quot;&gt;&lt;a href=&quot;#带有注释的三线表&quot; class=&quot;headerlink&quot; title=&quot;带有注释的三线表&quot;&gt;&lt;/a&gt;带有注释的三线表&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
      <category term="latex" scheme="http://wang22ti.com/categories/latex/"/>
    
    
  </entry>
  
  <entry>
    <title>在校外通过VPN使用微软远程桌面连接校内主机的方法</title>
    <link href="http://wang22ti.com/2018/12/09/%E5%9C%A8%E6%A0%A1%E5%A4%96%E9%80%9A%E8%BF%87VPN%E4%BD%BF%E7%94%A8%E5%BE%AE%E8%BD%AF%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E8%BF%9E%E6%8E%A5%E6%A0%A1%E5%86%85%E4%B8%BB%E6%9C%BA%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://wang22ti.com/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/</id>
    <published>2018-12-08T17:29:04.000Z</published>
    <updated>2018-12-10T09:57:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>以后都在所里干活，暂时没有分配台式机，宿舍的又不方便带过去（主要是不方便再带出来），所以折腾了一圈，终于大致搞定了。</p><h1 id="申请校内ip地址"><a href="#申请校内ip地址" class="headerlink" title="申请校内ip地址"></a>申请校内ip地址</h1><p>设置远程桌面的前提条件是有固定的ip址，公网的ip地址要花钱，所以需要申请一个学校的ip地址，详见<a href="http://cnms.bjtu.edu.cn/network/dormnetwork/" target="_blank" rel="noopener">申请页面</a>。然后再这个校内IP的端口上插上路由器，开启宿舍的无线网。</p><h1 id="配置路由器转发"><a href="#配置路由器转发" class="headerlink" title="配置路由器转发"></a>配置路由器转发</h1><p>这时候路由器的IP是固定的，但是在局域网中台式机的IP并不是固定的，所以要配置路由器，将局域网地址和设备绑定。我用的是小米路由器，所以要进入<a href="http://miwifi.com/cgi-bin/luci/web" target="_blank" rel="noopener">配置页面</a>，绑定DHCP静态IP，这样在局域网中分配给台式机的IP就是固定的了。</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/1.png" alt=""></p><h1 id="设置Windows10远程桌面连接"><a href="#设置Windows10远程桌面连接" class="headerlink" title="设置Windows10远程桌面连接"></a>设置Windows10远程桌面连接</h1><p>首先Windows10自带的远程桌面只有在<code>专业版</code>中才能开启（淘宝上有专业版的激活码，15元一个）。</p><p>将台式机升级到专业版后在<code>设置-显示-远程桌面</code>中开启即可，如下图所示。</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/2.png" alt=""></p><h1 id="设置远程桌面客户端"><a href="#设置远程桌面客户端" class="headerlink" title="设置远程桌面客户端"></a>设置远程桌面客户端</h1><p>现在已经可以在校内任意位置连接台式机了，首先查看路由器的IP地址，还是以小米路由器为例：</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/3.png" alt=""></p><h2 id="笔记本"><a href="#笔记本" class="headerlink" title="笔记本"></a>笔记本</h2><p>先在Windows应用商店中下载微软提供的<a href="https://www.microsoft.com/zh-cn/p/microsoft-%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/9wzdncrfj3ps?SilentAuth=1&amp;rtc=1" target="_blank" rel="noopener">远程桌面客户端</a>，然后在<code>添加-桌面</code>中进行如下的配置，自其中计算机名称就是上面的IP地址，用户账户是在台式机上设置允许登陆的微软账号。</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/4.png" alt=""></p><h2 id="安卓手机"><a href="#安卓手机" class="headerlink" title="安卓手机"></a>安卓手机</h2><p>先在Google play上下载微软提供的<a href="https://play.google.com/store/apps/details?id=com.microsoft.rdc.android" target="_blank" rel="noopener">远程桌面客户端</a>，配置过程和笔记本上完全相同，不赘述。</p><h1 id="配置客户端VPN"><a href="#配置客户端VPN" class="headerlink" title="配置客户端VPN"></a>配置客户端VPN</h1><p>在上述配置后，仍然不能用校外网访问远程桌面，因为学校给分配的IP地址仍然不是公网IP，所以要配置学校的VPN。这是学校VPN的<a href="https://www.bjtu.edu.cn/pub/gxnjs/vpn/index.htm" target="_blank" rel="noopener">教程</a>，注意的是，要使用的服务器是<code>libvpn.bjtu.edu.cn</code>。</p><h2 id="笔记本-1"><a href="#笔记本-1" class="headerlink" title="笔记本"></a>笔记本</h2><p>学校官方的教程并不管用，还好<a href="https://zhixing.bjtu.edu.cn/forum.php?mod=viewthread&amp;tid=1045855&amp;highlight=vpn" target="_blank" rel="noopener">知行论坛</a>有专业人士作答，附上<a href="http://106.15.64.216:8080/zh/troubleshooting" target="_blank" rel="noopener">下载地址</a>，不做赘述。</p><h2 id="安卓手机-1"><a href="#安卓手机-1" class="headerlink" title="安卓手机"></a>安卓手机</h2><p>官方教程是有效的，设施方法和笔记本相同，不做赘述。</p><h1 id="使用体验"><a href="#使用体验" class="headerlink" title="使用体验"></a>使用体验</h1><ol><li><p>对于不同大小的屏幕，软件是怎么处理的？</p><p>这一点十分优秀，一些窗口的排布会自动调整，比如下面是在手机上的显示</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/5.jpg" alt=""></p></li><li><p>延迟怎么样？</p><p>无论是使用宿舍的局域网还是使用4G，延迟都很令人满意，几乎察觉不到</p></li><li><p>对网速的要求怎么样？</p><p>在手机上网速稳定在60k左右</p></li><li><p>可以用来打游戏吗？</p><p>想多了，并可以，不是延迟的问题，而是拒绝渲染</p></li></ol><h1 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h1><p>到所里测试结果不知道为啥电脑就是连接不上libvpn.bjtu.edu.cn这个服务器，可以连接上vpn.bjtu.edu.cn，所以电脑还是用不上远程桌面了，，，还好手机上一切正常，所以只能在笔记本上写好，用OneDrive同步，然后在手机上启动程序了，，，问题不大，但是请问有大佬能指出问题所在原因嘛？</p><p><img src="/2018/12/09/在校外通过VPN使用微软远程桌面连接校内主机的方法/5.png" alt=""></p><p>但是，如果拥有一台华为手机，这就不是问题了！只需要买一个拓展坞，给手机连上鼠标、键盘、显示器，然后在电脑模式下运行远程桌面，就可以获得特别好的体验！虽然是远程使用台式机，但是并没有明显的延迟，太爽了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以后都在所里干活，暂时没有分配台式机，宿舍的又不方便带过去（主要是不方便再带出来），所以折腾了一圈，终于大致搞定了。&lt;/p&gt;
&lt;h1 id=&quot;申请校内ip地址&quot;&gt;&lt;a href=&quot;#申请校内ip地址&quot; class=&quot;headerlink&quot; title=&quot;申请校内ip地址&quot;&gt;
      
    
    </summary>
    
      <category term="杂记" scheme="http://wang22ti.com/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>论文阅读-IRGAN_A_Minimax_Game_for_Unifying_Generative_and_Discriminative_Information_Retrieval_Models</title>
    <link href="http://wang22ti.com/2018/12/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/"/>
    <id>http://wang22ti.com/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/</id>
    <published>2018-12-04T11:48:40.000Z</published>
    <updated>2018-12-14T03:19:50.625Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://arxiv.org/pdf/1705.10513.pdf" target="_blank" rel="noopener">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models</a></p><p><a href="https://zhuanlan.zhihu.com/p/27297452" target="_blank" rel="noopener">Information retrieval GAN</a></p><p><a href="https://zhuanlan.zhihu.com/p/29860542" target="_blank" rel="noopener">再读IRGAN，聊聊Code与Formulation的差异</a></p><p><a href="https://github.com/geek-ai/irgan" target="_blank" rel="noopener">IRGAN SIGIR paper experimental code</a></p><h1 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h1><ol><li><p>研究对象？</p><blockquote><p>Information retrieval(IR) is to provide a list of <strong>documents</strong>(e.g., textual documents, information items, answers) given a <strong>query</strong>. There are two major schools of thinking when coming to IR theory and modeling.</p><p>Generative school: focused on describing how a document is generated from a given information need: <strong>q → d</strong>.</p><p>Discriminative(Classification) school: Consider documents and queries jointly as features and predicts their relevancy from a large amount of training data: <strong>q + d → r</strong>.</p></blockquote></li><li><p>生成式检索模型？</p><blockquote><p> $p_θ (d|q, r)$ tries to generate (or <strong>select</strong>) relevant documents from the <strong>candidate pool</strong> for the given query $q$, whose goal is to approximate the true relevance distribution over documents $p_{true} (d|q, r)$ as much as possible.</p></blockquote><p>在推荐系统中，作者使用的是矩阵分解，即下图中的函数$g$是右侧的函数$s$。</p><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/1.png" alt=""></p></li><li><p>判别式检索模型？</p><blockquote><p>$f_ϕ (q,d)$ tries to discriminate well-matched query-document tuples $(q,d)$ from ill-matched ones, which is in fact simply a <strong>binary classifier</strong>, and we could use 1 for truly match pair while 0 for those that do not really match.</p></blockquote><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/2.png" alt=""></p></li><li><p>总体框架？</p><blockquote><p>$p_θ (d|q, r)$ tries to approximate the true relevance distribution over documents $p_{true} (d|q, r)$ as much as possible.</p><p>$f_ϕ (q,d)$ tries to discriminate well-matched query-document tuples (q,d) from ill-matched ones.</p></blockquote><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/3.png" alt=""></p></li><li><p>推广到pair-wise的情况？</p><blockquote><p>we have a set of labeled document pairs $R_n=\{<d_i, d_j="">│d_i≻d_j \}$. The generator $G$ would try to <strong>generate document pairs</strong> that are similar to those in $R_n$, i.e., the correct ranking. The discriminator $D $ would try to distinguish such generated document pairs from those real document pairs. </d_i,></p></blockquote><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/4.png" alt=""></p></li><li><p>优化算法？</p><p>判别器使用的是随机梯度下降，而生成器为了处理自然语言处理中的问题，所以使用的策略梯度下降：</p><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/5.png" alt=""></p></li></ol><h1 id="实验复现（1）"><a href="#实验复现（1）" class="headerlink" title="实验复现（1）"></a>实验复现（1）</h1><p>实验的环境很奇怪，用的是python2的语法和tensorflow，这让我这个新时代的程序员很为难，因为tensorflow是和python3兼容的。改了一圈两者不兼容的地方，一个是<code>print</code>函数的使用，一个是把<code>dict.key()</code>对象转化为<code>list</code>对象，还有一个是<code>sort</code>函数的使用，然而还是卡住了，，卡住的原因是之前训练好的生成器参数用<code>pkl</code>的格式存储的，怎么读取都出错，换了各种打开和编码方式，，，求大佬指导啊</p><p><img src="/2018/12/04/论文阅读-IRGAN-A-Minimax-Game-for-Unifying-Generative-and-Discriminative-Information-Retrieval-Models/6.png" alt=""></p><p>目前的解决方案是去掉参数读取，把用到的地方换为<code>None</code>，然而跑了一天一夜，限于调参的水平，NDCG只跑到了二十几，，，</p><h1 id="实验复现（2）"><a href="#实验复现（2）" class="headerlink" title="实验复现（2）"></a>实验复现（2）</h1><p>经过幸运的尝试,终于解决了上面的问题，代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">param = pickle.load(</span><br><span class="line">    open(os.path.join(workdir, <span class="string">"model_dns_ori.pkl"</span>), <span class="string">'rb'</span>),</span><br><span class="line">    encoding=<span class="string">'latin1'</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>最后基本达到了论文中的结果！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=&quot;headerlink&quot; title=&quot;参考文献&quot;&gt;&lt;/a&gt;参考文献&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.10513.pdf&quot; target=&quot;_blank&quot;
      
    
    </summary>
    
      <category term="推荐算法" scheme="http://wang22ti.com/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>论文阅读-Large_scale_Collaborative_Ranking_in_Near-Linear_Time</title>
    <link href="http://wang22ti.com/2018/12/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/"/>
    <id>http://wang22ti.com/2018/12/04/论文阅读-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/</id>
    <published>2018-12-04T11:47:16.000Z</published>
    <updated>2018-12-06T11:49:28.933Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>两篇文献都是关于Collaborative Ranking，第一篇偏重数学推导，是第二篇的基础。</p><p><a href="https://arxiv.org/pdf/1507.04457.pdf" target="_blank" rel="noopener">Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons</a></p><p><a href="http://www.stat.ucdavis.edu/~chohsieh/rf/KDD_Collaborative_Ranking.pdf" target="_blank" rel="noopener">Large-scale Collaborative Ranking in Near-Linear Time</a></p><h1 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h1><ol><li><p>研究对象？</p><p>输入为用户$i$对于物品$j$和物品$k$的偏好程度</p><script type="math/tex; mode=display">Y _ { i j k } = \left\{ \begin{array} { c l } { 1 , } & { \text { user i prefers item j better than item } k } \\ { - 1 , } & { \text { user i prefers item } k \text { better than item } j } \end{array} \right.</script><p>和CF不一样，CR输出的是用户$i$对物品$j$的偏好程度的矩阵，即</p><script type="math/tex; mode=display">X \in R ^ { d _ { 1 } \times d _ { 2 } }</script><p>其中$d_1$和$d_2$分别为用户数量和物品数量。</p></li><li><p>最直接的方法应该怎么做？为什么不这么做？怎么处理？</p><p>可以优化下面的损失函数：</p><script type="math/tex; mode=display">\min _ { X } \sum _ { ( i , j , k ) \in \Omega } \mathcal { L } \left( Y _ { i j k } \left( X _ { i j } - X _ { i k } \right) \right) + \lambda \| X \| _ { * }</script><p>其中$\mathcal{L}$是损失函数，常常用<a href="https://blog.csdn.net/u010976453/article/details/78488279" target="_blank" rel="noopener">$\mathcal{L}_2$-hinge loss</a>；而$| X | _ { * }$是<a href="https://en.wikipedia.org/wiki/Matrix_norm" target="_blank" rel="noopener">核正则化项</a>，其作用为保证$X$是低<a href="https://www.zhihu.com/question/21605094" target="_blank" rel="noopener">秩</a>的，这样假设的理由是</p><blockquote><p>We propose (as have others) that $X$ is low-rank or close to low-rank, the intuition being that each user bases their preferences on a small set of features that are common among all the items.</p></blockquote><p>这是个很好的凸优化问题，但是由于在大规模问题中算法复杂度过大，所以利用低秩这条假设，令</p><script type="math/tex; mode=display">X = U V ^ { T },U\in\R^{d_1\times r},V\in\R^{r\times d_2}</script><p>其中$r$为矩阵的秩，则损失函数转化为</p><script type="math/tex; mode=display">\min _ { U , V } \sum _ { ( i , j , k ) \in \Omega } \mathcal { L } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) + \frac { \lambda } { 2 } \left( \| U \| _ { F } ^ { 2 } + \| V \| _ { F } ^ { 2 } \right)</script></li></ol><ol><li><p>怎么优化上述的非凸问题？</p><p>总体思路是坐标下降法，在固定一个参数的情况下优化另一个。</p><p><img src="/2018/12/04/论文阅读-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/1.png" alt=""></p><p>而算法2如下图所示</p><p><img src="/2018/12/04/论文阅读-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/2.png" alt=""></p><p>其中</p><script type="math/tex; mode=display">V = \underset { V \in \mathbb { R } ^ { r \times d _ { 2 } } } { \operatorname { argmin } } \left\{ \frac { \lambda } { 2 } \| V \| _ { F } ^ { 2 } + \sum _ { ( i , j , k ) \in \Omega } \mathcal { L } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \right\} : = f ( V )\\U = \underset { U \in \mathbb { R } ^ { r \times d _ { 2 } } } { \operatorname { argmin } } \left\{ \frac { \lambda } { 2 } \| U \| _ { F } ^ { 2 } + \sum _ { i = 1 } ^ { d _ { 1 } } \sum _ { ( j , k ) \in \overline { d } _ { 2 } ( i ) } \mathcal { L } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \right\}</script><p>由于假设$U$相对独立，所以有</p><script type="math/tex; mode=display">u _ { i } = \underset { u \in \mathbb { R } ^ { r } } { \operatorname { argmin } } \frac { \lambda } { 2 } \| u \| _ { 2 } ^ { 2 } + \sum _ { ( j , k ) \in \overline { d } _ { 2 } ( i ) } \mathcal { L } \left( Y _ { i j k } \cdot u ^ { T } \left( v _ { j } - v _ { k } \right) \right) : = h ( u )</script><p>即在并行计算的情况下优化$U$并不困难，关键是优化$V$。</p></li><li><p>怎么理解算法2？</p><p><code>牛顿方法（Newton&#39;s Method）</code>是求解函数零点的一种方法，具体参加<a href="http://wang22ti.com/2018/05/25/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE1%E2%80%94%E2%80%94%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">我的博客</a>，在优化问题中的表达式为：</p><script type="math/tex; mode=display">x \leftarrow x - \left( \nabla ^ { 2 } f ( x ) \right) ^ { - 1 } \nabla f ( x )</script><p>然而在大规模优化问题中，海森矩阵$H,\nabla ^ { 2 } f ( x )$的逆矩阵的求解过于复杂，因此使将两者乘积的值记为$a$，转而求解方程</p><script type="math/tex; mode=display">\nabla ^ { 2 } f ( x ) a = \nabla f ( x )</script><p>的近似解，求解方法就是<code>共轭梯度法（Linear Conjugate Gradient）</code>，复杂的过程在算法2中有，也可以参照<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method" target="_blank" rel="noopener">维基百科</a>或<a href="https://keson96.github.io/2016/11/27/2016-11-27-Conjugate-Gradient-Method/" target="_blank" rel="noopener">大神的博客</a>，其基本思想是将方程组求解问题转化为优化问题：</p><script type="math/tex; mode=display">A x = b \Leftrightarrow \min \phi ( x ) = \frac { 1 } { 2 } x ^ { T } A x - b ^ { T } x</script><p>所以现在的问题是——</p></li><li><p>如何快速求解海森矩阵和梯度矩阵？</p><p>以优化$V$为例，先写出梯度的表达式为</p><script type="math/tex; mode=display">\nabla f ( V ) = \sum _ { i = 1 } ^ { d _ { 1 } } \sum _ { ( j , k ) \in \Omega _ { i } } \mathcal { L } ^ { \prime } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \left( u _ { i } e _ { j } ^ { T } - u _ { i } e _ { k } ^ { T } \right) Y _ { i j k } + \lambda V</script><p>注意到其中有大量的矩阵计算，且除了$u_ie^T$外均是常熟，所以上式部分可以采用如下的表达形式：</p><script type="math/tex; mode=display">\sum _ { ( j , k ) \in \Omega _ { i } } \mathcal { L } ^ { \prime } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \left( u _ { i } e _ { j } ^ { T } - u _ { i } e _ { k } ^ { T } \right) Y _ { i j k } = \sum _ { j \in \overline { d } _ { 2 } ( i ) } t _ { j } u _ { i } e _ { j } ^ { T }</script><p>即提前算好所有的矩阵乘法，然后计算每一个$(i, j)$的时候直接加到对应的$u_i$即可，如下图所示</p><p><img src="/2018/12/04/论文阅读-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/3.png" alt=""></p><p>对于海森矩阵的求解，也有类似的思路，先写出表达式：</p><script type="math/tex; mode=display">\begin{array} { l } { \nabla _ { j , k } ^ { 2 } f ( V ) = } \\ {  \sum _ { i : ( j , k ) \in \overline { d } _ { 2 } ( i ) } \mathcal { L } ^ { \prime \prime } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \left( - u _ { i } u _ { i } ^ { T } \right)  } & { \text { if } j \neq k } \\ { \sum _ { i : j \in \overline { d } _ { 2 } ( i ) } \sum _ { k \in \overline { d } _ { 2 } ( i ) , k \neq j } \mathcal { L } ^ { \prime \prime } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) u _ { i } u _ { i } ^ { T } + \lambda I _ { r \times r } } & { \text { if } j = k } \end{array}</script><p>进一步有</p><script type="math/tex; mode=display">\begin{array} { l } { H \cdot a = \sum _ { j } E _ { j } ( H \cdot a ) _ { j } } \\ { = \lambda a + \sum _ { i } \sum _ { j \in \overline { d } _ { 2 } ( i ) } E _ { j } u _ { i } \sum _ { k \in \tilde { d } _ { 2 } ( i ), k \neq j } \mathcal { L } ^ { \prime \prime } \left( Y _ { i j k } \cdot u _ { i } ^ { T } \left( v _ { j } - v _ { k } \right) \right) \left( u _ { i } ^ { T } a _ { j } - u _ { i } ^ { T } a _ { k } \right) } \end{array}</script><p>类似有：</p><p><img src="/2018/12/04/论文阅读-Large-scale-Collaborative-Ranking-in-Near-Linear-Time/4.png" alt=""></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=&quot;headerlink&quot; title=&quot;参考文献&quot;&gt;&lt;/a&gt;参考文献&lt;/h1&gt;&lt;p&gt;两篇文献都是关于Collaborative Ranking，第一篇偏重数学推导，是第二篇的基础。&lt;/p&gt;
&lt;p&gt;&lt;a hre
      
    
    </summary>
    
      <category term="推荐算法" scheme="http://wang22ti.com/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>论文阅读-Neural_Collaborative_Filtering</title>
    <link href="http://wang22ti.com/2018/11/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Neural-Collaborative-Filtering/"/>
    <id>http://wang22ti.com/2018/11/11/论文阅读-Neural-Collaborative-Filtering/</id>
    <published>2018-11-11T02:38:10.000Z</published>
    <updated>2018-11-22T13:06:43.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h2 id="直接"><a href="#直接" class="headerlink" title="直接"></a>直接</h2><p><a href="https://arxiv.org/pdf/1708.05031.pdf" target="_blank" rel="noopener">Neural Collaborative Filtering</a></p><p><a href="https://www.comp.nus.edu.sg/~xiangnan/" target="_blank" rel="noopener">Xiangnan He’s Homwpage</a></p><h2 id="间接"><a href="#间接" class="headerlink" title="间接"></a>间接</h2><p><a href="https://www.cnblogs.com/HolyShine/p/6728999.html" target="_blank" rel="noopener">【翻译】Neural Collaborative Filtering—神经协同过滤</a></p><p><a href="https://www.cnblogs.com/wzyj/p/8974782.html" target="_blank" rel="noopener">【推荐系统】neural_collaborative_filtering（源码解析）</a></p><p><a href="https://zhuanlan.zhihu.com/p/31122667" target="_blank" rel="noopener">Neural Collaborative Filtering文章概要</a></p><p><a href="https://www.cnblogs.com/baihuaxiu/p/6617389.html" target="_blank" rel="noopener">[机器学习]推荐系统之协同过滤算法</a></p><p><a href="https://blog.csdn.net/yinruiyang94/article/details/78906370" target="_blank" rel="noopener">implicit feedback</a></p><p><a href="https://baike.baidu.com/item/Jaccard%E7%B3%BB%E6%95%B0/6784913?fr=aladdin" target="_blank" rel="noopener">Jaccard系数</a></p><p><a href="https://blog.csdn.net/u011926899/article/details/52669180" target="_blank" rel="noopener">NDCG评价指标讲解</a></p><h1 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h1><ol><li><p>文章简述？</p><ul><li>证明MF具有局限性</li><li>提出NCF的基本结构</li><li>提出NCF的具体实现——GMF、MLP以及由它们融合的NeuMF</li><li>实验与结论，包括预训练的技巧</li></ul></li><li><p>文章研究的对象?</p><p>以implicit feedback为基础的协同过滤</p><blockquote><p>which indirectly reflects users’ preference through behaviours like watching videos, purchasing products and clicking items. Compared to explicit feedback (i.e., ratings and reviews), implicit feedback can be tracked automatically and is thus much easier to collect for content providers. However, it is more challenging to utilize, since user satisfaction is not observed and there is a natural scarcity of negative feedback. In this paper, we explore the central theme of how to utilize DNNs to model noisy implicit feedback signals.</p></blockquote></li><li><p>MF的局限性？或者说为什么要用神经网络代替MF？</p><blockquote><p>Despite the effectiveness of MF for collaborative filtering, it is well-known that its performance can be hindered by the simple choice of the interaction function — inner product. </p></blockquote></li><li><p>为什么神经网络的引入可以克服MF的局限性？</p><blockquote><p>The neural network has been proven to be capable of approximating any continuous function</p></blockquote></li><li><p>NCF的结构？</p><p><img src="/2018/11/11/论文阅读-Neural-Collaborative-Filtering/../../../博士/方向探索/推荐算法/神经协同过滤/对于神经协同网络几个关键问题的思考/1.png" alt=""></p><p>数学的表达为：</p><script type="math/tex; mode=display">\hat { y } _ { u i } = f \left( \mathbf { P } ^ { T } \mathbf { v } _ { u } ^ { U } , \mathbf { Q } ^ { T } \mathbf { v } _ { i } ^ { I } | \mathbf { P } , \mathbf { Q } , \Theta _ { f } \right)</script></li></ol><blockquote><p> where $\mathbf { P } \in \mathbb { R } ^ { M \times K } \text { and } \mathbf { Q } \in \mathbb { R } ^ { N \times K }$, denoting the latent factor matrix for users and items, respectively; and  $\Theta _ { f }$ denotes the model parameters of the interaction function $f$. Since the function $f$ is defined as a multi-layer neural network, it can be formulated as</p></blockquote><script type="math/tex; mode=display">   f \left( \mathbf { P } ^ { T } \mathbf { v } _ { u } ^ { U } , \mathbf { Q } ^ { T } \mathbf { v } _ { i } ^ { I } \right) = \phi _ { o u t } \left( \phi _ { X } \left( \ldots \phi _ { 2 } \left( \mathbf { P } ^ { T } \mathbf { v } _ { u } ^ { U } , \mathbf { Q } ^ { T } \mathbf { v } _ { i } ^ { I } \right) \right) \ldots \right) )</script><blockquote><p>where $\phi _ { o u t } $ and $ \phi _ { x }$ respectively denote the mapping function for the output layer and $x$-th neural collaborative filtering (CF) layer, and there are $X$ neural $CF$ layers in total.</p></blockquote><ol><li><p>为什么在NCF的损失函数是交叉熵，或者说如何处理implicit sample？</p><blockquote><p>While the squared loss can be explained by assuming that observations are generated from a Gaussian distribution, we point out that it may not tally well with implicit data. This is because for implicit data, the target value $y_{ui}$ is a binarized 1 or 0 denoting whether u has interacted with i.</p><p>Considering the one-class nature of implicit feedback, wecan view the value of $y_{ui}$ as a label — 1 means item $i$ is relevant to u, and $0$ otherwise. The prediction score $\hat{y}_{ui}$ then represents how likely $i$ is relevant to $u$. To endow NCF with such a probabilistic explanation, we need to constrain the output $\hat{y}_{ui}$ in the range of $[0, 1]$, which can be easily achieved by using a probabilistic function (e.g., the Logistic or Probit function) as the activation function for the output layer $φ_{out}$.</p></blockquote></li><li><p>为什么说GMF是Generated MF？或者为什么说MF是GMF的一个特例？</p><p>在MF中有</p><script type="math/tex; mode=display">\phi _ { 1 } \left( \mathbf { p } _ { u } , \mathbf { q } _ { i } \right) = \mathbf { p } _ { u } \odot \mathbf { q } _ { i }</script><p>而在GMF可以写成</p><script type="math/tex; mode=display">\hat { y } _ { u i } = a _ { o u t } \left( \mathbf { h } ^ { T } \left( \mathbf { p } _ { u } \odot \mathbf { q } _ { i } \right) \right)</script><p>因此有</p><blockquote><p>if we use an identity function for $a_{out}$ and enforce $h$ to be a uniform vector of 1, we can exactly recover the MF model.</p></blockquote></li><li><p>为什么要将GMF和MLP融合？</p><blockquote><p>It unifies the strengths of linearity of MF and non-linearity of MLP for modelling the user–item latent structures.</p></blockquote></li><li><p>为什么要预训练？</p><blockquote><p>Due to the non-convexity of the objective function of NeuMF可能的进一步工作？</p></blockquote></li><li><p>实验结果？</p><ul><li>pre-trained NeuMF &gt; NeuMF &gt; MLP &gt; GMF &gt; others</li><li>更深的网络是有作用的</li></ul></li><li><p>进一步的工作？</p><blockquote><p> While a nonuniform sampling strategy (e.g., item popularity-biased [14, 12]) might further improve the performance, we leave the exploration as a future work.</p><p>In future, we will study pairwise learners for NCF models and extend NCF to model auxiliary information, such as user reviews [11], knowledge bases [45], and temporal signals [1]. While existing personalization models have primarily focused on individuals, it is interesting to develop models for groups of users, which help the decision-making for social groups [15, 42]. Moreover, we are particularly interested in building recommender systems for multi-media items, an interesting task but has received relatively less scrutiny in the recommendation community [3]. Multi-media items, such as images and videos, contain much richer visual semantics [16, 41] that can reflect users’ interest. To build a multi-media recommender system, we need to develop effective methods to learn from multi-view and multi-modal data [13, 40]. Another emerging direction is to explore the potential of recurrent neural networks and hashing method</p></blockquote></li></ol><h1 id="实验复现"><a href="#实验复现" class="headerlink" title="实验复现"></a>实验复现</h1><p>首先是git一波</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hexiangnan/neural_collaborative_filtering.git</span><br></pre></td></tr></table></figure><p>看一下Read Me，环境用的是</p><blockquote><ul><li>Keras version:  ‘1.0.7’</li><li>Theano version: ‘0.8.0’</li></ul></blockquote><p>于是用anaconda新建一个环境，就叫ncf吧，结果运行起来就报了个错：</p><blockquote><p> ValueError: Only call sigmoid_cross_entropy_with_logits with named arguments (labels=…, logits=…, …)</p></blockquote><p>原因是它并没有告诉我安装什么版本的tensorflow，，还好issue里有<a href="https://github.com/hexiangnan/neural_collaborative_filtering/issues/15" target="_blank" rel="noopener">解答</a>（我的环境是tensorflow=1.8.0, python=3.6）。接着还会报一个</p><blockquote><p>ImportError: cannot import name ‘control_flow_ops’</p></blockquote><p>的错误，还好还是有<a href="https://github.com/tensorflow/tensorflow/issues/7020" target="_blank" rel="noopener">大神</a>能搞定。</p><p>至此，GMF.py终于跑起来了，然而跑MLP.py的时候又报了新的错：</p><blockquote><p>TypeError: Expected int32, got list containing Tensors of type ‘_Message’ instead.</p></blockquote><p>emmmm，还是新的tensorflow的api出现的了问题，<a href="https://github.com/carpedm20/DCGAN-tensorflow/issues/99" target="_blank" rel="noopener">大神</a>已经指出了直接调用tensorflow的情况。在keras中，还需要根据报错路径修改文件<code>tensorflow_backend.py</code>中的<code>concatenate</code>函数：</p><blockquote><p>from </p><p><code>return tf.concat(as, tensors)</code></p><p>to</p><p><code>return tf.concat(tensors, ax)</code></p></blockquote><p>实际上，有这样问题的不止一处，但是这样已经跑起来了！</p><p>NeuMF.py是上面两个网络的综合，所以并没有出现新的错误。</p><p>事实证明，应该先看一下issue，用python2.7的，，，</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;参考文献&quot;&gt;&lt;a href=&quot;#参考文献&quot; class=&quot;headerlink&quot; title=&quot;参考文献&quot;&gt;&lt;/a&gt;参考文献&lt;/h1&gt;&lt;h2 id=&quot;直接&quot;&gt;&lt;a href=&quot;#直接&quot; class=&quot;headerlink&quot; title=&quot;直接&quot;&gt;&lt;/a&gt;直接&lt;/h
      
    
    </summary>
    
      <category term="推荐算法" scheme="http://wang22ti.com/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验6-BP神经网络</title>
    <link href="http://wang22ti.com/2018/11/11/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C6-BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://wang22ti.com/2018/11/11/《模式识别》实验6-BP神经网络/</id>
    <published>2018-11-11T02:29:21.000Z</published>
    <updated>2018-11-13T02:57:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li><p>了解人工神经网络的生物学基础</p></li><li><p>掌握神经网络网络的前向传播和反向传播的数学原理</p></li><li><p>用matlab实现一个简单的全连接神经网络</p></li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><p>​        可以参见我的个人博客wang22ti.com，其中博文《<a href="http://wang22ti.com/2018/07/31/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">mooc-深度学习工程师-1-神经网络和深度学习</a>》对神经网络的数学原理有详细的介绍。</p><p>​        MATLAB软件包含MATLAB神经网络工具箱。它是以人工神经网络理论为基础，用MATLAB语言构造出了该理论所涉及的公式运算、矩阵操作和方程求解等大部分子程序以用于神经网络的设计和训练。用户只需要根据自己的需要调用相关的子程序，即可以完成包括网络结构设计、权值初始化、网络训练及结果输出等在内的一系列工作，免除编写复杂庞大程序的困扰。BP神经网络主要用到newff，sim和train3个神经网络函数：</p><ol><li><p>net=Newff (P, T, S, TF, BTF, BLF, PF, IPF, OPE, DDE)</p><p>创建一个BP神经网络，其中P为输入数据矩阵；T为输出数据矩阵；S为隐含层节点的数组；TF为节点的激活函数，比如logsig、purelin；BTF为训练函数，比如动态反向传播和动态自适应学习率的梯度下降算法traingdx；BLF为网络学习函数，比如BP学习规则learned。一般手动设置前6个参数，后面4个采用系统默认。</p></li><li><p>[net,tr]=train(NET, X, T, Pi, Ai)</p><p>用训练数据训练BP神经网络，其中NET为待训练网络；X为输入数据矩阵；T为输出数据矩阵；Pi为初始化输入层条件；Ai为初始化输出层条件；net为训练好的神经网络；tr为训练过程记录。一般手动设置前面3个参数。</p></li><li><p>y=sim(net, x)</p><p>用训练好的BP神经网络预测函数输出。其中net是训练好的神经网络；x为输入数据；y为网络预测数据。</p></li></ol><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><p>​        有一批Iris花，已知这批Iris花可分为3个品种，现需要对其进行分类。不同品种的Iris花的花萼长度、花萼宽度、花瓣长度、花瓣宽度会有差异。我们现有一批已知品种的Iris花的花萼长度、花萼宽度、花瓣长度、花瓣宽度的数据。用已有的数据训练一个神经网络用作分类器。实验代码如下所示，前者是训练代码，后者是测试代码。</p><h2 id="train"><a href="#train" class="headerlink" title="train"></a>train</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%将Iris数据集分为2组，每组各75个样本，每组中每种花各有25个样本。</span></span><br><span class="line"><span class="comment">%其中一组作为以上程序的训练样本，另外一组作为检验样本。</span></span><br><span class="line"><span class="comment">%为了方便训练，将3类花分别编号为1，2，3 。</span></span><br><span class="line"><span class="comment">%使用这些数据训练一个4输入（分别对应4个特征），3输出（分别对应该样本属于某一品种的可能性大小）的前向网络。</span></span><br><span class="line"></span><br><span class="line">clear all;</span><br><span class="line"><span class="comment">%读取训练数据</span></span><br><span class="line">[f1,f2,f3,f4,class] = textread(<span class="string">'trainData.txt'</span>,<span class="string">'%f%f%f%f%s'</span>,<span class="number">75</span>);</span><br><span class="line"><span class="comment">%特征值归一化</span></span><br><span class="line"><span class="comment">%构造输出矩阵</span></span><br><span class="line">[input,minI,maxI] = premnmx( [f1 , f2 , f3 , f4 ]')  ;</span><br><span class="line">s=<span class="built_in">length</span>(class);</span><br><span class="line">output=<span class="built_in">zeros</span>(s,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : s </span><br><span class="line">    <span class="keyword">if</span> strcmp(class(<span class="built_in">i</span>),<span class="string">'Isetosa'</span>)</span><br><span class="line">        output( <span class="built_in">i</span> , <span class="number">1</span>) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">elseif</span> strcmp(class(<span class="built_in">i</span>),<span class="string">'Iversicolor'</span>)</span><br><span class="line">        output( <span class="built_in">i</span> , <span class="number">2</span>) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        output( <span class="built_in">i</span> , <span class="number">3</span> ) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%创建神经网络</span></span><br><span class="line">net = newff(minmax(input), [<span class="number">10</span>, <span class="number">3</span>], &#123;<span class="string">'logsig'</span>, <span class="string">'purelin'</span>&#125;, <span class="string">'traingdx'</span>) ; </span><br><span class="line"><span class="comment">%设置训练参数</span></span><br><span class="line">net.trainparam.show = <span class="number">50</span> ;          <span class="comment">%显示中间结果的周期；</span></span><br><span class="line">net.trainparam.epochs = <span class="number">1000</span> ;     <span class="comment">%最大的迭代次数；</span></span><br><span class="line">net.trainparam.goal = <span class="number">0.01</span>;          <span class="comment">%神经网络的训练的目标误差；</span></span><br><span class="line">net.trainParam.lr = <span class="number">0.005</span> ;           <span class="comment">%学习率；</span></span><br><span class="line"><span class="comment">%开始训练 </span></span><br><span class="line">[net, tr] = train( net, input , output' ) ;</span><br></pre></td></tr></table></figure><h2 id="test"><a href="#test" class="headerlink" title="test"></a>test</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%读取测试数据</span></span><br><span class="line">[t1, t2, t3, t4, c] = textread(<span class="string">'testData.txt'</span> , <span class="string">'%f%f%f%f%s'</span>,<span class="number">75</span>);</span><br><span class="line"><span class="comment">%测试数据归一化</span></span><br><span class="line">testInput = tramnmx ( [t1,t2,t3,t4]' , minI, maxI ) ;</span><br><span class="line"><span class="comment">%仿真</span></span><br><span class="line">Y = sim( net , testInput );</span><br><span class="line"><span class="comment">%补充程序4</span></span><br><span class="line">s=<span class="built_in">length</span>(c);</span><br><span class="line">output1=<span class="built_in">zeros</span>(s,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : s </span><br><span class="line">    <span class="keyword">if</span> strcmp(c(<span class="built_in">i</span>),<span class="string">'Isetosa'</span>)</span><br><span class="line">        output1( <span class="built_in">i</span> , <span class="number">1</span> ) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">elseif</span> strcmp(c(<span class="built_in">i</span>),<span class="string">'Iversicolor'</span>)</span><br><span class="line">        output1( <span class="built_in">i</span> , <span class="number">2</span>  ) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        output1( <span class="built_in">i</span> , <span class="number">3</span>  ) = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%统计识别正确率</span></span><br><span class="line">[s1 , s2] = <span class="built_in">size</span>( Y ) ;</span><br><span class="line">hitNum = <span class="number">0</span> ;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : s2</span><br><span class="line">    [m , Index] = max( Y( : ,  <span class="built_in">i</span> ) ) ;</span><br><span class="line">    <span class="keyword">if</span>( output1(<span class="built_in">i</span>,Index) == <span class="number">1</span>   ) </span><br><span class="line">        hitNum = hitNum + <span class="number">1</span> ; </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">sprintf(<span class="string">'识别率是 %3.3f%%'</span>,<span class="number">100</span> * hitNum / s2 )</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><p>​        运行训练代码会出现如下图所示的UI，可以实时查看神经网络的结构，训练过程中的数据，比如代数、时间、梯度、损失等等，十分简单易用。</p><p><img src="/2018/11/11/《模式识别》实验6-BP神经网络/《模式识别》实验5-最近邻与k近邻/1.png" alt=""></p><p>运行测试代码，得到在测试集上的识别率为96.000%，还是一个比较理想的结果。</p><p><img src="/2018/11/11/《模式识别》实验6-BP神经网络/《模式识别》实验5-最近邻与k近邻/2.png" alt=""></p><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>​        本次实验聚焦于神经网络的原理分析与设计。神经网络是当前模式识别领域最火热的方法，在计算机视觉、自然语言处理等领域每天都有新的神经网络模型被提出。此前我一直使用python和tensorflow，这是我第一次使用matlab搭建神经网络，取得了意想不到的收获。相信这次实验对于我今后的科研工作会带来很大的帮助。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;了解人工神经网络的生物学基础&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;掌握神经网络网络的前向传播和反向传播的数学
      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验5-最近邻与k近邻</title>
    <link href="http://wang22ti.com/2018/11/11/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C5-%E6%9C%80%E8%BF%91%E9%82%BB%E4%B8%8Ek%E8%BF%91%E9%82%BB/"/>
    <id>http://wang22ti.com/2018/11/11/《模式识别》实验5-最近邻与k近邻/</id>
    <published>2018-11-11T02:28:47.000Z</published>
    <updated>2018-11-13T02:53:19.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li><p>掌握最近邻分类算法。</p></li><li><p>掌握k近邻分类算法。</p></li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><ol><li>最近邻法将与测试样本最近邻样本的类别作为决策的结果，对于一个C类的问题，每类有$N_i$个样本，则第$i$类$W_i$的判别函数为</li></ol><script type="math/tex; mode=display">g _ { i } ( x ) = \min _ { k } \left\| x - x _ { i } ^ { k } \right\| , k = 1 , \dots , N _ { i }</script><p>​        其中$| \cdot |$表示某种距离的度量，通常使用欧式距离。</p><ol><li>K近邻法是最近邻法的扩展，其基本规则是在所有$N$个样本中找到与测试样本的$k$个最近邻者，其中各类别所占个数表示为$\mathrm { k } _ { \mathrm { i } } , i = 1 , \dots , c$，定义判别函数为：</li></ol><script type="math/tex; mode=display">\mathrm { g } _ { \mathrm { i } } ( x ) = k _ { i } , i = 1,2 , \ldots , c</script><p>​    决策规则为</p><script type="math/tex; mode=display">\mathrm { j } = \operatorname { argmax } _ { i } g _ { i } ( x ) , i = 1 , \ldots , c</script><p>​        其中$k$一般采用奇数，避免因为票数相等而难以决策</p><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><ol><li><p>每类产生50个样本作为训练样本；每类产生100个样本作为考试样本</p></li><li><p>按最近邻法用训练样本对考试样本分类，计算平均错误率</p></li><li><p>按最k近邻法（k=21）用训练样本对考试样本分类，计算平均错误率</p></li><li><p>标注错分点。</p></li></ol><h2 id="最近邻"><a href="#最近邻" class="headerlink" title="最近邻"></a>最近邻</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 最近邻</span></span><br><span class="line">clear all;</span><br><span class="line">close all;</span><br><span class="line">clc;</span><br><span class="line">warning off</span><br><span class="line">mu1=[<span class="number">-2</span> <span class="number">-2</span>];    <span class="comment">%均值向量</span></span><br><span class="line">mu2=[<span class="number">2</span> <span class="number">2</span>];</span><br><span class="line">sigma1=[<span class="number">1</span> <span class="number">0</span>;<span class="number">0</span> <span class="number">1</span>];    <span class="comment">%协方差矩阵</span></span><br><span class="line">sigma2=[<span class="number">1</span> <span class="number">0</span>;<span class="number">0</span> <span class="number">4</span>];</span><br><span class="line">N1=<span class="number">50</span>;  <span class="comment">%每一类50个训练样本</span></span><br><span class="line">N2=<span class="number">100</span>; <span class="comment">%每一类100个考试样本</span></span><br><span class="line">train1=mvnrnd(mu1,sigma1,N1);   <span class="comment">%产生多维正态随机数</span></span><br><span class="line">train2=mvnrnd(mu2,sigma2,N1);</span><br><span class="line">test1=mvnrnd(mu1,sigma1,N2);</span><br><span class="line">test2=mvnrnd(mu2,sigma2,N2);</span><br><span class="line">train=[train1;train2];  <span class="comment">%训练样本，前50行为第一类，后50行为第二类</span></span><br><span class="line">dist1=<span class="built_in">zeros</span>(N2,<span class="number">2</span>*N1); <span class="comment">%考试点到第一类训练点的距离矩阵</span></span><br><span class="line">dist2=<span class="built_in">zeros</span>(N2,<span class="number">2</span>*N1); <span class="comment">%考试点到第二类训练点的距离矩阵</span></span><br><span class="line">t1=<span class="number">1</span>;</span><br><span class="line">t2=<span class="number">1</span>;</span><br><span class="line">err_index1=[];</span><br><span class="line">err_index2=[];</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:N2 <span class="comment">%遍历所有考试点</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">2</span>*N1 <span class="comment">%遍历所有训练点</span></span><br><span class="line">        <span class="comment">%补充程序1  （第一类）考试点到所有训练点的距离</span></span><br><span class="line">        dist1(<span class="built_in">i</span>, <span class="built_in">j</span>) = ((test1(<span class="built_in">i</span>, <span class="number">1</span>) - train(<span class="built_in">j</span>, <span class="number">1</span>))^<span class="number">2</span> + (test1(<span class="built_in">i</span>, <span class="number">2</span>) - train(<span class="built_in">j</span>, <span class="number">2</span>))^<span class="number">2</span>)^<span class="number">0.5</span>;</span><br><span class="line">        <span class="comment">%补充程序2  （第二类）考试点到所有训练点的距离</span></span><br><span class="line">        dist2(<span class="built_in">i</span>, <span class="built_in">j</span>) = ((test2(<span class="built_in">i</span>, <span class="number">1</span>) - train(<span class="built_in">j</span>, <span class="number">1</span>))^<span class="number">2</span> + (test2(<span class="built_in">i</span>, <span class="number">2</span>) - train(<span class="built_in">j</span>, <span class="number">2</span>))^<span class="number">2</span>)^<span class="number">0.5</span>;       </span><br><span class="line">    <span class="keyword">end</span> <span class="comment">%计算每个考试点到所有训练点的欧式距离</span></span><br><span class="line">    col1=<span class="built_in">find</span>(dist1(<span class="built_in">i</span>,:)==min(dist1(<span class="built_in">i</span>,:)));   <span class="comment">%发现（第一类）考试点到两类训练点距离最小值的列号</span></span><br><span class="line">    <span class="keyword">if</span> col1&gt;N1<span class="comment">%补充程序3 （第一类）考试点到第二类训练点的距离最小</span></span><br><span class="line">        err_index1(t1)=<span class="built_in">i</span>;   <span class="comment">%（第一类）考试点错分为第二类的索引</span></span><br><span class="line">        t1=t1+<span class="number">1</span>;    <span class="comment">%（第一类）考试点错分数加1</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    col2=<span class="built_in">find</span>(dist2(<span class="built_in">i</span>,:)==min(dist2(<span class="built_in">i</span>,:)));   <span class="comment">%发现（第二类）考试点到两类训练点距离最小值的列号</span></span><br><span class="line">    <span class="keyword">if</span> col2&lt;=N1<span class="comment">%补充程序4（第二类）考试点到第一类训练点的距离最小</span></span><br><span class="line">        err_index2(t2)=<span class="built_in">i</span>;   <span class="comment">%（第二类）考试点错分为第一类的索引</span></span><br><span class="line">        t2=t2+<span class="number">1</span>;    <span class="comment">%（第二类）考试点错分数加1</span></span><br><span class="line">    <span class="keyword">end</span> <span class="comment">%找到距离该考试点最近的训练点，判断是否错分</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">pe1=<span class="built_in">size</span>(err_index1,<span class="number">2</span>)/N2;</span><br><span class="line">pe2=<span class="built_in">size</span>(err_index2,<span class="number">2</span>)/N2;</span><br><span class="line">pe=<span class="number">0.5</span>*(pe1+pe2); <span class="comment">%计算错误率</span></span><br><span class="line">figure(<span class="number">1</span>)</span><br><span class="line">hold on</span><br><span class="line">grid on</span><br><span class="line">plot(train1(:,<span class="number">1</span>),train1(:,<span class="number">2</span>),<span class="string">'*y'</span>);</span><br><span class="line">plot(train2(:,<span class="number">1</span>),train2(:,<span class="number">2</span>),<span class="string">'+g'</span>);</span><br><span class="line">plot(test1(:,<span class="number">1</span>),test1(:,<span class="number">2</span>),<span class="string">'*r'</span>);</span><br><span class="line">plot(test2(:,<span class="number">1</span>),test2(:,<span class="number">2</span>),<span class="string">'+b'</span>);</span><br><span class="line">plot(test1(err_index1,<span class="number">1</span>),test1(err_index1,<span class="number">2</span>),<span class="string">'or'</span>,<span class="string">'MarkerSize'</span>,<span class="number">12</span>);</span><br><span class="line">plot(test2(err_index2,<span class="number">1</span>),test2(err_index2,<span class="number">2</span>),<span class="string">'sb'</span>,<span class="string">'MarkerSize'</span>,<span class="number">12</span>);</span><br></pre></td></tr></table></figure><h2 id="k近邻"><a href="#k近邻" class="headerlink" title="k近邻"></a>k近邻</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% K近邻</span></span><br><span class="line">clear all;</span><br><span class="line">close all;</span><br><span class="line">clear all;</span><br><span class="line">close all;</span><br><span class="line">clc;</span><br><span class="line">warning off</span><br><span class="line">mu1=[<span class="number">-2</span> <span class="number">-2</span>];    <span class="comment">%均值向量</span></span><br><span class="line">mu2=[<span class="number">2</span> <span class="number">2</span>];</span><br><span class="line">sigma1=[<span class="number">1</span> <span class="number">0</span>;<span class="number">0</span> <span class="number">1</span>];    <span class="comment">%协方差矩阵</span></span><br><span class="line">sigma2=[<span class="number">1</span> <span class="number">0</span>;<span class="number">0</span> <span class="number">4</span>];</span><br><span class="line">N1=<span class="number">50</span>;  <span class="comment">%每一类50个训练样本</span></span><br><span class="line">N2=<span class="number">100</span>; <span class="comment">%每一类100个考试样本</span></span><br><span class="line">train1=mvnrnd(mu1,sigma1,N1);   <span class="comment">%产生多维正态随机数</span></span><br><span class="line">train2=mvnrnd(mu2,sigma2,N1);</span><br><span class="line">test1=mvnrnd(mu1,sigma1,N2);</span><br><span class="line">test2=mvnrnd(mu2,sigma2,N2);</span><br><span class="line">train=[train1;train2];  <span class="comment">%训练样本，前50行为第一类，后50行为第二类</span></span><br><span class="line">dist1=<span class="built_in">zeros</span>(N2,<span class="number">2</span>*N1); <span class="comment">%考试点到第一类训练点的距离矩阵</span></span><br><span class="line">dist2=<span class="built_in">zeros</span>(N2,<span class="number">2</span>*N1); <span class="comment">%考试点到第二类训练点的距离矩阵</span></span><br><span class="line">t1=<span class="number">1</span>;</span><br><span class="line">t2=<span class="number">1</span>;</span><br><span class="line">err_index1=[];</span><br><span class="line">err_index2=[];</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:N2  <span class="comment">%遍历所有考试点</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">2</span>*N1 <span class="comment">%遍历所有训练点</span></span><br><span class="line">        dist1(<span class="built_in">i</span>,<span class="built_in">j</span>)=<span class="built_in">sqrt</span>((test1(<span class="built_in">i</span>,<span class="number">1</span>)-train(<span class="built_in">j</span>,<span class="number">1</span>))^<span class="number">2</span>+(test1(<span class="built_in">i</span>,<span class="number">2</span>)-train(<span class="built_in">j</span>,<span class="number">2</span>))^<span class="number">2</span>);  <span class="comment">%（第一类）考试点到所有训练点的距离</span></span><br><span class="line">        dist2(<span class="built_in">i</span>,<span class="built_in">j</span>)=<span class="built_in">sqrt</span>((test2(<span class="built_in">i</span>,<span class="number">1</span>)-train(<span class="built_in">j</span>,<span class="number">1</span>))^<span class="number">2</span>+(test2(<span class="built_in">i</span>,<span class="number">2</span>)-train(<span class="built_in">j</span>,<span class="number">2</span>))^<span class="number">2</span>);  <span class="comment">%（第二类）考试点到所有训练点的距离</span></span><br><span class="line">    <span class="keyword">end</span> <span class="comment">%计算每个考试点到所有训练点的欧式距离</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%k近邻（k=21）</span></span><br><span class="line">k=<span class="number">21</span>;</span><br><span class="line">thr=<span class="built_in">ceil</span>(k/<span class="number">2</span>);  <span class="comment">%向正方向取整</span></span><br><span class="line"><span class="comment">%补充程序1  对于每一行，将所有列按升序排列</span></span><br><span class="line">[sort_dist1, sort_index1] = sort(dist1, <span class="number">2</span>);</span><br><span class="line">[sort_dist2, sort_index2] = sort(dist2, <span class="number">2</span>);</span><br><span class="line"><span class="comment">%补充程序2   %先将得到的考试点与样本点的距离排序，同时记录排序的标号</span></span><br><span class="line"></span><br><span class="line">t1=<span class="number">1</span>;</span><br><span class="line">t2=<span class="number">1</span>;</span><br><span class="line">k_err_index1=[];</span><br><span class="line">k_err_index2=[];</span><br><span class="line">err_num1=<span class="built_in">size</span>(<span class="built_in">find</span>(sort_index1(<span class="built_in">i</span>,<span class="number">1</span>:k)&gt;N1),<span class="number">2</span>); </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:N2 <span class="comment">%遍历所有考试点</span></span><br><span class="line">    err_num1=<span class="built_in">size</span>(<span class="built_in">find</span>(sort_index1(<span class="built_in">i</span>,<span class="number">1</span>:k)&gt;N1),<span class="number">2</span>);  <span class="comment">%找前k个最近值中分错了几个</span></span><br><span class="line">    <span class="keyword">if</span> err_num1 &gt; thr<span class="comment">%补充程序3 如果错分数目过半</span></span><br><span class="line">        k_err_index1(t1)=<span class="built_in">i</span>;</span><br><span class="line">        t1=t1+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    err_num2=<span class="built_in">size</span>(<span class="built_in">find</span>(sort_index2(<span class="built_in">i</span>,<span class="number">1</span>:k)&lt;=N1),<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span> err_num2 &gt; thr<span class="comment">%补充程序4</span></span><br><span class="line">        k_err_index2(t2)=<span class="built_in">i</span>;</span><br><span class="line">        t2=t2+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="comment">%取前k个最小距离，看其标号中来自哪一类的训练样本点较多，判断是否错分</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">k_pe1=<span class="built_in">size</span>(k_err_index1,<span class="number">2</span>)/N2;</span><br><span class="line">k_pe2=<span class="built_in">size</span>(k_err_index2,<span class="number">2</span>)/N2;</span><br><span class="line">k_pe=<span class="number">0.5</span>*(k_pe1+k_pe2); <span class="comment">%计算错误率</span></span><br><span class="line">figure(<span class="number">1</span>)</span><br><span class="line">hold on</span><br><span class="line">grid on</span><br><span class="line">plot(train1(:,<span class="number">1</span>),train1(:,<span class="number">2</span>),<span class="string">'*y'</span>);</span><br><span class="line">plot(train2(:,<span class="number">1</span>),train2(:,<span class="number">2</span>),<span class="string">'+g'</span>);</span><br><span class="line">plot(test1(:,<span class="number">1</span>),test1(:,<span class="number">2</span>),<span class="string">'*r'</span>);</span><br><span class="line">plot(test2(:,<span class="number">1</span>),test2(:,<span class="number">2</span>),<span class="string">'+b'</span>);</span><br><span class="line">plot(test1(k_err_index1,<span class="number">1</span>),test1(k_err_index1,<span class="number">2</span>),<span class="string">'or'</span>,<span class="string">'MarkerSize'</span>,<span class="number">12</span>);</span><br><span class="line">plot(test2(k_err_index2,<span class="number">1</span>),test2(k_err_index2,<span class="number">2</span>),<span class="string">'sb'</span>,<span class="string">'MarkerSize'</span>,<span class="number">12</span>);</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><ol><li><p>最近邻的实验结果如下图所示，可见大多数样本被正确标记，只有临界区的几个出现了错误。</p><p><img src="/2018/11/11/《模式识别》实验5-最近邻与k近邻/1.png" alt=""></p></li><li><p>K近邻的实验结果如下图所示，与最近邻的实验现象相仿。</p><p><img src="/2018/11/11/《模式识别》实验5-最近邻与k近邻/2.png" alt=""></p></li></ol><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>​        本次实验聚焦于最近邻和K近邻两种分类器的设计。通过实验，我掌握了这两个同为一类的分类器的原理及其实现过程。这两个分类器都是无监督的分类，即便是在今后的科研学习中，只要合理定义“距离”，仍然十分有效。相信通过这次的学习，会对我今后的科研以及课程下一阶段的学习带来帮助。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;掌握最近邻分类算法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;掌握k近邻分类算法。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol
      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>华为Mate20Pro的使用总结</title>
    <link href="http://wang22ti.com/2018/11/08/%E5%8D%8E%E4%B8%BAMate20Pro%E7%9A%84%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://wang22ti.com/2018/11/08/华为Mate20Pro的使用总结/</id>
    <published>2018-11-08T07:21:17.000Z</published>
    <updated>2018-12-13T06:03:57.429Z</updated>
    
    <content type="html"><![CDATA[<p>讲道理的话，本不应该换手机的，米6用起来还是不错的。但是遇到了mate20pro这一部国产真旗舰，还是不由地高呼“真香”，于是入手了8+128G蓝色版本。详细的测评就不写了，网上铺天盖地，就写一些比较独特的吧。</p><h1 id="关于绿屏"><a href="#关于绿屏" class="headerlink" title="关于绿屏"></a>关于绿屏</h1><p>入手之前很担心这个问题，还好是京东方的屏幕，只要百度软件<code>device info hw</code>就可以看啦：</p><p><img src="/2018/11/08/华为Mate20Pro的使用总结/1.jpg" alt=""></p><p>在<code>Touchscreen</code>中BOE就是京东方啦。屏幕素质很不错，不过和三星的比还是略有差距，显示白色背景的时候曲面还是有一点点绿，无大碍，微信扫一扫没有翻车。有趣的是分辨率是智能调节的，比如图中显示的就是1080p。</p><h1 id="关于SIM卡槽"><a href="#关于SIM卡槽" class="headerlink" title="关于SIM卡槽"></a>关于SIM卡槽</h1><p>为了压缩空间，mate20pro的两张sim卡是背靠背放在一起的！这还是我第一次见，太刺激了~</p><h1 id="关于窗口小部件"><a href="#关于窗口小部件" class="headerlink" title="关于窗口小部件"></a>关于窗口小部件</h1><p>使用了邮箱和备忘录小部件之后，半天都没有刷新，贴吧上也有人有一样的情况：</p><p><a href="http://tieba.baidu.com/p/5322839441" target="_blank" rel="noopener">p10plus 备忘录 小部件不显示内容</a></p><p>实际上重启一下就好啦~不过还是软件做得不好</p><h1 id="关于隐藏应用"><a href="#关于隐藏应用" class="headerlink" title="关于隐藏应用"></a>关于隐藏应用</h1><p>之前用p9的时候，十分喜欢的功能是将不常用的应用，所谓眼不见为净嘿嘿，不过mate20pro竟然把这个功能给砍掉了emmmm，还好在论坛上有解决方案：</p><p>开启桌面隐藏的神器：<a href="https://club.huawei.com/thread-15930827-1-1.html" target="_blank" rel="noopener">Tweaker for Huawei_v2.4</a></p><h1 id="关于手机克隆的速度"><a href="#关于手机克隆的速度" class="headerlink" title="关于手机克隆的速度"></a>关于手机克隆的速度</h1><p>按照说明对米6进行克隆的时候，大多数情况特别特别慢，速度在5K到10M之间浮动，，，终于在一个偶然的机会，我发现当两个手机背对背拥抱的时候，就是使用NFC配对的时候，可以保持在非常高的速度，大概40-50M，几乎是米6的带宽极限了吧。</p><h1 id="关于自启动权限"><a href="#关于自启动权限" class="headerlink" title="关于自启动权限"></a>关于自启动权限</h1><p>emmmm，这个十分令人无语，因为捷波朗耳机的软件需要后台运行一个插件，我把设置翻了个遍也没找到这样的权限设置，最后在网上查了一下竟然在应用<code>手机管家</code>里面，，</p><h1 id="和米6的对比"><a href="#和米6的对比" class="headerlink" title="和米6的对比"></a>和米6的对比</h1><p>之所以和小米的上一代产品比，是因为真的没有钱再买米8了啊，，</p><p>优势：</p><ol><li>无敌的摄像水平，就不放样张了，见了都说好</li><li>960帧慢动作，AI摄影，AR表情，手持夜景，这些都是小米6没有的</li><li>40W的快充和4200毫安的电池，十分的安心</li><li>无线充电和反向无线充电实在是太酷了</li><li>优秀的屏幕A屏，极高的屏占比，看起来赏心悦目，还有息屏信息</li><li>蓝牙耳机几乎没有底噪</li><li>稳定的信号，比如在电梯里依然可以看视频！</li><li>完整的Google框架，翻墙很轻松</li><li>云电脑和无线投屏还是很赞的</li><li>指关节操作还是很赞的，而且比p9好用多了</li><li>支持长按图标呼出菜单，很方便</li><li>IP68防水，冲洗十分方便</li><li>抬腕亮屏+人脸解锁+屏下指纹，十分优秀的解锁方案</li><li>蓝色版本背后的纹理十分的好看，耐指纹</li><li>比米6陶瓷版要轻一些哈哈</li></ol><p>劣势主要集中在系统方面：</p><ol><li>没有负一屏比较鸡肋，没有我的购物、我的快递、我的收藏这些聚类</li><li>一些设定的逻辑混乱，就比如自启动的权限竟然不在设置当中</li><li>UI统一度有待加强，比如夜间模式中邮箱小部件完全没有改动（在2018年12月13日的更新中修复，赞）</li><li>无法自动获取流量套餐情况</li><li>应用双开完全没法和小米比</li><li>同步功能不如小米完善</li><li>相册没有按文字查找的功能，人脸分析的水平有待提高</li><li>可选的主题没有小米丰富</li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>华为mate20pro满足了我对于2018乃至2019年上半年对于机皇的所有想象。再加上对于国产零部件的带动，可以说是用心做手机了。同时，还有很多细节是值得进一步改善的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;讲道理的话，本不应该换手机的，米6用起来还是不错的。但是遇到了mate20pro这一部国产真旗舰，还是不由地高呼“真香”，于是入手了8+128G蓝色版本。详细的测评就不写了，网上铺天盖地，就写一些比较独特的吧。&lt;/p&gt;
&lt;h1 id=&quot;关于绿屏&quot;&gt;&lt;a href=&quot;#关于绿
      
    
    </summary>
    
      <category term="杂记" scheme="http://wang22ti.com/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>一个极简的翻译前端</title>
    <link href="http://wang22ti.com/2018/11/06/%E4%B8%80%E4%B8%AA%E6%9E%81%E7%AE%80%E7%9A%84%E7%BF%BB%E8%AF%91%E5%89%8D%E7%AB%AF/"/>
    <id>http://wang22ti.com/2018/11/06/一个极简的翻译前端/</id>
    <published>2018-11-06T08:08:52.000Z</published>
    <updated>2018-11-12T07:03:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>嗯……不知道为啥脑残地写了这个极简的翻译器</p><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>就是调用百度翻译的API了，输入框没有东西的时候按回车窗口跑到鼠标处，输入框里是q的时候按回车退出。</p><p><img src="/2018/11/06/一个极简的翻译前端/1.png" alt=""></p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><p>主要用到了了<a href="http://wang22ti.com/2018/02/20/%E7%AC%94%E8%AE%B0-%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91API/">调用百度翻译</a>，python前端包<code>tkinter</code>，以及检测鼠标键盘的包<code>pyautogui</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> pyautogui <span class="keyword">as</span> pag</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">baidu_traslate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        q=<span class="string">'apple'</span>, toLang=<span class="string">'zh'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        fromLang=<span class="string">'auto'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        appid=<span class="string">'***********'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        secretKey=<span class="string">'***************'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="keyword">import</span> random</span><br><span class="line">    <span class="keyword">import</span> hashlib</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    url = <span class="string">'http://api.fanyi.baidu.com/api/trans/vip/translate'</span></span><br><span class="line">    salt = random.randint(<span class="number">32768</span>, <span class="number">65536</span>)</span><br><span class="line"></span><br><span class="line">    sign = appid + q + str(salt) + secretKey</span><br><span class="line">    m = hashlib.md5(sign.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    sign = m.hexdigest()</span><br><span class="line"></span><br><span class="line">    url = url + \</span><br><span class="line">          <span class="string">'?appid='</span> + appid + \</span><br><span class="line">          <span class="string">'&amp;q='</span> + q + \</span><br><span class="line">          <span class="string">'&amp;from='</span> + fromLang + \</span><br><span class="line">          <span class="string">'&amp;to='</span> + toLang + \</span><br><span class="line">          <span class="string">'&amp;salt='</span> + str(salt) + <span class="string">'&amp;sign='</span> + sign</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        text = requests.get(url).text</span><br><span class="line">        ret_dict = json.loads(text)</span><br><span class="line">        ret_dict[<span class="string">'src'</span>] = ret_dict[<span class="string">'trans_result'</span>][<span class="number">0</span>][<span class="string">'src'</span>]</span><br><span class="line">        ret_dict[<span class="string">'dst'</span>] = ret_dict[<span class="string">'trans_result'</span>][<span class="number">0</span>][<span class="string">'dst'</span>]</span><br><span class="line">        ret_dict.pop(<span class="string">'trans_result'</span>)</span><br><span class="line">        <span class="keyword">return</span> ret_dict</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'dst'</span>: <span class="string">''</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyWindow</span><span class="params">(Frame)</span>:</span></span><br><span class="line"></span><br><span class="line">    x, y = <span class="number">1000</span>, <span class="number">80</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">operate</span><span class="params">(self, event)</span>:</span></span><br><span class="line">        src = self.input.get()</span><br><span class="line">        <span class="keyword">if</span> src == <span class="string">''</span>:</span><br><span class="line">            self.x, self.y = pag.position()</span><br><span class="line">            self.root.geometry(<span class="string">"+%d+%d"</span> % (self.x, self.y))</span><br><span class="line">        <span class="keyword">elif</span> src == <span class="string">'q'</span>:</span><br><span class="line">            sys.exit()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dst = baidu_traslate(src)[<span class="string">'dst'</span>]</span><br><span class="line">            <span class="comment"># print(dst)</span></span><br><span class="line">            self.ouput.delete(<span class="number">0</span>, <span class="string">'end'</span>)</span><br><span class="line">            self.ouput.insert(<span class="number">0</span>, dst)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, root=None)</span>:</span></span><br><span class="line">        self.root = root</span><br><span class="line">        self.root.wm_attributes(<span class="string">'-topmost'</span>, <span class="number">1</span>)</span><br><span class="line">        self.root.overrideredirect(<span class="keyword">True</span>)</span><br><span class="line">        self.root.geometry(<span class="string">"+%d+%d"</span> % (self.x, self.y))</span><br><span class="line">        Frame.__init__(self, self.root)</span><br><span class="line"></span><br><span class="line">        self.input = Entry(root)</span><br><span class="line">        self.input.bind(<span class="string">'&lt;Return&gt;'</span>, self.operate)</span><br><span class="line">        self.input.pack()</span><br><span class="line"></span><br><span class="line">        self.ouput = Entry(root)</span><br><span class="line">        self.ouput.pack()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root = MyWindow(Tk())</span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure><h1 id="关于打包"><a href="#关于打包" class="headerlink" title="关于打包"></a>关于打包</h1><p>第一次将python源代码打包为exe，用到的包是<code>pyinstaller</code>。用到的语句是</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyinstaller -F 源文件.py -w</span><br></pre></td></tr></table></figure><p>其中<code>-F</code>打包为一个exe文件，<code>-w</code>表示在运行的时候不需要dos界面。</p><p>需要注意的是即便是一个很小的程序，因为这个包会把所有python环境的包打包进来，就导致十分地累赘。正确的做法是在anaconda中新建一个纯净的环境，需要什么包就安装什么，然后再调用pyinstaller，这样该程序从300M下降到10M。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;嗯……不知道为啥脑残地写了这个极简的翻译器&lt;/p&gt;
&lt;h1 id=&quot;功能&quot;&gt;&lt;a href=&quot;#功能&quot; class=&quot;headerlink&quot; title=&quot;功能&quot;&gt;&lt;/a&gt;功能&lt;/h1&gt;&lt;p&gt;就是调用百度翻译的API了，输入框没有东西的时候按回车窗口跑到鼠标处，输入框里是q
      
    
    </summary>
    
      <category term="小程序" scheme="http://wang22ti.com/categories/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验4-线性分类器设计</title>
    <link href="http://wang22ti.com/2018/10/20/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C4-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>http://wang22ti.com/2018/10/20/《模式识别》实验4-线性分类器设计/</id>
    <published>2018-10-20T02:55:39.000Z</published>
    <updated>2018-11-12T09:25:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li><p>了解基于Fisher准则的线性分类器和基于感知准则的线性分类器的数学原理。</p></li><li><p>实现上述两种线性分类器的设计，加深对其原理的理解。</p></li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><ol><li><p>Fisher准则的基本思想是：对于两类问题，就是要找到一个最合适的投影轴，使两类样本在该轴上投影的交迭部分最少，从而使分类效果为最佳。故有基本参数：各类样本的均值向量$m _ { i } = \frac { 1 } { N _ { i } } \sum _ { \left\{ x \in X _ { i } \right\} } x$，样本类内离散度矩阵$\mathrm { S } _ { \mathrm { i } } = \sum _ { \left\{ x \in X _ { i } \right\} } \left( x - m _ { i } \right) \left( x - m _ { i } \right) ^ { T }$，总类内离散度矩阵$S _ { \mathrm { w } } = S _ { 1 } + S _ { 2 }$，样本间离散度矩阵$S _ { b } = \left( m _ { 1 } - m _ { 2 } \right) \left( m _ { 1 } - m _ { 2 } \right) ^ { T }$。则定义Fisher准则函数：$\mathrm { J } _ { \mathrm { F } } ( W ) = \frac { \left( \tilde { m } _ { 1 } - \tilde { m } _ { 2 } \right) ^ { 2 } } { \tilde { S } _ { 1 } ^ { 2 } + \tilde { S } _ { 2 } ^ { 2 } } , \tilde { m } _ { i } = w ^ { T } \mathrm { m } _ { \mathrm { i } } , \tilde { S } _ { i } ^ { 2 } = w ^ { T } S _ { i } w$，则有最优投影方向$\mathrm { W } ^ { * } = S _ { W } ^ { - 1 } \left( m _ { 1 } - m _ { 2 } \right)$，而一般$\mathrm { W } _ { 0 } = - \frac { \tilde { m } _ { 1 } - \tilde { m } _ { 2 } } { 2 }$。</p></li><li><p>定义感知准则函数$J ( a ) = \sum _ { \left\{ y \in y ^ { k } \right\} } - a ^ { T } y$，其中$y^k$为错分样本集合。因此对$a$求梯度有</p></li></ol><script type="math/tex; mode=display">\nabla \mathrm { J } = \frac { \partial J ( a ) } { \partial a } = \sum _ { \left\{ \mathrm { y } \in \mathrm { y } ^ { \mathrm { k } } \right\} } - y</script><p>​        所以有感知机迭代公式：</p><script type="math/tex; mode=display">a _ { K + 1 } = a _ { k } + \rho _ { k } \sum _ { \left\{ y \in y ^ { k } \right\} } y</script><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><ol><li><p>把数据作为样本，根据Fisher准则选择投影方向，使原样本向量在该方向上的投影能兼顾类间分布尽可能分开，类内样本投影尽可能密集的要求，求出评价投影方向$W$的函数，并在图形表示出来，并求使$J_F(W)$取极大值的$W^*$ 。用matlab完成Fisher线性分类器的设计。根据上述的结果并判断(1,1.5,0.6), (1.2,1.0,0.55), (2.0,0.9,0.68), (1.2,1.5,0.89), (0.23,2.33,1.43)，属于哪个类别，并画出数据分类相应的结果图，画出其在上的投影。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">x1 =[<span class="number">0.2331</span>    <span class="number">1.5207</span>    <span class="number">0.6499</span>    <span class="number">0.7757</span>    <span class="number">1.0524</span>    <span class="number">1.1974</span></span><br><span class="line">    <span class="number">0.2908</span>    <span class="number">0.2518</span>    <span class="number">0.6682</span>    <span class="number">0.5622</span>    <span class="number">0.9023</span>    <span class="number">0.1333</span></span><br><span class="line">    <span class="number">-0.5431</span>    <span class="number">0.9407</span>   <span class="number">-0.2126</span>    <span class="number">0.0507</span>   <span class="number">-0.0810</span>    <span class="number">0.7315</span></span><br><span class="line">    <span class="number">0.3345</span>    <span class="number">1.0650</span>   <span class="number">-0.0247</span>    <span class="number">0.1043</span>    <span class="number">0.3122</span>    <span class="number">0.6655</span></span><br><span class="line">    <span class="number">0.5838</span>    <span class="number">1.1653</span>    <span class="number">1.2653</span>    <span class="number">0.8137</span>   <span class="number">-0.3399</span>    <span class="number">0.5152</span></span><br><span class="line">    <span class="number">0.7226</span>   <span class="number">-0.2015</span>    <span class="number">0.4070</span>   <span class="number">-0.1717</span>   <span class="number">-1.0573</span>   <span class="number">-0.2099</span>];</span><br><span class="line">y1 =[<span class="number">2.3385</span>    <span class="number">2.1946</span>    <span class="number">1.6730</span>    <span class="number">1.6365</span>    <span class="number">1.7844</span>    <span class="number">2.0155</span></span><br><span class="line">    <span class="number">2.0681</span>    <span class="number">2.1213</span>    <span class="number">2.4797</span>    <span class="number">1.5118</span>    <span class="number">1.9692</span>    <span class="number">1.8340</span></span><br><span class="line">    <span class="number">1.8704</span>    <span class="number">2.2948</span>    <span class="number">1.7714</span>    <span class="number">2.3939</span>    <span class="number">1.5648</span>    <span class="number">1.9329</span></span><br><span class="line">    <span class="number">2.2027</span>    <span class="number">2.4568</span>    <span class="number">1.7523</span>    <span class="number">1.6991</span>    <span class="number">2.4883</span>    <span class="number">1.7259</span></span><br><span class="line">    <span class="number">2.0466</span>    <span class="number">2.0226</span>    <span class="number">2.3757</span>    <span class="number">1.7987</span>    <span class="number">2.0828</span>    <span class="number">2.0798</span></span><br><span class="line">    <span class="number">1.9449</span>    <span class="number">2.3801</span>    <span class="number">2.2373</span>    <span class="number">2.1614</span>    <span class="number">1.9235</span>    <span class="number">2.2604</span>];</span><br><span class="line">z1 =[<span class="number">0.5338</span>    <span class="number">0.8514</span>    <span class="number">1.0831</span>    <span class="number">0.4164</span>    <span class="number">1.1176</span>    <span class="number">0.5536</span></span><br><span class="line">    <span class="number">0.6071</span>    <span class="number">0.4439</span>    <span class="number">0.4928</span>    <span class="number">0.5901</span>    <span class="number">1.0927</span>    <span class="number">1.0756</span></span><br><span class="line">    <span class="number">1.0072</span>    <span class="number">0.4272</span>    <span class="number">0.4353</span>    <span class="number">0.9869</span>    <span class="number">0.4841</span>    <span class="number">1.0992</span></span><br><span class="line">    <span class="number">1.0299</span>    <span class="number">0.7127</span>    <span class="number">1.0124</span>    <span class="number">0.4576</span>    <span class="number">0.8544</span>    <span class="number">1.1275</span></span><br><span class="line">    <span class="number">0.7705</span>    <span class="number">0.4129</span>    <span class="number">1.0085</span>    <span class="number">0.7676</span>    <span class="number">0.8418</span>    <span class="number">0.8784</span></span><br><span class="line">    <span class="number">0.9751</span>    <span class="number">0.7840</span>    <span class="number">0.4158</span>    <span class="number">1.0315</span>    <span class="number">0.7533</span>    <span class="number">0.9548</span>];</span><br><span class="line"><span class="comment">%将x1、y1、z1变为列向量</span></span><br><span class="line">x1=x1(:);y1=y1(:);z1=z1(:);</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算第一类的样本均值向量m1</span></span><br><span class="line">m1(<span class="number">1</span>)=mean(x1);</span><br><span class="line">m1(<span class="number">2</span>)=mean(y1);</span><br><span class="line">m1(<span class="number">3</span>)=mean(z1);</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算第一类样本类内离散度矩阵S1，参考（4-17）</span></span><br><span class="line"></span><br><span class="line">S1=<span class="built_in">zeros</span>(<span class="number">3</span>,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">36</span></span><br><span class="line">    <span class="comment">%程序补充（1）</span></span><br><span class="line">    tmp = [x1(i)-m1(<span class="number">1</span>) y1(i)-m1(<span class="number">2</span>) z1(i)-m1(<span class="number">3</span>)]';</span><br><span class="line">    S1 = S1 + tmp * tmp';   </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%w2的数据点坐标</span></span><br><span class="line">x2 =[<span class="number">1.4010</span>    <span class="number">1.2301</span>    <span class="number">2.0814</span>    <span class="number">1.1655</span>    <span class="number">1.3740</span>    <span class="number">1.1829</span></span><br><span class="line">    <span class="number">1.7632</span>    <span class="number">1.9739</span>    <span class="number">2.4152</span>    <span class="number">2.5890</span>    <span class="number">2.8472</span>    <span class="number">1.9539</span></span><br><span class="line">    <span class="number">1.2500</span>    <span class="number">1.2864</span>    <span class="number">1.2614</span>    <span class="number">2.0071</span>    <span class="number">2.1831</span>    <span class="number">1.7909</span></span><br><span class="line">    <span class="number">1.3322</span>    <span class="number">1.1466</span>    <span class="number">1.7087</span>    <span class="number">1.5920</span>    <span class="number">2.9353</span>    <span class="number">1.4664</span></span><br><span class="line">    <span class="number">2.9313</span>    <span class="number">1.8349</span>    <span class="number">1.8340</span>    <span class="number">2.5096</span>    <span class="number">2.7198</span>    <span class="number">2.3148</span></span><br><span class="line">    <span class="number">2.0353</span>    <span class="number">2.6030</span>    <span class="number">1.2327</span>    <span class="number">2.1465</span>    <span class="number">1.5673</span>    <span class="number">2.9414</span>];</span><br><span class="line"></span><br><span class="line">y2 =[<span class="number">1.0298</span>    <span class="number">0.9611</span>    <span class="number">0.9154</span>    <span class="number">1.4901</span>    <span class="number">0.8200</span>    <span class="number">0.9399</span></span><br><span class="line">    <span class="number">1.1405</span>    <span class="number">1.0678</span>    <span class="number">0.8050</span>    <span class="number">1.2889</span>    <span class="number">1.4601</span>    <span class="number">1.4334</span></span><br><span class="line">    <span class="number">0.7091</span>    <span class="number">1.2942</span>    <span class="number">1.3744</span>    <span class="number">0.9387</span>    <span class="number">1.2266</span>    <span class="number">1.1833</span></span><br><span class="line">    <span class="number">0.8798</span>    <span class="number">0.5592</span>    <span class="number">0.5150</span>    <span class="number">0.9983</span>    <span class="number">0.9120</span>    <span class="number">0.7126</span></span><br><span class="line">    <span class="number">1.2833</span>    <span class="number">1.1029</span>    <span class="number">1.2680</span>    <span class="number">0.7140</span>    <span class="number">1.2446</span>    <span class="number">1.3392</span></span><br><span class="line">    <span class="number">1.1808</span>    <span class="number">0.5503</span>    <span class="number">1.4708</span>    <span class="number">1.1435</span>    <span class="number">0.7679</span>    <span class="number">1.1288</span>];</span><br><span class="line">z2 =[<span class="number">0.6210</span>    <span class="number">1.3656</span>    <span class="number">0.5498</span>    <span class="number">0.6708</span>    <span class="number">0.8932</span>    <span class="number">1.4342</span></span><br><span class="line">    <span class="number">0.9508</span>    <span class="number">0.7324</span>    <span class="number">0.5784</span>    <span class="number">1.4943</span>    <span class="number">1.0915</span>    <span class="number">0.7644</span></span><br><span class="line">    <span class="number">1.2159</span>    <span class="number">1.3049</span>    <span class="number">1.1408</span>    <span class="number">0.9398</span>    <span class="number">0.6197</span>    <span class="number">0.6603</span></span><br><span class="line">    <span class="number">1.3928</span>    <span class="number">1.4084</span>    <span class="number">0.6909</span>    <span class="number">0.8400</span>    <span class="number">0.5381</span>    <span class="number">1.3729</span></span><br><span class="line">    <span class="number">0.7731</span>    <span class="number">0.7319</span>    <span class="number">1.3439</span>    <span class="number">0.8142</span>    <span class="number">0.9586</span>    <span class="number">0.7379</span></span><br><span class="line">    <span class="number">0.7548</span>    <span class="number">0.7393</span>    <span class="number">0.6739</span>    <span class="number">0.8651</span>    <span class="number">1.3699</span>    <span class="number">1.1458</span>];</span><br><span class="line">x2=x2(:);</span><br><span class="line">y2=y2(:);</span><br><span class="line">z2=z2(:);</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算第二类的样本均值向量m2</span></span><br><span class="line">m2(<span class="number">1</span>)=mean(x2);</span><br><span class="line">m2(<span class="number">2</span>)=mean(y2);</span><br><span class="line">m2(<span class="number">3</span>)=mean(z2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算第二类样本类内离散度矩阵S2</span></span><br><span class="line"></span><br><span class="line">S2=<span class="built_in">zeros</span>(<span class="number">3</span>,<span class="number">3</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">36</span></span><br><span class="line">    <span class="comment">%程序补充（2）</span></span><br><span class="line">    tmp = [x2(i)-m2(<span class="number">1</span>) y2(i)-m2(<span class="number">2</span>) z2(i)-m2(<span class="number">3</span>)]';</span><br><span class="line">    S2 = S2 + tmp * tmp';  </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%总类内离散度矩阵Sw，参考（4-18）</span></span><br><span class="line"><span class="comment">%程序补充（3）</span></span><br><span class="line"></span><br><span class="line">Sw = S1 + S2;</span><br><span class="line"></span><br><span class="line"><span class="comment">%样本类间离散度矩阵Sb，参考（4-19）</span></span><br><span class="line">Sb=<span class="built_in">zeros</span>(<span class="number">3</span>,<span class="number">3</span>);</span><br><span class="line">Sb=(m1-m2)'*(m1-m2);</span><br><span class="line"></span><br><span class="line"><span class="comment">%最优解W</span></span><br><span class="line">W=Sw^<span class="number">-1</span>*(m1-m2)';   <span class="comment">%，参考（4-32）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%将W变为单位向量以方便计算投影</span></span><br><span class="line">W=W/<span class="built_in">sqrt</span>(sum(W.^<span class="number">2</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">%计算一维Y空间中的各类样本均值M1及M2</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">36</span></span><br><span class="line">    y(<span class="built_in">i</span>)=W'*[x1(i) y1(i) z1(i)]';</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">M1=mean(y);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">36</span></span><br><span class="line">    y(<span class="built_in">i</span>)=W'*[x2(i) y2(i) z2(i)]';</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">M2=mean(y);</span><br><span class="line"></span><br><span class="line">W0=-(M1+M2)/<span class="number">2</span>; <span class="comment">%参考（4-33）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%计算将样本投影到最佳方向上以后的新坐标</span></span><br><span class="line">X1=[x1*W(<span class="number">1</span>)+y1*W(<span class="number">2</span>)+z1*W(<span class="number">3</span>)]';</span><br><span class="line">X2=[x2*W(<span class="number">1</span>)+y2*W(<span class="number">2</span>)+z2*W(<span class="number">3</span>)]';   <span class="comment">%得到投影长度</span></span><br><span class="line">XX1=[W(<span class="number">1</span>)*X1;W(<span class="number">2</span>)*X1;W(<span class="number">3</span>)*X1];</span><br><span class="line">XX2=[W(<span class="number">1</span>)*X2;W(<span class="number">2</span>)*X2;W(<span class="number">3</span>)*X2];   <span class="comment">%得到新坐标</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%绘制样本点</span></span><br><span class="line">figure;</span><br><span class="line">h1=plot3(x1,y1,z1,<span class="string">'r*'</span>);   <span class="comment">%第一类(红色星号)</span></span><br><span class="line">hold on</span><br><span class="line">h2=plot3(x2,y2,z2,<span class="string">'gp'</span>) ;  <span class="comment">%第二类(绿色五角星)</span></span><br><span class="line">title(<span class="string">'Fisher线性判别曲线'</span>);</span><br><span class="line">W1=<span class="number">5</span>*W;     <span class="comment">%使画的线更长</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%判别已给点的类 </span></span><br><span class="line">a1=[<span class="number">1</span>,<span class="number">1.5</span>,<span class="number">0.6</span>]';a2=[<span class="number">1.2</span>,<span class="number">1.0</span>,<span class="number">0.55</span>]';a3=[<span class="number">2.0</span>,<span class="number">0.9</span>,<span class="number">0.68</span>]';a4=[<span class="number">1.2</span>,<span class="number">1.5</span>,<span class="number">0.89</span>]';a5=[<span class="number">0.23</span>,<span class="number">2.33</span>,<span class="number">1.43</span>]';</span><br><span class="line">A=[a1 a2 a3 a4 a5];</span><br><span class="line">n=<span class="built_in">size</span>(A,<span class="number">2</span>);                      </span><br><span class="line"><span class="comment">%下面代码在改变样本时可不修改</span></span><br><span class="line"><span class="comment">%绘制待测数据投影到最佳方向上的点</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:n</span><br><span class="line">    A1=A(:,k)'*W;   <span class="comment">%得到投影长度</span></span><br><span class="line">    A11=W*A1;   <span class="comment">%得到待测数据投影新坐标</span></span><br><span class="line">    y=W'*A(:,k)+W0;    <span class="comment">%计算后与0相比以判断类别，大于0为第一类，小于0为第二类            </span></span><br><span class="line">    <span class="keyword">if</span> y&gt;<span class="number">0</span></span><br><span class="line">        h3=plot3(A(<span class="number">1</span>,k),A(<span class="number">2</span>,k),A(<span class="number">3</span>,k),<span class="string">'ro'</span>);   <span class="comment">%点为"ro"对应第一类(红色圆圈)</span></span><br><span class="line">        h3=plot3(A11(<span class="number">1</span>),A11(<span class="number">2</span>),A11(<span class="number">3</span>),<span class="string">'ro'</span>);  <span class="comment">%投影为"ro"对应第一类</span></span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        h4=plot3(A(<span class="number">1</span>,k),A(<span class="number">2</span>,k),A(<span class="number">3</span>,k),<span class="string">'bh'</span>);   <span class="comment">%点为"ch"对应第二类(蓝色六角星)</span></span><br><span class="line">        h4=plot3(A11(<span class="number">1</span>),A11(<span class="number">2</span>),A11(<span class="number">3</span>),<span class="string">'bh'</span>);  <span class="comment">%投影为"ch"对应第二类</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">legend([h1,h2,h3,h4],<span class="string">'第一类样本点'</span>,<span class="string">'第二类样本点'</span>,<span class="string">'属于第一类的点'</span>,<span class="string">'属于第二类的点'</span>);</span><br><span class="line"><span class="comment">%画出最佳方向 </span></span><br><span class="line">line([-W1(<span class="number">1</span>),W1(<span class="number">1</span>)],[-W1(<span class="number">2</span>),W1(<span class="number">2</span>)],[-W1(<span class="number">3</span>),W1(<span class="number">3</span>)],<span class="string">'color'</span>,<span class="string">'k'</span>); </span><br><span class="line">view([<span class="number">-37.5</span>,<span class="number">30</span>]);   <span class="comment">%设置视点的函数view(方位角,仰角)</span></span><br><span class="line">axis([<span class="number">-2</span>,<span class="number">3</span>,<span class="number">-1</span>,<span class="number">3</span>,<span class="number">-0.5</span>,<span class="number">1.5</span>]); <span class="comment">%设置坐标轴可见范围</span></span><br><span class="line">grid on</span><br><span class="line">hold off</span><br></pre></td></tr></table></figure></li><li><p>实验所用样本数据如表1给出（其中每个数据为两维， x1表示第一维的值、x2表示第二维的值），编程实现y1、y2类，和y2、y3类的分类。分析分类器算法的性能，写出实现感知器算法的程序，具体要求：1、将程序应用在y1和y2的训练数据上。记下收敛的步数。2、将程序应用在y2和y3类上，同样记下收敛的步数。</p></li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line"><span class="comment">%original data</span></span><br><span class="line"><span class="comment">%产生第一类、第二类和第三类原始数据，分别赋给w1、w2 和w3 变量</span></span><br><span class="line">w1=[<span class="number">0.1</span> <span class="number">6.8</span> <span class="number">-3.5</span> <span class="number">2.0</span> <span class="number">4.1</span> <span class="number">3.1</span> <span class="number">-0.8</span> <span class="number">0.9</span> <span class="number">5.0</span> <span class="number">3.9</span>;<span class="number">1.1</span> <span class="number">7.1</span> <span class="number">-4.1</span> <span class="number">2.7</span> <span class="number">2.8</span> <span class="number">5.0</span> <span class="number">-1.3</span> <span class="number">1.2</span> <span class="number">6.4</span> <span class="number">4.0</span>];</span><br><span class="line">w2=[<span class="number">7.1</span> <span class="number">-1.4</span> <span class="number">4.5</span> <span class="number">6.3</span> <span class="number">4.2</span> <span class="number">1.4</span> <span class="number">2.4</span> <span class="number">2.5</span> <span class="number">8.4</span> <span class="number">4.1</span>;<span class="number">4.2</span> <span class="number">-4.3</span> <span class="number">0.0</span> <span class="number">1.6</span> <span class="number">1.9</span> <span class="number">-3.2</span> <span class="number">-4.0</span> <span class="number">-6.1</span> <span class="number">3.7</span> <span class="number">-2.2</span>];</span><br><span class="line">w3=[<span class="number">-3.0</span> <span class="number">0.5</span> <span class="number">2.9</span> <span class="number">-0.1</span> <span class="number">-4.0</span> <span class="number">-1.3</span> <span class="number">-3.4</span> <span class="number">-4.1</span> <span class="number">-5.1</span> <span class="number">1.9</span>;<span class="number">-2.9</span> <span class="number">8.7</span> <span class="number">2.1</span> <span class="number">5.2</span> <span class="number">2.2</span> <span class="number">3.7</span> <span class="number">6.2</span> <span class="number">3.4</span> <span class="number">1.6</span> <span class="number">5.1</span>];</span><br><span class="line"><span class="comment">%normalized</span></span><br><span class="line"><span class="comment">%分别产生第一类、第二类和第三类增广样本向量集ww1、ww2 和ww3</span></span><br><span class="line">ww1=[ones(<span class="number">1</span>,size(w1,<span class="number">2</span>)); w1];</span><br><span class="line">ww2=[ones(<span class="number">1</span>,size(w2,<span class="number">2</span>)); w2];</span><br><span class="line">ww3=[ones(<span class="number">1</span>,size(w3,<span class="number">2</span>)); w3];</span><br><span class="line"><span class="comment">%产生第一类和第二类样本向量的规范化增广样本向量集w12</span></span><br><span class="line">w12=[ww1,-ww2];<span class="comment">%4-42</span></span><br><span class="line"><span class="comment">%%w13=[ww1,-ww3];</span></span><br><span class="line"><span class="comment">%%w23=[ww2,-ww3];</span></span><br><span class="line">y=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">size</span>(w12,<span class="number">2</span>)); <span class="comment">%产生1x20 的行向量，赋给y，初值全为0</span></span><br><span class="line">v=[<span class="number">1</span>;<span class="number">1</span>;<span class="number">1</span>]; <span class="comment">%给权向量v 赋初值</span></span><br><span class="line">k=<span class="number">0</span>; <span class="comment">%k 为迭代次数，v(0)= [1;1;1]</span></span><br><span class="line"><span class="keyword">while</span> any(y&lt;=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(y,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">%补充程序(1)</span></span><br><span class="line">        y(<span class="built_in">i</span>) = v'*w12(:,<span class="built_in">i</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="comment">%补充程序(2)</span></span><br><span class="line">    v = v+(sum( (w12(:,<span class="built_in">find</span>(y&lt;<span class="number">0</span>)))'))'</span><br><span class="line">    k=k+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">v <span class="comment">%显示最终求得的权向量v 的值</span></span><br><span class="line">k <span class="comment">%迭代次数值</span></span><br><span class="line">figure(<span class="number">1</span>)</span><br><span class="line">plot(w1(<span class="number">1</span>,:),w1(<span class="number">2</span>,:),<span class="string">'r.'</span>)</span><br><span class="line">hold on</span><br><span class="line">plot(w2(<span class="number">1</span>,:),w2(<span class="number">2</span>,:),<span class="string">'b*'</span>)</span><br><span class="line">xmin=min(min(w1(<span class="number">1</span>,:)),min(w2(<span class="number">1</span>,:)));</span><br><span class="line">xmax=max(max(w1(<span class="number">1</span>,:)),max(w2(<span class="number">1</span>,:)));</span><br><span class="line">ymin=min(min(w1(<span class="number">2</span>,:)),min(w2(<span class="number">2</span>,:)));</span><br><span class="line">ymax=max(max(w1(<span class="number">2</span>,:)),max(w2(<span class="number">2</span>,:)));</span><br><span class="line">xindex=xmin<span class="number">-1</span>:(xmax-xmin)/<span class="number">100</span>:xmax+<span class="number">1</span>;</span><br><span class="line">yindex=-v(<span class="number">2</span>)*xindex/v(<span class="number">3</span>)-v(<span class="number">1</span>)/v(<span class="number">3</span>); <span class="comment">%由v*xindex=0推，参考书上（4-44）</span></span><br><span class="line">plot(xindex,yindex)</span><br><span class="line"></span><br><span class="line"><span class="comment">%从v=0 开始，将程序应用在ω2 和ω3 类上，同样记下收敛的步数。</span></span><br><span class="line">w23=[ww2,-ww3];</span><br><span class="line">yy=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="built_in">size</span>(w23,<span class="number">2</span>)); <span class="comment">%产生1x20 的行向量，赋给y，初值全为0</span></span><br><span class="line">vv=[<span class="number">1</span>;<span class="number">1</span>;<span class="number">1</span>]; <span class="comment">%给权向量v 赋初值</span></span><br><span class="line">kk=<span class="number">0</span>; <span class="comment">%k 为迭代次数，v(0)= [1;1;1]</span></span><br><span class="line"><span class="keyword">while</span> any(yy&lt;=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">size</span>(yy,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">%补充程序(3)</span></span><br><span class="line">        yy(<span class="built_in">i</span>) = vv'*w23(:,<span class="built_in">i</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="comment">%补充程序(4)</span></span><br><span class="line">    vv = vv+(sum( (w23(:,<span class="built_in">find</span>(yy&lt;<span class="number">0</span>)))'))'</span><br><span class="line">    kk=kk+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">vv <span class="comment">%显示最终求得的权向量v 的值</span></span><br><span class="line">kk <span class="comment">%迭代次数值</span></span><br><span class="line">figure(<span class="number">2</span>)</span><br><span class="line">plot(w2(<span class="number">1</span>,:),w2(<span class="number">2</span>,:),<span class="string">'r.'</span>)</span><br><span class="line">hold on</span><br><span class="line">plot(w3(<span class="number">1</span>,:),w3(<span class="number">2</span>,:),<span class="string">'b*'</span>)</span><br><span class="line">xxmin=min(min(w2(<span class="number">1</span>,:)),min(w3(<span class="number">1</span>,:)));</span><br><span class="line">xxmax=max(max(w2(<span class="number">1</span>,:)),max(w3(<span class="number">1</span>,:)));</span><br><span class="line">yymin=min(min(w2(<span class="number">2</span>,:)),min(w3(<span class="number">2</span>,:)));</span><br><span class="line">yymax=max(max(w2(<span class="number">2</span>,:)),max(w3(<span class="number">2</span>,:)));</span><br><span class="line">xxindex=xmin<span class="number">-1</span>:(xxmax-xxmin)/<span class="number">100</span>:xxmax+<span class="number">1</span>;</span><br><span class="line">yyindex=-vv(<span class="number">2</span>)*xxindex/vv(<span class="number">3</span>)-vv(<span class="number">1</span>)/vv(<span class="number">3</span>);</span><br><span class="line">plot(xxindex,yyindex);</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><ol><li>Fisher准则的线性分类器如下图所示，其中5个点有2个被分为第一类，剩下3个被分为第二类。</li></ol><p><img src="/2018/10/20/《模式识别》实验4-线性分类器设计/1.png" alt=""></p><ol><li><p>两次分类结果如下图所示，其中y1和y2的分类在28轮收敛，其中y2和y3的分类在23轮收敛。</p><p><img src="/2018/10/20/《模式识别》实验4-线性分类器设计/2.png" alt=""></p><p><img src="/2018/10/20/《模式识别》实验4-线性分类器设计/3.png" alt=""></p></li></ol><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>​        本次实验聚焦于线性分类器的设计，通过实践完成基于Fisher准则和基于感知准则的两个线性分类器的设计，我真正领会了其数学原理，进一步加深了对它们的理解，这必将有利于我进一步的学习。值得注意的是，本次所使用的数据均线性可分，对于线性不可分以及高维数据的情况，需要进一步讨论。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;了解基于Fisher准则的线性分类器和基于感知准则的线性分类器的数学原理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;
      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验3-概率密度函数估计</title>
    <link href="http://wang22ti.com/2018/10/20/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C3-%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E4%BC%B0%E8%AE%A1/"/>
    <id>http://wang22ti.com/2018/10/20/《模式识别》实验3-概率密度函数估计/</id>
    <published>2018-10-20T02:55:03.000Z</published>
    <updated>2018-11-12T08:36:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li><p>了解常用的概率密度函数估计的方法：参数估计法和非参数估计法，其中后者包括parzen窗和Kn近邻两种方法。</p></li><li><p>掌握正态分布的参数估计的两种求解方法：极大似然估计和贝叶斯估计。</p></li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>对于正态分布的极大似然估计，有</p><script type="math/tex; mode=display">\mathrm { P } ( \mathrm { x } ; \mu , \sigma ) = \frac { 1 } { \sqrt { 2 \pi } \sigma } e ^ { - \frac { ( x - \mu ) ^ { 2 } } { 2 \sigma ^ { 2 } } }</script><p>当有多个独立同分布的样本之后有</p><script type="math/tex; mode=display">\mathrm { P } ( \mathbf { x } ; \mu , \sigma ) = \prod _ { i = 1 } ^ { N } \frac { 1 } { \sqrt { 2 \pi } \sigma } e ^ { - \frac { \left( x _ { i } - \mu \right) ^ { 2 } } { 2 \sigma ^ { 2 } } } = \frac { 1 } { ( 2 \pi \sigma ) ^ { \frac { N } { 2 } } } e ^ { \sum _ { i = 1 } ^ { N } - \frac { \left( x _ { i } - \mu \right) ^ { 2 } } { 2 \sigma ^ { 2 } } }</script><p>两边取对数有</p><script type="math/tex; mode=display">\ln \mathrm { P } ( \mathbf { x } ; \mu , \sigma ) = - \frac { N } { 2 } \ln 2 \pi \sigma + \sum _ { i = 1 } ^ { N } - \frac { \left( x _ { i } - \mu \right) ^ { 2 } } { 2 \sigma ^ { 2 } }</script><p>求导有</p><script type="math/tex; mode=display">\hat { \mu } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } x _ { i } , \quad \hat { \Sigma } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } ( x - \hat { \mu } ) ( x - \hat { \mu } ) ^ { T }</script><h2 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h2><p>在贝叶斯估计中，参数也是随机变量，则有 </p><script type="math/tex; mode=display">\hat { \mu } = \frac { \sigma _ { 0 } ^ { 2 } } { N \sigma _ { 0 } ^ { 2 } + \sigma ^ { 2 } } \sum _ { i = 1 } ^ { N } x _ { i } + \frac { \sigma _ { 0 } ^ { 2 } } { N \sigma _ { 0 } ^ { 2 } + \sigma ^ { 2 } } \mu _ { 0 } , \quad \widehat { \sigma ^ { 2 } } = \frac { \sigma _ { 0 } ^ { 2 } \sigma ^ { 2 } } { N \sigma _ { 0 } ^ { 2 } + \sigma ^ { 2 } }</script><p>其中$\mu$的先验概率服从$\mathrm { N } \left( \mu _ { 0 } , \sigma _ { 0 } ^ { 2 } \right)$，总体分布密度服从$\mathrm { N } \left( \mu , \sigma ^ { 2 } \right)$</p><h2 id="非参数估计"><a href="#非参数估计" class="headerlink" title="非参数估计"></a>非参数估计</h2><p>在非参数估计中有</p><script type="math/tex; mode=display">\hat { p } ( x ) = \frac { k } { V N }</script><p>其中$N$为样本总数，$V$为区域体积，$K$为落入区域的样本数，同时有</p><script type="math/tex; mode=display">\mathrm { k } = \sum _ { i = 1 } ^ { N } \varphi \left( \frac { \left| x - x _ { i } \right| } { h } \right)</script><p>其中$h$为窗口长度，$\varphi$为判别是否在区域内的函数。如果区域太小，则概率密度函数不连续；如果区域太大，则概率密度函数不准确。所以要选取恰当的区域体积，Parzen窗口法令</p><script type="math/tex; mode=display">\mathrm { V } = \frac { h } { \sqrt { N } }</script><p>其中$h$为常数。在K近邻法则令</p><script type="math/tex; mode=display">\mathrm { K } = \mathrm { k } \sqrt { N }</script><p>选取合适的$V$使得区域恰好包含K个近邻。</p><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><h2 id="极大似然估计-1"><a href="#极大似然估计-1" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>利用最大似然参数估计方法计算单变量正态分布情况下的参数：均值$\mu$和方差$\sigma^2$，并利用MATLAB画出给出的样本数据和求得的概率密度函数；样本数据：x={0.42 -0.2 1.3 0.39 -1.6 0.029 -0.23 0.27 -1.9 0.87}</p><h3 id="sd-mle-m"><a href="#sd-mle-m" class="headerlink" title="sd_mle.m"></a>sd_mle.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[u, s]</span>=<span class="title">sd_mle</span><span class="params">(x)</span></span></span><br><span class="line"><span class="comment">%单维样本的最大似然估计（3-24，3-25</span></span><br><span class="line">len=<span class="built_in">numel</span>(x);           <span class="comment">%求数据个数N</span></span><br><span class="line">u=sum(x)/len;           <span class="comment">%求均值的估计</span></span><br><span class="line">s=sum((x-u)'*(x-u))/len;     <span class="comment">%求方差的估计</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="ztsr-m"><a href="#ztsr-m" class="headerlink" title="ztsr.m"></a>ztsr.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">w1=[<span class="number">0.42</span> <span class="number">-0.2</span> <span class="number">1.3</span> <span class="number">0.39</span> <span class="number">-1.6</span> <span class="number">-0.029</span> <span class="number">-0.23</span> <span class="number">0.27</span> <span class="number">-1.9</span> <span class="number">0.87</span>]';</span><br><span class="line"><span class="comment">%--------问题a---------</span></span><br><span class="line"><span class="comment">%类别w1中特征1的最大似然估计</span></span><br><span class="line">[u1, s]=sd_mle(w1); <span class="comment">%最大似然估计</span></span><br><span class="line"><span class="built_in">disp</span>(u1);</span><br><span class="line"><span class="built_in">disp</span>(s);</span><br><span class="line"><span class="comment">%画出采样数据</span></span><br><span class="line">figure;</span><br><span class="line">hold on;</span><br><span class="line"><span class="built_in">i</span>(<span class="number">1</span>:<span class="number">10</span>,<span class="number">1</span>)=<span class="number">0.2</span>;</span><br><span class="line">scatter(w1,<span class="built_in">i</span>,<span class="string">'ob'</span>); <span class="comment">%画点函数</span></span><br><span class="line"><span class="built_in">j</span>=<span class="built_in">linspace</span>(<span class="number">-0.1</span>,<span class="number">0.6</span>,<span class="number">100</span>);</span><br><span class="line"><span class="comment">%画出估计值线</span></span><br><span class="line">plot(u1,<span class="built_in">j</span>,<span class="string">'-b'</span>);</span><br><span class="line"><span class="comment">%画出正态曲线</span></span><br><span class="line">x=<span class="built_in">linspace</span>(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">200</span>);</span><br><span class="line">y=<span class="number">1</span> /(<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>*s))*<span class="built_in">exp</span>(-(x-u1).^<span class="number">2</span>/(<span class="number">2</span>*s));</span><br><span class="line">plot(x,y,<span class="string">'g'</span>);</span><br><span class="line">title(<span class="string">'一维正态最大似然参数估计'</span>);</span><br><span class="line">grid on;</span><br><span class="line">hold off;</span><br></pre></td></tr></table></figure><h2 id="贝叶斯估计-1"><a href="#贝叶斯估计-1" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h2><p>利用贝叶斯参数估计的方法计算一维正态概率密度函数的参数均值$\mu$，并利MATLAB函数画出样本数据和估计出的概率密度函数图。样本数据：x={0.42 -0.2 1.3 0.39 -1.6 0.029 -0.23 0.27 -1.9 0.87}。概率密度函数的方差：s=0.9062；均值的$\mu$先验分布也是正态分布，参数$\mu _ { 0 } = - 0.0709 , \sigma _ { 0 } ^ { 2 } = 1$。</p><h3 id="ubeyes-m"><a href="#ubeyes-m" class="headerlink" title="ubeyes.m"></a>ubeyes.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[u,ss]</span>=<span class="title">ubeyes</span><span class="params">(x,s,u0,s0)</span></span></span><br><span class="line">N=<span class="built_in">numel</span>(x);</span><br><span class="line">u=s0 * sum(x) / (N*s0+s) + s*u0/(N*s0+s);</span><br><span class="line">ss=s*s0/(N*s0+s);</span><br></pre></td></tr></table></figure><h3 id="beyes-m"><a href="#beyes-m" class="headerlink" title="beyes.m"></a>beyes.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%一维正态的贝叶斯参数估计，均值u是待估计参数，方差s已知</span></span><br><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line"><span class="comment">%w2为观测数据</span></span><br><span class="line">w2=[<span class="number">0.42</span> <span class="number">-0.2</span> <span class="number">1.3</span> <span class="number">0.39</span> <span class="number">-1.6</span> <span class="number">-0.029</span> <span class="number">-0.23</span> <span class="number">0.27</span> <span class="number">-1.9</span> <span class="number">0.87</span>]';</span><br><span class="line">s=<span class="number">0.9062</span>; <span class="comment">%样本概率密度函数的方差已知</span></span><br><span class="line">u0=<span class="number">-0.0709</span>;s0=<span class="number">1</span>;  <span class="comment">%均值u的先验分布也是正态分布，均值，方差已知</span></span><br><span class="line">[u,ss]=ubeyes(w2,s,u0,s0); <span class="comment">%ss 为估计均值后的方差变化</span></span><br><span class="line"><span class="comment">%画出采样数据</span></span><br><span class="line">figure;</span><br><span class="line"><span class="built_in">i</span>(<span class="number">1</span>:<span class="number">10</span>,<span class="number">1</span>)=<span class="number">0.2</span>;</span><br><span class="line">scatter(w2,<span class="built_in">i</span>);  <span class="comment">%画线函数</span></span><br><span class="line">hold on;</span><br><span class="line"><span class="comment">%画出正态曲线</span></span><br><span class="line">x=<span class="built_in">linspace</span>(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">200</span>);</span><br><span class="line">y1=<span class="number">1.</span>/(<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>*s))*<span class="built_in">exp</span>(-(x-u).^<span class="number">2</span>/(<span class="number">2</span>*s));</span><br><span class="line">y2=<span class="number">1.</span>/(<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>*(s+ss)))*<span class="built_in">exp</span>(-(x-u).^<span class="number">2</span>/(<span class="number">2</span>*(s+ss)));</span><br><span class="line">plot(x,y1,<span class="string">'r'</span>); <span class="comment">%红色线是确定的方差下的概率密度函数</span></span><br><span class="line">plot(x,y2,<span class="string">'g'</span>); <span class="comment">%青色线是估计后变化了的方差下的概率密度函数</span></span><br><span class="line">legend(<span class="string">'样本数据'</span>,<span class="string">'确定方差下的概率密度函数'</span>,<span class="string">'变化了的方差下的概率密度函数'</span>);</span><br><span class="line"><span class="built_in">j</span>=<span class="built_in">linspace</span>(<span class="number">-0.1</span>,<span class="number">0.6</span>,<span class="number">100</span>);</span><br><span class="line"><span class="comment">%画出估计值线</span></span><br><span class="line">plot(u,<span class="built_in">j</span>,<span class="string">'r'</span>);</span><br><span class="line">title(<span class="string">'贝叶斯'</span>);</span><br><span class="line">grid on;</span><br><span class="line">hold off;</span><br></pre></td></tr></table></figure><h2 id="Parzen窗法"><a href="#Parzen窗法" class="headerlink" title="Parzen窗法"></a>Parzen窗法</h2><p>利用Parzen窗法，估计单一正态分布和两个均匀分布，样本数N分别为1、16、256、 无穷大，用一个比较大的数据代替，窗口宽度分别为：0.25、1、4，画出实验结果图。实验代码如下</p><h3 id="Parzen-m"><a href="#Parzen-m" class="headerlink" title="Parzen.m"></a>Parzen.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span> = <span class="title">Parzen</span><span class="params">(x, X, h1, N)</span>  % <span class="title">x</span>为横坐标; <span class="title">X</span>为样本; <span class="title">h1</span>用来调节窗宽<span class="title">h</span>; <span class="title">N</span>为样本个数. </span></span><br><span class="line"><span class="comment">% Parzen窗口法的原理实现</span></span><br><span class="line">h = h1/<span class="built_in">sqrt</span>(N);                    <span class="comment">% (1) h为窗宽.</span></span><br><span class="line">Kn = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="number">100</span>); </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:N </span><br><span class="line">Kn = Kn +  normpdf((x-X(<span class="built_in">i</span>))/h);   <span class="comment">% (2) 用正态窗函数作Parzen窗估计,计算落入Vn内的样本数</span></span><br><span class="line"><span class="keyword">end</span>                     <span class="comment">% normpdf：正态概率密度函数</span></span><br><span class="line">p = Kn/(h*N);                    <span class="comment">% (3) 密度估计</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="myparzen01-m"><a href="#myparzen01-m" class="headerlink" title="myparzen01.m"></a>myparzen01.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%%%%%% Parzen窗口法估计标准正态分布实验 %%%%%%</span></span><br><span class="line">clc;</span><br><span class="line">close all;</span><br><span class="line">clear all;</span><br><span class="line">M = <span class="number">128</span>^<span class="number">2</span>;    <span class="comment">%调整M的值可以改进精度   </span></span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>); <span class="comment">%功能：用于产生-3,3之间的100点行线性的矢量。</span></span><br><span class="line">X = <span class="built_in">randn</span>(M, <span class="number">1</span>); <span class="comment">%产生标准正态分布</span></span><br><span class="line">figure;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">1</span>);     </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>);plot(x, p);title(<span class="string">'N =1, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]);grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">1</span>);        </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>);plot(x, p);title(<span class="string">'N =1, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, <span class="number">1</span>);        </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">3</span>);plot(x, p);title(<span class="string">'N =1, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">16</span>);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>);plot(x, p);title(<span class="string">'N =16, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">16</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>);plot(x, p);title(<span class="string">'N =16, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, <span class="number">16</span>);       </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">6</span>);plot(x, p);title(<span class="string">'N =16, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">256</span>);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">7</span>);plot(x, p);title(<span class="string">'N =256, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">256</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>);plot(x, p);title(<span class="string">'N =256, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>,<span class="number">256</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">9</span>);plot(x, p);title(<span class="string">'N =256, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, M);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">10</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, M);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">11</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, M);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">12</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">grid on;</span><br></pre></td></tr></table></figure><h3 id="myparzen02-m"><a href="#myparzen02-m" class="headerlink" title="myparzen02.m"></a>myparzen02.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%%%%%% Parzen窗口法估计两个均匀分布实验 %%%%%%</span></span><br><span class="line">clc;</span><br><span class="line">close all;</span><br><span class="line">clear all;</span><br><span class="line">M = <span class="number">128</span>^<span class="number">2</span>;    <span class="comment">%调整M的值可以改进精度   </span></span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>); <span class="comment">%功能：用于产生-3,3之间的100点行线性的矢量。</span></span><br><span class="line">n = M;</span><br><span class="line"><span class="built_in">i</span>=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">i</span> &lt;= n <span class="comment">%产生均匀分布双峰概密随机数，x分布在-2.5到-2之间概率为0.5，x分布在0到2之间概率为0.5；</span></span><br><span class="line">    R(<span class="built_in">i</span>)=<span class="built_in">rand</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> R(<span class="built_in">i</span>)&gt;<span class="number">0.5</span></span><br><span class="line">        p(<span class="number">1</span>,<span class="built_in">i</span>)=<span class="number">2</span>*<span class="built_in">rand</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">elseif</span> R(<span class="built_in">i</span>)&lt;<span class="number">0.5</span></span><br><span class="line">        p(<span class="number">1</span>,<span class="built_in">i</span>)=<span class="number">0.5</span>*<span class="built_in">rand</span>(<span class="number">1</span>)<span class="number">-2.5</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        null;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="built_in">i</span>=<span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">X=p;</span><br><span class="line">figure;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">1</span>);     </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>);plot(x, p);title(<span class="string">'N =1, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]);grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">1</span>);        </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>);plot(x, p);title(<span class="string">'N =1, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, <span class="number">1</span>);        </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">3</span>);plot(x, p);title(<span class="string">'N =1, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">16</span>);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>);plot(x, p);title(<span class="string">'N =16, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">16</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>);plot(x, p);title(<span class="string">'N =16, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, <span class="number">16</span>);       </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">6</span>);plot(x, p);title(<span class="string">'N =16, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line"></span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, <span class="number">256</span>);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">7</span>);plot(x, p);title(<span class="string">'N =256, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, <span class="number">256</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">8</span>);plot(x, p);title(<span class="string">'N =256, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>,<span class="number">256</span>);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">9</span>);plot(x, p);title(<span class="string">'N =256, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">0.25</span>, M);   </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">10</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 0.25'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">1</span>, M);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">11</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 1'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">p = Parzen(x, X, <span class="number">4</span>, M);      </span><br><span class="line">subplot(<span class="number">4</span>,<span class="number">3</span>,<span class="number">12</span>);plot(x, p);title(<span class="string">'N =128^2, h1 = 4'</span>);axis([<span class="number">-3</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>]); grid on;</span><br><span class="line">grid on;</span><br></pre></td></tr></table></figure><h2 id="Kn近邻法"><a href="#Kn近邻法" class="headerlink" title="Kn近邻法"></a>Kn近邻法</h2><p>利用Kn近邻法，估计单一正态分布和两个均匀分布，样本数N分别为1、16、256、 无穷大，用一个比较大的数据代替，画出实验结果图。</p><h3 id="knjl01-m"><a href="#knjl01-m" class="headerlink" title="knjl01.m"></a>knjl01.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span>=<span class="title">knjl01</span><span class="params">(x,N)</span> </span></span><br><span class="line"><span class="comment">% 根据Kn近邻法对下列四处代码补全</span></span><br><span class="line">xb=<span class="built_in">randn</span>(N,<span class="number">1</span>);<span class="comment">%产生标准正态分布</span></span><br><span class="line"><span class="comment">%Kn近邻法的原理实现</span></span><br><span class="line">Kn=<span class="built_in">sqrt</span>(N);                         <span class="comment">% (1) 计算Kn</span></span><br><span class="line">p=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">100</span>  </span><br><span class="line">    d=sort(<span class="built_in">abs</span>(xb-x(<span class="built_in">j</span>)));      <span class="comment">% (2) 用当前所处位置的x值减去样本点的值，并对其绝对值按升序排序</span></span><br><span class="line">    Vn=d(<span class="built_in">ceil</span>(Kn)) * <span class="number">2</span>;                     <span class="comment">%（3）计算包含kn个样本点所需的体积</span></span><br><span class="line">    p(<span class="built_in">j</span>)=Kn/(N * Vn);                   <span class="comment">%（4）计算该位置的密度</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="myjl01-m"><a href="#myjl01-m" class="headerlink" title="myjl01.m"></a>myjl01.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%%%%%% Kn近邻法估计标准正态分布实验 %%%%%%</span></span><br><span class="line">clc;  </span><br><span class="line">clear all; </span><br><span class="line">close all; </span><br><span class="line">x=<span class="built_in">linspace</span>(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">100</span>); </span><br><span class="line">N=<span class="number">1</span>;  </span><br><span class="line">p1=knjl01(x,N);  </span><br><span class="line">figure;</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>),plot(x,p1); </span><br><span class="line">title(<span class="string">'N=1'</span>); </span><br><span class="line">N=<span class="number">16</span>;  </span><br><span class="line">p2=knjl01(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>),plot(x,p2); </span><br><span class="line">title(<span class="string">'N=16'</span>); </span><br><span class="line">N=<span class="number">256</span>;  </span><br><span class="line">p3=knjl01(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>);plot(x,p3); </span><br><span class="line">title(<span class="string">'N=256'</span>); </span><br><span class="line">N=<span class="number">128</span>^<span class="number">2</span>;  </span><br><span class="line">p4=knjl01(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>);plot(x,p4); </span><br><span class="line">title(<span class="string">'N=128^2'</span>);</span><br></pre></td></tr></table></figure><h3 id="knjl02-m"><a href="#knjl02-m" class="headerlink" title="knjl02.m"></a>knjl02.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">p</span>=<span class="title">knjl02</span><span class="params">(x,N)</span> </span></span><br><span class="line"><span class="comment">% 根据Kn近邻法对下列四处代码补全</span></span><br><span class="line">xb=<span class="built_in">zeros</span>(N,<span class="number">1</span>);</span><br><span class="line">n=N; </span><br><span class="line"><span class="built_in">i</span>=<span class="number">1</span>;  </span><br><span class="line"><span class="keyword">while</span> <span class="built_in">i</span>&lt;=n <span class="comment">%产生均匀分布双峰概密随机数，x分布在-2.5到-2之间的概率为0.5;x分布在0到2之间的概率为0.5 </span></span><br><span class="line">    R(<span class="built_in">i</span>)=<span class="built_in">rand</span>(<span class="number">1</span>); </span><br><span class="line">    <span class="keyword">if</span> R(<span class="built_in">i</span>)&gt;<span class="number">0.5</span>  </span><br><span class="line">        q(<span class="number">1</span>,<span class="built_in">i</span>)= <span class="number">2</span>*<span class="built_in">rand</span>(<span class="number">1</span>);                <span class="comment">%概率密度函数变后，改动这里</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        q(<span class="number">1</span>,<span class="built_in">i</span>)= <span class="number">0.5</span>*<span class="built_in">rand</span>() <span class="number">-2.5</span>;                 <span class="comment">%概率密度函数变化后，改动这里 </span></span><br><span class="line">    <span class="keyword">end</span> </span><br><span class="line">    <span class="built_in">i</span>=<span class="built_in">i</span>+<span class="number">1</span>; </span><br><span class="line"><span class="keyword">end</span> </span><br><span class="line">xb=q; </span><br><span class="line"><span class="comment">%Kn近邻法的原理实现</span></span><br><span class="line">Kn=<span class="built_in">sqrt</span>(N);                         <span class="comment">% (1) 计算Kn</span></span><br><span class="line">p=<span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">100</span>); </span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">100</span>  </span><br><span class="line">    d=sort(<span class="built_in">abs</span>(xb-x(<span class="built_in">j</span>)));      <span class="comment">% (2) 用当前所处位置的x值减去样本点的值，并对其绝对值按升序排序</span></span><br><span class="line">    Vn=d(<span class="built_in">ceil</span>(Kn)) * <span class="number">2</span>;                     <span class="comment">%（3）计算包含kn个样本点所需的体积</span></span><br><span class="line">    p(<span class="built_in">j</span>)=Kn/(N * Vn);                   <span class="comment">%（4）计算该位置的密度</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="myjl02-m"><a href="#myjl02-m" class="headerlink" title="myjl02.m"></a>myjl02.m</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%%%%%% Kn近邻法估计两个均匀分布实验 %%%%%%</span></span><br><span class="line">clc;  </span><br><span class="line">clear all; </span><br><span class="line">close all; </span><br><span class="line">x=<span class="built_in">linspace</span>(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">100</span>); </span><br><span class="line">N=<span class="number">1</span>;  </span><br><span class="line">p1=knjl02(x,N);  </span><br><span class="line">figure;</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>),plot(x,p1); </span><br><span class="line">title(<span class="string">'N=1'</span>); </span><br><span class="line">N=<span class="number">16</span>;  </span><br><span class="line">p2=knjl02(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>),plot(x,p2); </span><br><span class="line">title(<span class="string">'N=16'</span>); </span><br><span class="line">N=<span class="number">256</span>;  </span><br><span class="line">p3=knjl02(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>);plot(x,p3); </span><br><span class="line">title(<span class="string">'N=256'</span>); </span><br><span class="line">N=<span class="number">128</span>^<span class="number">2</span>;  </span><br><span class="line">p4=knjl02(x,N);  </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>);plot(x,p4); </span><br><span class="line">title(<span class="string">'N=128^2'</span>);</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><h2 id="极大似然估计-2"><a href="#极大似然估计-2" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>正态分布的极大似然估计的结果如下图所示</p><p><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/1.png" alt=""></p><h2 id="贝叶斯估计-2"><a href="#贝叶斯估计-2" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h2><p>正态分布的贝叶斯估计的结果如下图所示<br><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/2.png" alt=""></p><h2 id="Parzen窗法-1"><a href="#Parzen窗法-1" class="headerlink" title="Parzen窗法"></a>Parzen窗法</h2><p>在不同样本数量和不同窗口长度情况下，Parzen窗的实验结果如下，前者是正态分布，后者是分段函数。</p><p><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/3.png" alt=""></p><p><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/4.png" alt=""></p><h2 id="Kn近邻法-1"><a href="#Kn近邻法-1" class="headerlink" title="Kn近邻法"></a>Kn近邻法</h2><p>K近邻的实验结果如下，前者是正态分布，后者是分段函数。</p><p><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/5.png" alt=""></p><p><img src="/2018/10/20/《模式识别》实验3-概率密度函数估计/6.png" alt=""></p><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>​        本次实验聚焦于概率密度估计，通过实践完成参数估计的极大似然估计、贝叶斯估计，以及非参数估计的Parzen窗方法和K近邻方法，我真正领会了其数学原理，进一步加深了对它们的理解，这必将有利于我进一步的学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;了解常用的概率密度函数估计的方法：参数估计法和非参数估计法，其中后者包括parzen窗和Kn近邻两种方法。
      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>《人工智能》作业集</title>
    <link href="http://wang22ti.com/2018/10/20/%E3%80%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E3%80%8B%E4%BD%9C%E4%B8%9A%E9%9B%86/"/>
    <id>http://wang22ti.com/2018/10/20/《人工智能》作业集/</id>
    <published>2018-10-20T02:54:01.000Z</published>
    <updated>2018-11-13T03:19:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>虽然王公仆老师布置的作业和考试并没有直接关系，但是实事求是的说，王老师《人工智能》课程的内容还是比较科学合理，能够勾起大家学习兴趣的。以下便是历次作业题及其解答。</p><h1 id="用遗传算法求解旅行商问题"><a href="#用遗传算法求解旅行商问题" class="headerlink" title="用遗传算法求解旅行商问题"></a>用遗传算法求解旅行商问题</h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/1-1.png" alt=""></p><h2 id="源代码1"><a href="#源代码1" class="headerlink" title="源代码1"></a>源代码1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(x1, x2, y1, y2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> ((x1 - x2) ** <span class="number">2</span> + (y1 - y2) ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sample</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_cost</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.cost = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, s <span class="keyword">in</span> enumerate(self.sample):</span><br><span class="line">            j = np.argmax(s)</span><br><span class="line">            self.cost += self.distances[i][j]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">check_sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        now = np.argmax(self.sample[<span class="number">0</span>])</span><br><span class="line">        num_check = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> now != <span class="number">0</span>:</span><br><span class="line">            now = np.argmax(self.sample[now])</span><br><span class="line">            num_check += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span> <span class="keyword">if</span> num_check == self.num_points <span class="keyword">else</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_points, distances)</span>:</span></span><br><span class="line">        self.num_points = num_points</span><br><span class="line">        self.distances = distances</span><br><span class="line">        self.sample = np.eye(num_points)</span><br><span class="line">        <span class="keyword">while</span> self.check_sample() <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">            i, j = [random.randint(<span class="number">0</span>, self.num_points - <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">            self.sample[[i, j], :] = self.sample[[j, i], :]</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        i, j = [random.randint(<span class="number">0</span>, self.num_points - <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">        self.sample[[i, j], :] = self.sample[[j, i], :]</span><br><span class="line">        <span class="keyword">while</span> self.check_sample() <span class="keyword">is</span> <span class="keyword">False</span>:</span><br><span class="line">            i, j = [random.randint(<span class="number">0</span>, self.num_points - <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">            self.sample[[i, j], :] = self.sample[[j, i], :]</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Samples</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, y, num_samples=<span class="number">100</span>)</span>:</span></span><br><span class="line">        self.inf = <span class="number">1000</span></span><br><span class="line">        self.x, self.y, self.num_samples = x, y, num_samples</span><br><span class="line">        self.num_points = len(self.x)</span><br><span class="line">        self.points = list(zip(self.x, self.y))</span><br><span class="line">        self.distances = np.array([</span><br><span class="line">            [distance(point1[<span class="number">0</span>], point2[<span class="number">0</span>], point1[<span class="number">1</span>], point2[<span class="number">1</span>]) <span class="keyword">if</span> point1 != point2 <span class="keyword">else</span> self.inf <span class="keyword">for</span> point2 <span class="keyword">in</span></span><br><span class="line">             self.points]</span><br><span class="line">            <span class="keyword">for</span> point1 <span class="keyword">in</span> self.points</span><br><span class="line">        ])</span><br><span class="line">        self.samples = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.num_samples):</span><br><span class="line">            self.samples.append(Sample(self.num_points, self.distances))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, num_iterator=<span class="number">300</span>, rate_kill=<span class="number">0.05</span>, rate_change=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        num_kill = int(rate_kill * self.num_samples)</span><br><span class="line">        num_live = self.num_samples - num_kill</span><br><span class="line">        num_change = int(rate_change * self.num_samples)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_iterator):</span><br><span class="line">            self.samples = self.samples[:num_live]</span><br><span class="line">            <span class="keyword">for</span> __ <span class="keyword">in</span> range(num_kill):</span><br><span class="line">                self.samples.append(deepcopy(self.samples[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(num_change):</span><br><span class="line">                self.samples[random.randint(<span class="number">0</span>, self.num_samples - <span class="number">1</span>)].change_sample()</span><br><span class="line"></span><br><span class="line">            self.samples.sort(key=<span class="keyword">lambda</span> s: s.cost)</span><br><span class="line">            <span class="comment"># print(_, self.samples[0].cost)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_result</span><span class="params">(self)</span>:</span></span><br><span class="line">        best_sample = self.samples[<span class="number">0</span>]</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.scatter(self.x, self.y)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(self.x, self.y):</span><br><span class="line">            plt.text(x, y, (x, y), fontdict=&#123;<span class="string">'size'</span>: <span class="number">16</span>, <span class="string">'color'</span>: <span class="string">'r'</span>&#125;)</span><br><span class="line">        print(<span class="string">'least cost: '</span>, best_sample.cost)</span><br><span class="line">        <span class="keyword">for</span> i, point <span class="keyword">in</span> enumerate(best_sample.sample):</span><br><span class="line">            j = np.argmax(point)</span><br><span class="line">            plt.plot([self.x[i], self.x[j]], [self.y[i], self.y[j]])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">points_x = [<span class="number">40</span>, <span class="number">24</span>, <span class="number">17</span>, <span class="number">22</span>, <span class="number">51</span>, <span class="number">87</span>, <span class="number">68</span>, <span class="number">84</span>, <span class="number">66</span>, <span class="number">61</span>, ]</span><br><span class="line">points_y = [<span class="number">44</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">76</span>, <span class="number">94</span>, <span class="number">65</span>, <span class="number">52</span>, <span class="number">36</span>, <span class="number">25</span>, <span class="number">26</span>, ]</span><br><span class="line">s = Samples(points_x, points_y)</span><br><span class="line">s.train()</span><br><span class="line">s.show_result()</span><br></pre></td></tr></table></figure><h2 id="源代码2"><a href="#源代码2" class="headerlink" title="源代码2"></a>源代码2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(x1, x2, y1, y2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> ((x1 - x2) ** <span class="number">2</span> + (y1 - y2) ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认从index为0的点出发</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sample</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_cost</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.cost = self.distances[<span class="number">0</span>][self.sample[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.sample) - <span class="number">1</span>):</span><br><span class="line">            a, b = self.sample[i], self.sample[i + <span class="number">1</span>]</span><br><span class="line">            self.cost += self.distances[a][b]</span><br><span class="line">        self.cost += self.distances[self.sample[<span class="number">-1</span>]][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_points, distances)</span>:</span></span><br><span class="line">        self.num_points = num_points</span><br><span class="line">        self.distances = distances</span><br><span class="line">        self.sample = list(range(<span class="number">1</span>, self.num_points))</span><br><span class="line">        random.shuffle(self.sample)</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        i, j = [random.randint(<span class="number">0</span>, len(self.sample) - <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">        self.sample[i], self.sample[j] = self.sample[j], self.sample[i]</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Samples</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, y, num_samples=<span class="number">100</span>)</span>:</span></span><br><span class="line">        self.inf = <span class="number">1000</span></span><br><span class="line">        self.x, self.y, self.num_samples = x, y, num_samples</span><br><span class="line">        self.num_points = len(self.x)</span><br><span class="line">        self.points = list(zip(self.x, self.y))</span><br><span class="line">        self.distances = np.array([</span><br><span class="line">            [distance(point1[<span class="number">0</span>], point2[<span class="number">0</span>], point1[<span class="number">1</span>], point2[<span class="number">1</span>]) <span class="keyword">if</span> point1 != point2 <span class="keyword">else</span> self.inf <span class="keyword">for</span> point2 <span class="keyword">in</span></span><br><span class="line">             self.points]</span><br><span class="line">            <span class="keyword">for</span> point1 <span class="keyword">in</span> self.points</span><br><span class="line">        ])</span><br><span class="line">        self.samples = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.num_samples):</span><br><span class="line">            self.samples.append(Sample(self.num_points, self.distances))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, num_iterator=<span class="number">1000</span>, rate_kill=<span class="number">0.05</span>, rate_change=<span class="number">0.3</span>)</span>:</span></span><br><span class="line">        num_kill = int(rate_kill * self.num_samples)</span><br><span class="line">        num_live = self.num_samples - num_kill</span><br><span class="line">        num_change = int(rate_change * self.num_samples)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_iterator):</span><br><span class="line">            self.samples = self.samples[:num_live]</span><br><span class="line">            <span class="keyword">for</span> __ <span class="keyword">in</span> range(num_kill):</span><br><span class="line">                self.samples.append(deepcopy(self.samples[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(num_change):</span><br><span class="line">                self.samples[random.randint(<span class="number">0</span>, self.num_samples - <span class="number">1</span>)].change_sample()</span><br><span class="line"></span><br><span class="line">            self.samples.sort(key=<span class="keyword">lambda</span> s: s.cost)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_result</span><span class="params">(self)</span>:</span></span><br><span class="line">        best_sample = self.samples[<span class="number">0</span>]</span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.scatter(self.x, self.y)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(self.x, self.y):</span><br><span class="line">            plt.text(x, y, (x, y), fontdict=&#123;<span class="string">'size'</span>: <span class="number">16</span>, <span class="string">'color'</span>: <span class="string">'r'</span>&#125;)</span><br><span class="line">        print(<span class="string">'least cost: '</span>, best_sample.cost)</span><br><span class="line">        plt.plot([self.x[<span class="number">0</span>], self.x[best_sample.sample[<span class="number">0</span>]]], [self.y[<span class="number">0</span>], self.y[best_sample.sample[<span class="number">0</span>]]])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(best_sample.sample)<span class="number">-1</span>):</span><br><span class="line">            a, b = best_sample.sample[i], best_sample.sample[i+<span class="number">1</span>]</span><br><span class="line">            plt.plot([self.x[a], self.x[b]], [self.y[a], self.y[b]])</span><br><span class="line">        plt.plot([self.x[<span class="number">0</span>], self.x[best_sample.sample[<span class="number">-1</span>]]], [self.y[<span class="number">0</span>], self.y[best_sample.sample[<span class="number">-1</span>]]])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">points_x = [<span class="number">40</span>, <span class="number">24</span>, <span class="number">17</span>, <span class="number">22</span>, <span class="number">51</span>, <span class="number">87</span>, <span class="number">68</span>, <span class="number">84</span>, <span class="number">66</span>, <span class="number">61</span>, ]</span><br><span class="line">points_y = [<span class="number">44</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">76</span>, <span class="number">94</span>, <span class="number">65</span>, <span class="number">52</span>, <span class="number">36</span>, <span class="number">25</span>, <span class="number">26</span>, ]</span><br><span class="line">s = Samples(points_x, points_y)</span><br><span class="line">s.train()</span><br><span class="line">s.show_result()</span><br></pre></td></tr></table></figure><h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><p><img src="/2018/10/20/《人工智能》作业集/1-2.png" alt=""></p><h1 id="一个简单的估计问题"><a href="#一个简单的估计问题" class="headerlink" title="一个简单的估计问题"></a>一个简单的估计问题</h1><h2 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/2-1.png" alt=""></p><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_samples</span><span class="params">(N=<span class="number">1000</span>, mean=<span class="number">0</span>, sigma=<span class="number">1</span>, A=<span class="number">5</span>)</span>:</span></span><br><span class="line">    np.random.seed(int(time.time()))</span><br><span class="line">    w = np.random.normal(mean, sigma, N)</span><br><span class="line">    x = A + w</span><br><span class="line">    hat_A = np.array([x[:k+<span class="number">1</span>].mean() <span class="keyword">for</span> k <span class="keyword">in</span> range(N)])</span><br><span class="line">    var_hat_A = [hat_A[:k+<span class="number">1</span>].var() <span class="keyword">for</span> k <span class="keyword">in</span> range(N)]</span><br><span class="line">    plt.scatter(range(<span class="number">1</span>, N+<span class="number">1</span>), var_hat_A, s=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">m, n = <span class="number">5</span>, <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        plt.subplot(m, n, m * i + j + <span class="number">1</span>)</span><br><span class="line">        plot_samples()</span><br><span class="line">        time.sleep(np.random.randint(<span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="运行结果-1"><a href="#运行结果-1" class="headerlink" title="运行结果"></a>运行结果</h2><p><img src="/2018/10/20/《人工智能》作业集/2-2.png" alt=""></p><h1 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h1><h2 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/3-1.png" alt=""></p><h2 id="观看视频"><a href="#观看视频" class="headerlink" title="观看视频"></a>观看视频</h2><p>随着数字图像的爆炸式增长，计算机视觉的发展已经成为必要。然而图像在计算机中的存储只是一堆矩阵，这让计算机理解图片变得很困难。传统的算法直接告诉计算机目标的特征，但是并不具有泛化能力，目标的形变、遮挡等等变化就会让算法完全失效。通过对于孩子认识物体过程的深入分析，李飞飞意识到问题不来自于算法，而来自于数据量。所以她领导开发了超大高质量数据集ImageNet；同时得益于硬件的发展，训练深度卷积神经网络，很快完成了图片中物体的识别，并进一步得到一个可以指出图片中物体简单关系的模型。模型还有3个可以改进的重点：一是防止对已经学习目标的过拟合，二是对没有相关训练集目标的识别，三是可以进一步提高模型的智力水平。</p><h2 id="阅读论文"><a href="#阅读论文" class="headerlink" title="阅读论文"></a>阅读论文</h2><p>传统的机器学习方法的局限性在于需要足够的工程技巧和领域专家的专业知识才能设计好的特征提取器。深度学习是表示学习的一种，通过逐级组装简单但是非线性的部件，并使用通用训练算法，由低级向高级自动提取特征。其中的非线性部件是指非线性激活函数，例如Relu、双曲正切函数、sigmoid函数，通用训练算法是指反向传播算法，归根到底是链式求导法则的一种应用。现在最常见的激活函数是Relu，因为它收敛的速度总是比sigmoid快；人们曾经担心反向传播算法容易陷入局部最小点，但实际上基本都是鞍点。</p><p>卷积神经网络是神经网络的一种，在计算机视觉领域有着很多应用，和全连接神经网络相比更加容易训练且更加具有泛化能力。其中，卷积层可以利用相邻值之间的关联性，还可以处理平移不变性；池化层是将相似的特征归为一类。</p><p>循环神经网络是另一种神经网络，对于序列数据处理的表现要好于卷积神经网络，比如在自然语言处理领域的文本预测、机器翻译。循环神经网络可以被看作非常深的前馈网络，其中所有层共享相同的权重，虽然这样设计的目的在于学习长期的依赖关系，但实际上并没有。解决这一问题的是LSTM（long short-term memory），其中加了一个连接到自己的“记忆细胞”，由其他单元学习到的乘法门控决定是否要将该值传入下一层。</p><p>未来的深度学习，非监督学习可能会更重要，计算机视觉系统会将卷积神经网络和带有强化学习的循环神经网络相结合，循环神经网络会广泛应用于自然语言处理。最终，人工智能的重大进步将来自表示学习和复杂推理的结合。</p><h1 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h1><h2 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/4-1.jpg" alt=""></p><h2 id="源代码-1"><a href="#源代码-1" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(x1, x2, y1, y2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> ((x1 - x2) ** <span class="number">2</span> + (y1 - y2) ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">points_x = [<span class="number">40</span>, <span class="number">24</span>, <span class="number">17</span>, <span class="number">22</span>, <span class="number">51</span>, <span class="number">87</span>, <span class="number">68</span>, <span class="number">84</span>, <span class="number">66</span>, <span class="number">61</span>, ]</span><br><span class="line">points_y = [<span class="number">44</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">76</span>, <span class="number">94</span>, <span class="number">65</span>, <span class="number">52</span>, <span class="number">36</span>, <span class="number">25</span>, <span class="number">26</span>, ]</span><br><span class="line">points = list(zip(points_x, points_y))</span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">colors = [<span class="string">'r'</span>, <span class="string">'g'</span>, <span class="string">'b'</span>]</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">m, n = <span class="number">3</span>, <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        results = &#123;point: <span class="number">-1</span> <span class="keyword">for</span> point <span class="keyword">in</span> points&#125;</span><br><span class="line">        centers = np.array([list(points[random.randint(<span class="number">0</span>, len(points_x) - <span class="number">1</span>)]) <span class="keyword">for</span> _ <span class="keyword">in</span> range(k)])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">            temp_x, temp_y = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> range(k)], [[] <span class="keyword">for</span> _ <span class="keyword">in</span> range(k)]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">                distances_to_center = [distance(point[<span class="number">0</span>], center[<span class="number">0</span>], point[<span class="number">1</span>], center[<span class="number">1</span>]) <span class="keyword">for</span> center <span class="keyword">in</span> centers]</span><br><span class="line">                c = np.argmin(distances_to_center)</span><br><span class="line">                results[point] = c</span><br><span class="line">                temp_x[c].append(point[<span class="number">0</span>])</span><br><span class="line">                temp_y[c].append(point[<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> range(k):</span><br><span class="line">                centers[c][<span class="number">0</span>] = np.mean(temp_x[c])</span><br><span class="line">                centers[c][<span class="number">1</span>] = np.mean(temp_y[c])</span><br><span class="line"></span><br><span class="line">        plt.subplot(m, n, i * m + j + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> c, center <span class="keyword">in</span> enumerate(centers):</span><br><span class="line">            plt.scatter(center[<span class="number">0</span>], center[<span class="number">1</span>], c=colors[c], marker=<span class="string">'^'</span>, s=<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(points_x, points_y):</span><br><span class="line">            plt.scatter(x, y, c=colors[results[x, y]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="运行结果-2"><a href="#运行结果-2" class="headerlink" title="运行结果"></a>运行结果</h2><p>因为是随机选取初始中心点，所以每次分类结果并不相同。所以分别在k=2和k=3的前提下进行9次聚类，结果如下图所示，其中三角形表示聚类中心。</p><h3 id="K-2"><a href="#K-2" class="headerlink" title="K=2"></a>K=2</h3><p><img src="/2018/10/20/《人工智能》作业集/4-2.png" alt=""></p><h3 id="K-3"><a href="#K-3" class="headerlink" title="K=3"></a>K=3</h3><p><img src="/2018/10/20/《人工智能》作业集/4-3.png" alt=""></p><h1 id="二叉树的先序遍历与BFS"><a href="#二叉树的先序遍历与BFS" class="headerlink" title="二叉树的先序遍历与BFS"></a>二叉树的先序遍历与BFS</h1><h2 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/5-1.jpg" alt=""></p><h2 id="源代码-2"><a href="#源代码-2" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value)</span>:</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = <span class="keyword">None</span></span><br><span class="line">        self.right = <span class="keyword">None</span></span><br><span class="line">        self.visited = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, root_value)</span>:</span></span><br><span class="line">        self.root = Node(root_value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_order_traverse_recursion</span><span class="params">(self, node)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        print(node.value, end=<span class="string">' '</span>)</span><br><span class="line">        self.pre_order_traverse_recursion(node.left)</span><br><span class="line">        self.pre_order_traverse_recursion(node.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pre_order_traverse</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'pre_order_traverse:'</span>)</span><br><span class="line">        self.pre_order_traverse_recursion(self.root)</span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'bfs:'</span>)</span><br><span class="line">        queue = [self.root, ]</span><br><span class="line">        <span class="keyword">while</span> len(queue) &gt; <span class="number">0</span>:</span><br><span class="line">            now = queue.pop(<span class="number">0</span>)</span><br><span class="line">            print(now.value, end=<span class="string">' '</span>)</span><br><span class="line">            <span class="keyword">if</span> now.left:</span><br><span class="line">                queue.append(now.left)</span><br><span class="line">            <span class="keyword">if</span> now.right:</span><br><span class="line">                queue.append(now.right)</span><br><span class="line">        print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tree = BinaryTree(<span class="string">'A'</span>)</span><br><span class="line">tree.root.left = Node(<span class="string">'B'</span>)</span><br><span class="line">tree.root.right = Node(<span class="string">'C'</span>)</span><br><span class="line">tree.root.left.left = Node(<span class="string">'D'</span>)</span><br><span class="line">tree.root.left.right = Node(<span class="string">'E'</span>)</span><br><span class="line">tree.root.right.left = Node(<span class="string">'F'</span>)</span><br><span class="line">tree.root.right.right = Node(<span class="string">'G'</span>)</span><br><span class="line">tree.root.left.left.left = Node(<span class="string">'H'</span>)</span><br><span class="line">tree.root.right.left.left = Node(<span class="string">'I'</span>)</span><br><span class="line">tree.root.right.right.right = Node(<span class="string">'J'</span>)</span><br><span class="line">tree.root.left.left.left.right = Node(<span class="string">'K'</span>)</span><br><span class="line"></span><br><span class="line">tree.pre_order_traverse()</span><br><span class="line">tree.bfs()</span><br></pre></td></tr></table></figure><h1 id="最大矩阵和"><a href="#最大矩阵和" class="headerlink" title="最大矩阵和"></a>最大矩阵和</h1><h2 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/6-1.jpg" alt=""></p><h2 id="源程序"><a href="#源程序" class="headerlink" title="源程序"></a>源程序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_in_row</span><span class="params">(row)</span>:</span></span><br><span class="line">    max_num = <span class="number">0</span></span><br><span class="line">    temp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> row:</span><br><span class="line">        <span class="keyword">if</span> num &gt;= <span class="number">0</span>:</span><br><span class="line">            temp += num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> temp &gt; max_num:</span><br><span class="line">                max_num = temp</span><br><span class="line">            temp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> max_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_in_matrix</span><span class="params">(matrix)</span>:</span></span><br><span class="line">    num_row = matrix.shape[<span class="number">0</span>]</span><br><span class="line">    max_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_row):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, num_row+<span class="number">1</span>):</span><br><span class="line">            max_num = max(max_num, max_in_row(np.sum(matrix[i:j, :], axis=<span class="number">0</span>)))</span><br><span class="line">    <span class="keyword">return</span> max_num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = int(input())</span><br><span class="line">matrix = np.array([[int(num) <span class="keyword">for</span> num <span class="keyword">in</span> input().split(<span class="string">' '</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)])</span><br><span class="line">print(matrix)</span><br><span class="line">print(max_in_matrix(matrix))</span><br></pre></td></tr></table></figure><h1 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h1><h2 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/7-1.png" alt=""></p><p><img src="/2018/10/20/《人工智能》作业集/7-2.png" alt=""></p><h2 id="源代码-3"><a href="#源代码-3" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">x1 = np.random.uniform(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">10000</span>)</span><br><span class="line">x2 = np.random.uniform(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">10000</span>)</span><br><span class="line">z = x1 + x2</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sns.kdeplot(z, shade=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">z = sum([np.random.uniform(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">10000</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>)])</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">sns.kdeplot(z, shade=<span class="keyword">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="运行结果-3"><a href="#运行结果-3" class="headerlink" title="运行结果"></a>运行结果</h2><p><img src="/2018/10/20/《人工智能》作业集/7-3.png" alt=""></p><h1 id="推导二元正态后验概率"><a href="#推导二元正态后验概率" class="headerlink" title="推导二元正态后验概率"></a>推导二元正态后验概率</h1><h2 id="题目-7"><a href="#题目-7" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/8-1.png" alt=""></p><h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p>  <img src="/2018/10/20/《人工智能》作业集/8-2.png" alt=""></p><h1 id="寻找最优解"><a href="#寻找最优解" class="headerlink" title="寻找最优解"></a>寻找最优解</h1><h2 id="题目-8"><a href="#题目-8" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/9-1.png" alt=""></p><p><img src="/2018/10/20/《人工智能》作业集/9-2.png" alt=""></p><h2 id="源代码-4"><a href="#源代码-4" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(num)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> <span class="keyword">if</span> abs(num - <span class="number">10</span>) &lt; abs(num + <span class="number">10</span>) <span class="keyword">else</span> <span class="number">-10</span></span><br><span class="line"></span><br><span class="line">h0, h1 = <span class="number">0.2</span>, <span class="number">0.1</span></span><br><span class="line">H = np.array([</span><br><span class="line">    [h0, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [h1, h0, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, h1, h0, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, h1, h0, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, h1, h0, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, h1, h0],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, h1],</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 穷举法</span></span><br><span class="line">min_error = []</span><br><span class="line"><span class="comment"># one by one detection</span></span><br><span class="line">error_list = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    s = np.array([random.choice([<span class="number">-10</span>, <span class="number">10</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">6</span>)]).T</span><br><span class="line">    w = np.random.normal(size=<span class="number">7</span>).T</span><br><span class="line">    y = np.dot(H, s) + w</span><br><span class="line">    <span class="comment"># 穷举法</span></span><br><span class="line">    error = float(<span class="string">'Inf'</span>)</span><br><span class="line">    <span class="keyword">for</span> s0 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">        <span class="keyword">for</span> s1 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">            <span class="keyword">for</span> s2 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">                <span class="keyword">for</span> s3 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">                    <span class="keyword">for</span> s4 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">                        <span class="keyword">for</span> s5 <span class="keyword">in</span> [<span class="number">-10</span>, <span class="number">10</span>]:</span><br><span class="line">                            s_hat = np.array([s0, s1, s2, s3, s4, s5])</span><br><span class="line">                            e = y - np.dot(H, s_hat)</span><br><span class="line">                            new_error = np.dot(e, e.T)</span><br><span class="line">                            error = min(new_error, error)</span><br><span class="line">    min_error.append(error)</span><br><span class="line">    <span class="comment"># one by one detection</span></span><br><span class="line">    s_hat = [f((y[<span class="number">0</span>] - w[<span class="number">0</span>]) / h0), ]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        new_s_hat = f((y[i] - h1 * s_hat[<span class="number">-1</span>] - w[i]) / h0)</span><br><span class="line">        s_hat.append(new_s_hat)</span><br><span class="line">    e = y - np.dot(H, s_hat)</span><br><span class="line">    error_list.append(np.dot(e, e.T))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">e1 = sum(min_error) / len(min_error)</span><br><span class="line">e2 = sum(error_list)/len(error_list)</span><br><span class="line">print(e1, e2)</span><br></pre></td></tr></table></figure><h2 id="运行结果-4"><a href="#运行结果-4" class="headerlink" title="运行结果"></a>运行结果</h2><p>显然E[e1]是大于E[e2]，显然穷举法得到的对于s的估计是最优的，one by one的方法，虽然有较高的error，但是显然速度较快。</p><h1 id="alpha-beta-剪枝法"><a href="#alpha-beta-剪枝法" class="headerlink" title="$\alpha-\beta$剪枝法"></a>$\alpha-\beta$剪枝法</h1><h2 id="题目与求解"><a href="#题目与求解" class="headerlink" title="题目与求解"></a>题目与求解</h2><p><img src="/2018/10/20/《人工智能》作业集/10-1.png" alt=""></p><h1 id="爬山算法与模拟剪枝算法"><a href="#爬山算法与模拟剪枝算法" class="headerlink" title="爬山算法与模拟剪枝算法"></a>爬山算法与模拟剪枝算法</h1><h2 id="题目-9"><a href="#题目-9" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/11-2.png" alt=""></p><h2 id="源代码-5"><a href="#源代码-5" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * np.e ** ((-x ** <span class="number">2</span> - y ** <span class="number">2</span>) / <span class="number">8</span>) + np.e ** (-(x - <span class="number">4</span>) ** <span class="number">2</span>) + np.e ** (-((x + <span class="number">4</span>) ** <span class="number">2</span> + (y - <span class="number">4</span>) ** <span class="number">2</span>) / <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">min_n, max_n = <span class="number">-10</span>, <span class="number">10</span></span><br><span class="line">_inf = <span class="number">0</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">X = np.linspace(min_n, max_n, <span class="number">100</span>)</span><br><span class="line">Y = np.linspace(min_n, max_n, <span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = f(X, Y)</span><br><span class="line">ax.plot_wireframe(X, Y, Z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬山算法</span></span><br><span class="line">x, y = np.random.uniform(min_n, max_n, <span class="number">2</span>)</span><br><span class="line">delta = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    ax.scatter(x, y, f(x, y), c=<span class="string">'r'</span>)</span><br><span class="line"></span><br><span class="line">    values = list()  <span class="comment"># 中，上，下，左，右</span></span><br><span class="line">    values.append(f(x, y))</span><br><span class="line">    values.append(f(x, y + delta) <span class="keyword">if</span> y + delta &lt; max_n <span class="keyword">else</span> _inf)</span><br><span class="line">    values.append(f(x, y - delta) <span class="keyword">if</span> y - delta &gt; min_n <span class="keyword">else</span> _inf)</span><br><span class="line">    values.append(f(x - delta, y) <span class="keyword">if</span> x - delta &gt; min_n <span class="keyword">else</span> _inf)</span><br><span class="line">    values.append(f(x + delta, y) <span class="keyword">if</span> x + delta &lt; max_n <span class="keyword">else</span> _inf)</span><br><span class="line">    max_index = np.argmax(values)</span><br><span class="line">    <span class="keyword">if</span> max_index == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> max_index == <span class="number">1</span>:</span><br><span class="line">        y += delta</span><br><span class="line">    <span class="keyword">elif</span> max_index == <span class="number">2</span>:</span><br><span class="line">        y -= delta</span><br><span class="line">    <span class="keyword">elif</span> max_index == <span class="number">3</span>:</span><br><span class="line">        x -= delta</span><br><span class="line">    <span class="keyword">elif</span> max_index == <span class="number">4</span>:</span><br><span class="line">        x += delta</span><br><span class="line">ax.text(x, y, f(x, y), str((x, y, f(x, y))))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟退火</span></span><br><span class="line">x, y = np.random.uniform(min_n, max_n, <span class="number">2</span>)</span><br><span class="line">E_now = f(x, y)</span><br><span class="line">Tk, T0, Tf, r = <span class="number">10</span>, <span class="number">10</span>, <span class="number">0.001</span>, <span class="number">0.95</span></span><br><span class="line">n_Tk = <span class="number">3</span></span><br><span class="line"><span class="keyword">while</span> Tk &gt; Tf:</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_Tk):</span><br><span class="line">        x_delta = np.random.uniform(min_n - x, max_n - x)</span><br><span class="line">        y_delta = np.random.uniform(min_n - y, max_n - y)</span><br><span class="line">        E_new = f(x + x_delta, y + y_delta)</span><br><span class="line">        <span class="comment"># 值变大,一定接受</span></span><br><span class="line">        <span class="keyword">if</span> E_new &gt; E_now:</span><br><span class="line">            ax.plot((x, x + x_delta), (y, y + y_delta), (E_now, E_new), c=<span class="string">'g'</span>)</span><br><span class="line">            E_now = E_new</span><br><span class="line">            x += x_delta</span><br><span class="line">            y += y_delta</span><br><span class="line">        <span class="comment"># 值变小,有一定概率接受</span></span><br><span class="line">        <span class="keyword">elif</span> np.e ** ((E_new - E_now) / Tk) &gt; np.random.uniform(<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">                ax.plot((x, x + x_delta), (y, y + y_delta), (E_now, E_new), c=<span class="string">'g'</span>)</span><br><span class="line">                E_now = E_new</span><br><span class="line">                x += x_delta</span><br><span class="line">                y += y_delta</span><br><span class="line">    <span class="comment"># 更新温度</span></span><br><span class="line">    Tk *= r</span><br><span class="line">ax.text(x, y, E_now, str((x, y, E_now)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="运行结果-5"><a href="#运行结果-5" class="headerlink" title="运行结果"></a>运行结果</h2><p>爬山算法总是能更快地落入极大点，但很容易是局部最大点。模拟退火虽然有时候会走弯路，但只要参数适当，总能接近全局最大点。如下图所示，红色为爬山路径，绿色为模拟退火路径。</p><p><img src="/2018/10/20/《人工智能》作业集/11-1.jpg" alt=""></p><p><img src="/2018/10/20/《人工智能》作业集/11-3.jpg" alt=""></p><h1 id="模拟退火算法求解旅行商问题"><a href="#模拟退火算法求解旅行商问题" class="headerlink" title="模拟退火算法求解旅行商问题"></a>模拟退火算法求解旅行商问题</h1><h2 id="题目-10"><a href="#题目-10" class="headerlink" title="题目"></a>题目</h2><p><img src="/2018/10/20/《人工智能》作业集/12-1.png" alt=""></p><h2 id="源代码-6"><a href="#源代码-6" class="headerlink" title="源代码"></a>源代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(x1, x2, y1, y2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> ((x1 - x2) ** <span class="number">2</span> + (y1 - y2) ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认从index为0的点出发</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sample</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calculate_cost</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.cost = self.distances[<span class="number">0</span>][self.sample[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.sample) - <span class="number">1</span>):</span><br><span class="line">            a, b = self.sample[i], self.sample[i + <span class="number">1</span>]</span><br><span class="line">            self.cost += self.distances[a][b]</span><br><span class="line">        self.cost += self.distances[self.sample[<span class="number">-1</span>]][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_points, distances)</span>:</span></span><br><span class="line">        self.num_points = num_points</span><br><span class="line">        self.distances = distances</span><br><span class="line">        self.sample = list(range(<span class="number">1</span>, self.num_points))</span><br><span class="line">        random.shuffle(self.sample)</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_sample</span><span class="params">(self)</span>:</span></span><br><span class="line">        i, j = [random.randint(<span class="number">0</span>, len(self.sample) - <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2</span>)]</span><br><span class="line">        self.sample[i], self.sample[j] = self.sample[j], self.sample[i]</span><br><span class="line">        self.calculate_cost()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Samples</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, y, num_samples=<span class="number">100</span>)</span>:</span></span><br><span class="line">        self.inf = <span class="number">1000</span></span><br><span class="line">        self.x, self.y, self.num_samples = x, y, num_samples</span><br><span class="line">        self.num_points = len(self.x)</span><br><span class="line">        self.points = list(zip(self.x, self.y))</span><br><span class="line">        self.distances = np.array([</span><br><span class="line">            [distance(point1[<span class="number">0</span>], point2[<span class="number">0</span>], point1[<span class="number">1</span>], point2[<span class="number">1</span>]) <span class="keyword">if</span> point1 != point2 <span class="keyword">else</span> self.inf <span class="keyword">for</span> point2 <span class="keyword">in</span></span><br><span class="line">             self.points]</span><br><span class="line">            <span class="keyword">for</span> point1 <span class="keyword">in</span> self.points</span><br><span class="line">        ])</span><br><span class="line">        self.sample = Sample(self.num_points, self.distances)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, Tk=<span class="number">100</span>, Tf=<span class="number">0.001</span>, r=<span class="number">0.99</span>, n_Tk=<span class="number">5</span>)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> Tk &gt; Tf:</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_Tk):</span><br><span class="line">                new_sample = deepcopy(self.sample)</span><br><span class="line">                new_sample.change_sample()</span><br><span class="line">                <span class="keyword">if</span> new_sample.cost &lt; self.sample.cost:</span><br><span class="line">                    self.sample = new_sample</span><br><span class="line">                <span class="keyword">elif</span> np.e ** ((self.sample.cost - new_sample.cost) / Tk) &gt; np.random.uniform(<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">                    self.sample = new_sample</span><br><span class="line">            <span class="comment"># 更新温度</span></span><br><span class="line">            Tk *= r</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_result</span><span class="params">(self)</span>:</span></span><br><span class="line">        plt.figure()</span><br><span class="line">        plt.scatter(self.x, self.y)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(self.x, self.y):</span><br><span class="line">            plt.text(x, y, (x, y), fontdict=&#123;<span class="string">'size'</span>: <span class="number">16</span>, <span class="string">'color'</span>: <span class="string">'r'</span>&#125;)</span><br><span class="line">        print(<span class="string">'least cost: '</span>, self.sample.cost)</span><br><span class="line">        plt.plot([self.x[<span class="number">0</span>], self.x[self.sample.sample[<span class="number">0</span>]]], [self.y[<span class="number">0</span>], self.y[self.sample.sample[<span class="number">0</span>]]])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.sample.sample)<span class="number">-1</span>):</span><br><span class="line">            a, b = self.sample.sample[i], self.sample.sample[i+<span class="number">1</span>]</span><br><span class="line">            plt.plot([self.x[a], self.x[b]], [self.y[a], self.y[b]])</span><br><span class="line">        plt.plot([self.x[<span class="number">0</span>], self.x[self.sample.sample[<span class="number">-1</span>]]], [self.y[<span class="number">0</span>], self.y[self.sample.sample[<span class="number">-1</span>]]])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">points_x = [<span class="number">40</span>, <span class="number">24</span>, <span class="number">17</span>, <span class="number">22</span>, <span class="number">51</span>, <span class="number">87</span>, <span class="number">68</span>, <span class="number">84</span>, <span class="number">66</span>, <span class="number">61</span>, ]</span><br><span class="line">points_y = [<span class="number">44</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">76</span>, <span class="number">94</span>, <span class="number">65</span>, <span class="number">52</span>, <span class="number">36</span>, <span class="number">25</span>, <span class="number">26</span>, ]</span><br><span class="line">s = Samples(points_x, points_y)</span><br><span class="line">s.train()</span><br><span class="line">s.show_result()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;虽然王公仆老师布置的作业和考试并没有直接关系，但是实事求是的说，王老师《人工智能》课程的内容还是比较科学合理，能够勾起大家学习兴趣的。以下便是历次作业题及其解答。&lt;/p&gt;
&lt;h1 id=&quot;用遗传算法求解旅行商问题&quot;&gt;&lt;a href=&quot;#用遗传算法求解旅行商问题&quot; class
      
    
    </summary>
    
      <category term="人工智能" scheme="http://wang22ti.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-latex-1-组织文本</title>
    <link href="http://wang22ti.com/2018/10/20/%E7%AC%94%E8%AE%B0-latex-1-%E7%BB%84%E7%BB%87%E6%96%87%E6%9C%AC/"/>
    <id>http://wang22ti.com/2018/10/20/笔记-latex-1-组织文本/</id>
    <published>2018-10-20T02:53:19.000Z</published>
    <updated>2018-11-24T13:20:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>这个系列全部来自于刘海洋先生的《Latex入门》，第1章是综述性质的介绍，读完基本上就可以写出蛮漂亮的文章了，这里就粗暴地粘贴出代码吧：</p><h1 id="gougu-tex"><a href="#gougu-tex" class="headerlink" title="gougu.tex"></a>gougu.tex</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[UTF8]&#123;ctexart&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\usepackage&#123;cite&#125;</span><br><span class="line">\usepackage&#123;geometry&#125;</span><br><span class="line">%页面设置</span><br><span class="line">\geometry&#123;a6paper, centering , scale=0.8&#125;</span><br><span class="line">%改变caption格式</span><br><span class="line">\usepackage[format=hang, font=small, textfont=it]&#123;caption&#125;</span><br><span class="line">%在目录中取消目录本身</span><br><span class="line">\usepackage[nottoc]&#123;tocbibind&#125;</span><br><span class="line">%自定义环境，简化代码</span><br><span class="line">\newenvironment&#123;myquote&#125;</span><br><span class="line">&#123;\begin&#123;quote&#125;\kaishu \zihao&#123;-5&#125;&#125;</span><br><span class="line">&#123;\end&#123;quote&#125;&#125;</span><br><span class="line">%自定义命令简化代码</span><br><span class="line">\newcommand&#123;\degree&#125;&#123;^\circ&#125;</span><br><span class="line"></span><br><span class="line">\title&#123;\heiti 勾股定理&#125;</span><br><span class="line">\author&#123;\kaishu 王子泰&#125;</span><br><span class="line">\date&#123;\today&#125;</span><br><span class="line">%声明参考文献的格式</span><br><span class="line">\bibliographystyle&#123;unsrt&#125;</span><br><span class="line">%thm是新定理在程序中的类名，定理是文章中的类名</span><br><span class="line">\newtheorem&#123;thm&#125;&#123;定理&#125;</span><br><span class="line">%以上为导言区</span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">%输出标题</span><br><span class="line">\maketitle</span><br><span class="line">\begin&#123;abstract&#125;</span><br><span class="line">这是一篇关于勾股定理的小短文。</span><br><span class="line">\end&#123;abstract&#125;</span><br><span class="line">%输出目录</span><br><span class="line">\tableofcontents</span><br><span class="line"></span><br><span class="line">\section&#123;勾股定理在古代&#125;</span><br><span class="line">西方勾股定理被称为毕达哥拉斯学派，将勾股定理的发现归功于公元前 6 世纪的毕达哥拉斯学派。欧几里得\footnote&#123;欧几里得：约公元前330-275年&#125;《几何原本》的命题47。</span><br><span class="line">%空行分段</span><br><span class="line"></span><br><span class="line">我国的《周髀算经》（约公元前12世纪）记载了答周公问，很经典的一段话：</span><br><span class="line">%引用</span><br><span class="line">%\begin&#123;quote&#125;</span><br><span class="line">%\zihao&#123;-5&#125;\kaishu 勾广三，股修四，径隅五。</span><br><span class="line">%\end&#123;quote&#125;</span><br><span class="line">\begin&#123;myquote&#125;</span><br><span class="line">勾广三，股修四，径隅五。</span><br><span class="line">\end&#123;myquote&#125;</span><br><span class="line">以上就是周公的一段话。</span><br><span class="line"></span><br><span class="line">\section&#123;勾股定理的近代形式&#125;</span><br><span class="line">满足(1)的整数被称为\emph&#123;勾股数&#125;,</span><br><span class="line">%用thm作为类名，用勾股定理作为具体名称</span><br><span class="line">\begin&#123;thm&#125;[勾股定理]</span><br><span class="line">直角三角形两边平方和等于第三边的平方。用公式表达为：设直角三角形ABC，其中$\angle C = 90\degree$。</span><br><span class="line">\end&#123;thm&#125;</span><br><span class="line">%插入图片需要包graphicx，ht表示浮动体here&amp;top</span><br><span class="line">\begin&#123;figure&#125;[ht]</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[scale=1]&#123;1.jpg&#125;</span><br><span class="line">\caption&#123;勾股定理&#125;</span><br><span class="line">\label&#123;fig:gougudingli&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line">%表格.|表示竖线位置</span><br><span class="line">\begin&#123;tabular&#125;&#123;|rrr|&#125;</span><br><span class="line">\hline %横线</span><br><span class="line">直角边$a$ &amp; 直角边$b$ &amp; 直角边$c$ \\</span><br><span class="line">\hline</span><br><span class="line">3 &amp; 4 &amp; 5 \\</span><br><span class="line">5 &amp; 12 &amp;13 \\</span><br><span class="line">\hline</span><br><span class="line">\end&#123;tabular&#125;</span><br><span class="line"></span><br><span class="line">参考文献\cite&#123;Kline&#125;</span><br><span class="line">\nocite&#123;jobs&#125;</span><br><span class="line">%正式生成参考文件</span><br><span class="line">\bibliography&#123;gougu&#125;</span><br><span class="line"></span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h1 id="gougu-bib"><a href="#gougu-bib" class="headerlink" title="gougu.bib"></a>gougu.bib</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">% Encoding: UTF8</span><br><span class="line"></span><br><span class="line">@BOOK&#123;Kline,</span><br><span class="line">title = &#123;数学原理&#125;,</span><br><span class="line">publisher = &#123;机械工业出版社&#125;,</span><br><span class="line">year = &#123;2002&#125;,</span><br><span class="line">author = &#123;克莱因&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@BOOK&#123;jobs,</span><br><span class="line">title = &#123;勾股定理&#125;,</span><br><span class="line">publisher = &#123;机械工业出版社&#125;,</span><br><span class="line">year = &#123;2012&#125;,</span><br><span class="line">author = &#123;乔布斯&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="参考文献在Texmaker上的编译"><a href="#参考文献在Texmaker上的编译" class="headerlink" title="参考文献在Texmaker上的编译"></a>参考文献在Texmaker上的编译</h1><p>没有参考文献的时候，用<code>快速构建</code>就可以了，但是在使用bib文件与tex文件交叉引用的时候，就变得复杂一点，首先需要用<code>XeLaTex</code>编译tex文件，再用<code>Bibtex</code>编译bib文件，最后再用<code>XeLatex</code>编译tex文件，就可以点击<code>查看PDF</code>看到结果了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这个系列全部来自于刘海洋先生的《Latex入门》，第1章是综述性质的介绍，读完基本上就可以写出蛮漂亮的文章了，这里就粗暴地粘贴出代码吧：&lt;/p&gt;
&lt;h1 id=&quot;gougu-tex&quot;&gt;&lt;a href=&quot;#gougu-tex&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
      <category term="latex" scheme="http://wang22ti.com/categories/latex/"/>
    
    
  </entry>
  
  <entry>
    <title>《软件综合实践》课程设计-基于龙芯处理器的C语言编译系统的设计与实现</title>
    <link href="http://wang22ti.com/2018/10/08/%E3%80%8A%E8%BD%AF%E4%BB%B6%E7%BB%BC%E5%90%88%E5%AE%9E%E8%B7%B5%E3%80%8B%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1-%E5%9F%BA%E4%BA%8E%E9%BE%99%E8%8A%AF%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84C%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wang22ti.com/2018/10/08/《软件综合实践》课程设计-基于龙芯处理器的C语言编译系统的设计与实现/</id>
    <published>2018-10-08T03:32:54.000Z</published>
    <updated>2019-01-11T02:50:08.152Z</updated>
    
    <content type="html"><![CDATA[<p>嗯……本来是想写一个超详细的说明的，但是发现细节实在是太多了，所以选一些重要的说一下吧。</p><h1 id="干了啥？"><a href="#干了啥？" class="headerlink" title="干了啥？"></a>干了啥？</h1><p>老师给了我们一款板子，上面有龙芯处理器。我们要做的是，在箱子外面写一个编译器，把C语言代码转化为可执行文件，然后传输到板子上，在板子上执行那个可执行文件。</p><p>整个工作分为PC和板子的通信、编译器、汇编器、链接器，我和<a href="https://www.wchhlbt.cn/" target="_blank" rel="noopener">楚涵</a>一起完成了汇编器的部分，就是将MIPS汇编代码翻译为Linux下可执行的ELF文件。</p><h1 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h1><ol><li><p>ELF文件长啥样？</p><p>在干这个项目之前，我以为只要参照MIPS指令的手册，粗暴地把指令翻译为二进制的格式并写到文件里面就行。但实际上，二进制可执行文件里面除了指令以外，还有很多的信息，比如文件一开始有一堆关于文件信息的描述，后面是表头，再后面才是各个具体的表。详细在此不赘述，可以参见参考文献。</p><p>由于不同部分之间存在很多交叉引用，尤其是地址的引用，这给我们带来了很大的困难。</p></li><li><p>MIPS汇编文件的宏指令？</p><p>在看了由标准GCC生成的汇编文件后，我们发现除了标准的MIPS指令，还存在大量其他内容。一个是宏指令，比如<code>li</code>和<code>la</code>，即将多条标准指令封装为一条宏指令，根据参数的不同由汇编器选择具体的指令；另外一种是由标准指令扩展的失灵，比如<code>mov</code>，既可以用<code>or</code>扩展，也可以用<code>addiu</code>来扩展；还有一种是以点开头的指令，比如<code>.set noreorder</code>，是对于汇编器的设置。</p><p>要搞清这三类指令的具体含义并转化为代码，并不是一个小工作。</p></li><li><p>怎么写二进制文件？</p><p>由于x86和龙芯MIPS都是小端机，所以直接将要写的数据结构传入函数<code>fwrite</code>即可，C语言会把其中的数据项以二进制的方式顺次写到文件中。需要注意的是，文件打开的模式一定要使用<code>wb</code>；因为在windows下如果模式是<code>w</code>，会在写<code>0x0A</code>的时候自动添加一个<code>0x0D</code>。一开始没注意这个问题，被耽误了一些时间。</p></li><li><p>怎么实现输入输出？</p><p>本来以为需要从头写，用一些系统调用，但实际上Linux系统存在很多动态连接库，他们具有<code>地址无关性</code>，只要在代码中传入恰当的参数并调用即可。当然，生成调用的汇编代码并不是我们的工作，我们的工作是把这些信息写到ELF文件中，这涉及到多个段表的填写，所以还是有点复杂的。</p></li><li><p>开发的环境？</p><p>由于最后的软件是在Linux上跑，汇编器又是涉及操作系统的部分，很多数据结构已经在Linux库函数里面有了定义，比如<code>elf.h</code>中就对于elf文件中各个段的数据结构有了定义，所以至少汇编器和链接器的开发要在Linux上进行。</p></li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>相比我们有些拙劣的代码，这些参考文献还是更有价值的：</p><ol><li>《自己动手构造编译系统++编译、汇编与链接》。关于x86和Linux环境下的MIPS编译器，中文且非常详细，对我们的工作有启发价值。此外，该书的配套代码已经在<a href="https://github.com/fanzhidongyzby/cit/tree/x86" target="_blank" rel="noopener">GitHub</a>上开源了，十分良心了。</li><li>·《See MIPS Run》。中英文都有，对于MIPS指令及其编码、函数调用等方面讲解非常详细，和我们工作最相关的是第2、8、9、11、16章。</li><li>《ELF_Format》。中英文都有，对于ELF文件各个段的讲解十分详细，对于文献1是一种有益的补充。</li></ol><h1 id="配套软件"><a href="#配套软件" class="headerlink" title="配套软件"></a>配套软件</h1><p>要理解汇编到ELF的翻译工作，离不开对于ELF文件的直接阅读，自然不能少了很多工具：</p><ol><li>readelf，Linux自带的读取ELF头信息的命令</li><li>BinaryViewer，可以轻松以各种方式查看二进制文件</li><li>IDA_PRO，以更高级的方式阅读ELF文件，比如指出某段数据是哪一个段的，不过阅读方式不如BinaryViewer灵活多样。</li><li>Snipaste，一个优秀的截图贴图软件，可以方便的依靠贴图在各个文件之间比对。</li><li>pyelftools，python阅读elf文件的包，通过以下代码可以输出每个段的具体内容：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> elftools.elf.elffile</span><br><span class="line"></span><br><span class="line">file_name = <span class="string">'**********'</span></span><br><span class="line">stream = open(file_name+<span class="string">'.o'</span>, <span class="string">'rb'</span>)</span><br><span class="line"></span><br><span class="line">elf_file = elftools.elf.elffile.ELFFile(stream)</span><br><span class="line">num_of_section = elf_file.num_sections()</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>, num_of_section):</span><br><span class="line">    section = elf_file.get_section(n)</span><br><span class="line">    print(n, section.name, section.header.sh_size)</span><br><span class="line">    data = section.data()</span><br><span class="line">    print(data)</span><br></pre></td></tr></table></figure><h1 id="Github链接"><a href="#Github链接" class="headerlink" title="Github链接"></a>Github链接</h1><p><a href="https://github.com/wang22ti/Assembly-For-MIPS" target="_blank" rel="noopener">https://github.com/wang22ti/Assembly-For-MIPS</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;嗯……本来是想写一个超详细的说明的，但是发现细节实在是太多了，所以选一些重要的说一下吧。&lt;/p&gt;
&lt;h1 id=&quot;干了啥？&quot;&gt;&lt;a href=&quot;#干了啥？&quot; class=&quot;headerlink&quot; title=&quot;干了啥？&quot;&gt;&lt;/a&gt;干了啥？&lt;/h1&gt;&lt;p&gt;老师给了我们一款板子
      
    
    </summary>
    
      <category term="软件综合实践" scheme="http://wang22ti.com/categories/%E8%BD%AF%E4%BB%B6%E7%BB%BC%E5%90%88%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验2-贝叶斯分类器设计</title>
    <link href="http://wang22ti.com/2018/10/08/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C2-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>http://wang22ti.com/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/</id>
    <published>2018-10-08T03:30:57.000Z</published>
    <updated>2018-10-13T02:02:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li>对模式识别有一个初步的理解</li><li>能够根据自己的设计对贝叶斯决策理论算法有一个深刻地认识</li><li>理解两类分类器的设计原理 </li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><ol><li><p>已知类别概率和先验概率，根据贝叶斯公式，有后验概率公式</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/1.png" alt=""></p></li><li><p>已知后验概率，基于最小错误率准则和最小风险准则设计分类器</p></li></ol><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><p>假定某个局部区域细胞识别中正常（w1） 和非正常（w2）两类先验概率分别为：正常状态P（w1）=0.9；异常状态P（w2）=0.1。现有一系列待观察的细胞，其观察值为x：</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/2.png" alt=""></p><p>类条件概率分布正态分布分别为N(-2, 0.5)和N(2,2)，试对观察的结果进行分类。<br>首先，根据示例代码和数据完成最小错误率贝叶斯分类器的设计，代码如下。为了加快计算速度、提高代码的简洁性，将原来的循环计算改为矩阵计算。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">x=[ <span class="number">-3.9847</span>  <span class="number">-3.5549</span>  <span class="number">-1.2401</span>  <span class="number">-0.9780</span>  <span class="number">-0.7932</span>  <span class="number">-2.8531</span>...</span><br><span class="line">    <span class="number">-2.7605</span>  <span class="number">-3.7287</span>  <span class="number">-3.5414</span>  <span class="number">-2.2692</span>  <span class="number">-3.4549</span>  <span class="number">-3.0752</span>...</span><br><span class="line">    <span class="number">-3.9934</span>  <span class="number">2.8792</span>  <span class="number">-0.9780</span>  <span class="number">0.7932</span>  <span class="number">1.1882</span>  <span class="number">3.0682</span>...</span><br><span class="line">    <span class="number">-1.5799</span>  <span class="number">-1.4885</span>  <span class="number">0.7431</span>  <span class="number">-0.4221</span>  <span class="number">-1.1186</span>   <span class="number">4.2532</span> ];</span><br><span class="line">pw1=<span class="number">0.9</span>; pw2=<span class="number">0.1</span>;</span><br><span class="line">e1=<span class="number">-2</span>; a1=<span class="number">0.5</span>;</span><br><span class="line">e2=<span class="number">2</span>;a2=<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">p_x_w1 = normpdf(x, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(x, e2, a2) * pw2;</span><br><span class="line">pw1_x = p_x_w1 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w1下的后验概率 </span></span><br><span class="line">pw2_x = p_x_w2 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w2下的后验概率 </span></span><br><span class="line">result = pw1_x &lt;= pw2_x;</span><br><span class="line"></span><br><span class="line">a = [<span class="number">-5</span>:<span class="number">0.05</span>:<span class="number">5</span>];                  <span class="comment">%取样本点以画图</span></span><br><span class="line">p_x_w1 = normpdf(a, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(a, e2, a2) * pw2;</span><br><span class="line">pw1_plot = p_x_w1 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w1的后验概率以画图</span></span><br><span class="line">pw2_plot = p_x_w2 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w2的后验概率以画图</span></span><br><span class="line"></span><br><span class="line">figure(<span class="number">1</span>);</span><br><span class="line">hold on</span><br><span class="line">h1=plot(a,pw1_plot,<span class="string">'b-'</span>);</span><br><span class="line">h2=plot(a,pw2_plot,<span class="string">'r-.'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">numel</span>(x)</span><br><span class="line">    <span class="keyword">if</span> result(k)==<span class="number">0</span> </span><br><span class="line">        h3=plot(x(k),<span class="number">-0.1</span>,<span class="string">'bp'</span>); <span class="comment">%正常细胞用五角星表示</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        h4=plot(x(k),<span class="number">-0.1</span>,<span class="string">'r*'</span>); <span class="comment">%异常细胞用*表示</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">legend([h1,h2,h3,h4],<span class="string">'正常细胞后验概率曲线'</span>,<span class="string">'异常细胞后验概率曲线'</span>,<span class="string">'正常细胞'</span>,<span class="string">'异常细胞'</span>);<span class="comment">%legend添加图例</span></span><br><span class="line">xlabel(<span class="string">'样本细胞的观察值'</span>);</span><br><span class="line">ylabel(<span class="string">'后验概率'</span>);</span><br><span class="line">title(<span class="string">'后验概率分布曲线'</span>);</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line">figure(<span class="number">2</span>);</span><br><span class="line">hold on</span><br><span class="line">a1=<span class="number">-2</span>;sigma1=<span class="number">0.5</span>;</span><br><span class="line">x1=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y1=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma1))*<span class="built_in">exp</span>(-((x1-a1).^<span class="number">2</span>)/(<span class="number">2</span>*sigma1.^<span class="number">2</span>));</span><br><span class="line">plot(x1,y1,<span class="string">'r'</span>);</span><br><span class="line">a2=<span class="number">2</span>;sigma2=<span class="number">2</span>;</span><br><span class="line">x2=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y2=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma2))*<span class="built_in">exp</span>(-((x2-a2).^<span class="number">2</span>)/(<span class="number">2</span>*sigma2.^<span class="number">2</span>));</span><br><span class="line">plot(x2,y2,<span class="string">'b'</span>);</span><br><span class="line">legend(<span class="string">'正常细胞类条件概率分布曲线'</span>,<span class="string">'异常细胞类条件概率分布曲线'</span>);</span><br><span class="line">title(<span class="string">'条件概率分布曲线'</span>);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>然后，根据风险决策表，完成最小风险贝叶斯分类器的设计，同样将循环计算改为矩阵计算，关键代码如下。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">x=[ <span class="number">-3.9847</span>  <span class="number">-3.5549</span>  <span class="number">-1.2401</span>  <span class="number">-0.9780</span>  <span class="number">-0.7932</span>  <span class="number">-2.8531</span>...</span><br><span class="line">    <span class="number">-2.7605</span>  <span class="number">-3.7287</span>  <span class="number">-3.5414</span>  <span class="number">-2.2692</span>  <span class="number">-3.4549</span>  <span class="number">-3.0752</span>...</span><br><span class="line">    <span class="number">-3.9934</span>  <span class="number">2.8792</span>  <span class="number">-0.9780</span>  <span class="number">0.7932</span>  <span class="number">1.1882</span>  <span class="number">3.0682</span>...</span><br><span class="line">    <span class="number">-1.5799</span>  <span class="number">-1.4885</span>  <span class="number">0.7431</span>  <span class="number">-0.4221</span>  <span class="number">-1.1186</span>   <span class="number">4.2532</span> ];</span><br><span class="line">pw1=<span class="number">0.9</span>; pw2=<span class="number">0.1</span>;</span><br><span class="line">e1=<span class="number">-2</span>; a1=<span class="number">0.5</span>;</span><br><span class="line">e2=<span class="number">2</span>;a2=<span class="number">2</span>;</span><br><span class="line">r1 = [<span class="number">0</span> <span class="number">4</span>]; </span><br><span class="line">r2 = [<span class="number">2</span> <span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">p_x_w1 = normpdf(x, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(x, e2, a2) * pw2;</span><br><span class="line">pw1_x = p_x_w1 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w1下的后验概率 </span></span><br><span class="line">pw2_x = p_x_w2 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w2下的后验概率 </span></span><br><span class="line"><span class="comment">%风险决策表</span></span><br><span class="line">R1 = r1 * [pw1_x;pw2_x];</span><br><span class="line">R2 = r2 * [pw1_x;pw2_x];</span><br><span class="line">result = R1 &gt; R2;</span><br><span class="line"></span><br><span class="line">a = [<span class="number">-5</span>:<span class="number">0.05</span>:<span class="number">5</span>];                  <span class="comment">%取样本点以画图</span></span><br><span class="line">p_x_w1 = normpdf(a, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(a, e2, a2) * pw2;</span><br><span class="line">pw1_plot = p_x_w1 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w1的后验概率以画图</span></span><br><span class="line">pw2_plot = p_x_w2 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w2的后验概率以画图</span></span><br><span class="line">R1_plot = r1 * [pw1_plot;pw2_plot];</span><br><span class="line">R2_plot = r2 * [pw1_plot;pw2_plot];</span><br><span class="line"></span><br><span class="line">figure(<span class="number">1</span>);</span><br><span class="line">hold on</span><br><span class="line">h1=plot(a,R1_plot,<span class="string">'b-'</span>);</span><br><span class="line">h2=plot(a,R2_plot,<span class="string">'r-.'</span>);</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">numel</span>(x)</span><br><span class="line">    <span class="keyword">if</span> result(k)==<span class="number">0</span> </span><br><span class="line">        h3=plot(x(k),<span class="number">-0.1</span>,<span class="string">'bp'</span>);<span class="comment">%正常细胞用五角星表示</span></span><br><span class="line">    <span class="keyword">else</span>            </span><br><span class="line">        h4=plot(x(k),<span class="number">-0.1</span>,<span class="string">'r*'</span>);<span class="comment">%异常细胞用*表示</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">legend([h1,h2,h3,h4], <span class="string">'正常细胞条件风险曲线'</span>,<span class="string">'异常细胞条件风险曲线'</span>,<span class="string">'正常细胞'</span>,<span class="string">'异常细胞'</span>);</span><br><span class="line">xlabel(<span class="string">'细胞分类结果'</span>);</span><br><span class="line">ylabel(<span class="string">'条件风险'</span>);</span><br><span class="line">title(<span class="string">'风险判决曲线'</span>);</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line">figure(<span class="number">2</span>);</span><br><span class="line">hold on</span><br><span class="line">a1=<span class="number">-2</span>;sigma1=<span class="number">0.5</span>;</span><br><span class="line">x1=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y1=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma1))*<span class="built_in">exp</span>(-((x1-a1).^<span class="number">2</span>)/(<span class="number">2</span>*sigma1.^<span class="number">2</span>));</span><br><span class="line">plot(x1,y1,<span class="string">'r'</span>);</span><br><span class="line">a2=<span class="number">2</span>;sigma2=<span class="number">2</span>;</span><br><span class="line">x2=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y2=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma2))*<span class="built_in">exp</span>(-((x2-a2).^<span class="number">2</span>)/(<span class="number">2</span>*sigma2.^<span class="number">2</span>));</span><br><span class="line">plot(x2,y2,<span class="string">'b'</span>);</span><br><span class="line">legend(<span class="string">'正常细胞类条件概率分布曲线'</span>,<span class="string">'异常细胞类条件概率分布曲线'</span>);</span><br><span class="line">title(<span class="string">'条件概率分布曲线'</span>);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><p>由于实验两部分修改的仅仅是分类器，所以正常细胞和异常细胞的类条件概率分布曲线图是完全一样的，如下图所示：</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/3.png" alt=""></p><p>当然，由于分类器的不同，两者的后验概率曲线是完全不同的，如下图所示。可以看出， 样本-3.9934、-3.9847在错误率最小分类器中被分为“正常细胞”，在风险最小分类器中被分为“异常细胞”——风险最小分类器倾向于将细胞分类为异常细胞，这与常识相符。导致这一不同的主导因素显然是“风险”这一重要因素的引入。<br><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/4.png" alt=""><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/5.png" alt=""></p><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>在本次实验中，我独立完成了错误率最小贝叶斯分类器和风险最小贝叶斯分类器的设计，并使用矩阵计算的方法进行优化。这一方面提高了我对于matlab的掌握程度，另一方面加深了我对于两种贝叶斯分类器的理解，这必将有利于我进一步的学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;对模式识别有一个初步的理解&lt;/li&gt;
&lt;li&gt;能够根据自己的设计对贝叶斯决策理论算法有一个深刻地认识&lt;/li&gt;

      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-Anaconda</title>
    <link href="http://wang22ti.com/2018/09/25/%E7%AC%94%E8%AE%B0-Anaconda/"/>
    <id>http://wang22ti.com/2018/09/25/笔记-Anaconda/</id>
    <published>2018-09-25T15:53:06.000Z</published>
    <updated>2018-11-11T02:36:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>最早学python的时候，他们都说用anaconda配置环境十分方便，适合初学者。然而那时我的电脑辣鸡，打开<code>anaconda navigator</code>要花很长时间 ，而且个人对于“环境”的理解又很糟糕，于是放弃了。</p><p>在浙大实习的时候，学长告诉我：有一些环境（即运行某些程序配套的程序）是相互冲突的，而anaconda采用沙盒的机制，即anaconda中的环境在不激活的情况下是不会被系统检测到的（即不会添加到环境变量），所以可以同时存在多个环境而又不冲突。</p><p>同时，anaconda不仅可以方便地切换环境，还可以对一个环境的python包进行很方便的管理，比如安装、更新、卸载等等。</p><p>嗯，真香！</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>就上<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">官网</a>咯，值得注意的是，python3和python2对应的anaconda的版本也是不一样的。</p><p>一路默认配置安装。唯一要注意的是，第一个勾是是否把Anaconda加入环境变量，这涉及到能否直接在cmd中使用conda、jupyter、ipython等命令，推荐打勾，如果不打勾话问题也不大，可以在之后使用Anaconda提供的命令行工具进行操作。</p><p><img src="/2018/09/25/笔记-Anaconda/0.png" alt=""></p><h1 id="对包的管理"><a href="#对包的管理" class="headerlink" title="对包的管理"></a>对包的管理</h1><p>安装好了之后，会在文件夹<code>Anaconda3</code>下面出现若干个软件，其中<code>Anaconda Prompt</code>是本体，一个命令行窗口；<code>Anaconda Navigtoer</code>是本体的图形化界面；其他的不用管，都是附带的IDE，而我一直觉得Pycharm是最好用的，也支持Anaconda的环境。</p><p>打开<code>Anaconda Prompt</code>后，会发现和普通的命令行相比，用户目录前面多了一个<code>base</code>，这就是在提示用户：你现在用的python环境叫做base！</p><p><img src="/2018/09/25/笔记-Anaconda/1.jpg" alt=""></p><p>base是anaconda默认配置的python环境，里面已经又很多包可以用了，使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure><p>就可以查看有哪些。当然，以下的命令想来不需要解释了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda remove 包名</span><br><span class="line">conda update 包名</span><br><span class="line">conda env export &gt; environment.yaml // 导出当前环境的包信息</span><br><span class="line">conda env create -f environment.yaml // 用配置文件创建新的虚拟环境</span><br></pre></td></tr></table></figure><h1 id="在Pycharm中使用Anaconda的环境"><a href="#在Pycharm中使用Anaconda的环境" class="headerlink" title="在Pycharm中使用Anaconda的环境"></a>在Pycharm中使用Anaconda的环境</h1><p>在Pycharm工具栏<code>File-Settings for new project-Project Interpreter</code>界面点击<code>齿轮</code>按钮，再点击<code>Add</code>按钮会出现如下界面：</p><p><img src="/2018/09/25/笔记-Anaconda/2.jpg" alt=""></p><p>此时点击<code>Conda Environment</code>就会看到</p><p><img src="/2018/09/25/笔记-Anaconda/3.jpg" alt=""></p><p>要选择<code>Existing Environment</code>，并点击<code>...</code>，再选择编译器所在的位置就好啦，默认如下：</p><p><img src="/2018/09/25/笔记-Anaconda/4.jpg" alt=""></p><p>之后在Pycharm中新建的Project的编译器就是Anaconda默认的那个了~</p><h1 id="对环境的管理"><a href="#对环境的管理" class="headerlink" title="对环境的管理"></a>对环境的管理</h1><p>这个功能有什么用？为什么要安装多个python环境？首先，某些包可能在某些特定的python版本才存在；其次，某些包会相互冲突，比如CPU版本和GPU版本的tensorflow；最后，别人的代码可能需要某特定的环境才能运行。</p><p>第一步当然是新建一个环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n 环境名称 [必备包的列表] [python=版本号]</span><br></pre></td></tr></table></figure><p>之后是激活环境，成功后base会变成新的环境名：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> windows</span></span><br><span class="line">activate 环境名</span><br><span class="line"><span class="meta">%</span><span class="bash"> Linux</span></span><br><span class="line">source activate 环境名</span><br></pre></td></tr></table></figure><p>离开环境也是很类似：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> windows</span></span><br><span class="line">deactivate</span><br><span class="line"><span class="meta">%</span><span class="bash"> Linux</span></span><br><span class="line">source deactivate</span><br></pre></td></tr></table></figure><p>这两个不需要解释：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda env list</span><br><span class="line">conda env remove -n 环境名</span><br></pre></td></tr></table></figure><p>此外，环境可以导出和读取，从而确保项目在其他电脑上一定能跑：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda env export &gt; 文件名.yaml</span><br><span class="line">conda env create -f 文件名.yaml</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最早学python的时候，他们都说用anaconda配置环境十分方便，适合初学者。然而那时我的电脑辣鸡，打开&lt;code&gt;anaconda navigator&lt;/code&gt;要花很长时间 ，而且个人对于“环境”的理解又很糟糕，于是放弃了。&lt;/p&gt;
&lt;p&gt;在浙大实习的时候，学长告
      
    
    </summary>
    
      <category term="anaconda" scheme="http://wang22ti.com/categories/anaconda/"/>
    
    
  </entry>
  
</feed>
