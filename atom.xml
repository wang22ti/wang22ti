<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王子泰</title>
  
  <subtitle>哭也欢乐，悲也潇洒</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wang22ti.com/"/>
  <updated>2018-10-08T03:32:54.628Z</updated>
  <id>http://wang22ti.com/</id>
  
  <author>
    <name>wang22ti</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《软件综合实践》课程设计-基于龙芯处理器的C语言编译系统的设计与实现</title>
    <link href="http://wang22ti.com/2018/10/08/%E3%80%8A%E8%BD%AF%E4%BB%B6%E7%BB%BC%E5%90%88%E5%AE%9E%E8%B7%B5%E3%80%8B%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1-%E5%9F%BA%E4%BA%8E%E9%BE%99%E8%8A%AF%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84C%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wang22ti.com/2018/10/08/《软件综合实践》课程设计-基于龙芯处理器的C语言编译系统的设计与实现/</id>
    <published>2018-10-08T03:32:54.000Z</published>
    <updated>2018-10-08T03:32:54.628Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《模式识别》实验2-贝叶斯分类器设计</title>
    <link href="http://wang22ti.com/2018/10/08/%E3%80%8A%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E3%80%8B%E5%AE%9E%E9%AA%8C2-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>http://wang22ti.com/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/</id>
    <published>2018-10-08T03:30:57.000Z</published>
    <updated>2018-10-13T02:02:57.038Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h1><ol><li>对模式识别有一个初步的理解</li><li>能够根据自己的设计对贝叶斯决策理论算法有一个深刻地认识</li><li>理解两类分类器的设计原理 </li></ol><h1 id="实验原理"><a href="#实验原理" class="headerlink" title="实验原理"></a>实验原理</h1><ol><li><p>已知类别概率和先验概率，根据贝叶斯公式，有后验概率公式</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/1.png" alt=""></p></li><li><p>已知后验概率，基于最小错误率准则和最小风险准则设计分类器</p></li></ol><h1 id="实验内容与步骤"><a href="#实验内容与步骤" class="headerlink" title="实验内容与步骤"></a>实验内容与步骤</h1><p>假定某个局部区域细胞识别中正常（w1） 和非正常（w2）两类先验概率分别为：正常状态P（w1）=0.9；异常状态P（w2）=0.1。现有一系列待观察的细胞，其观察值为x：</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/2.png" alt=""></p><p>类条件概率分布正态分布分别为N(-2, 0.5)和N(2,2)，试对观察的结果进行分类。<br>首先，根据示例代码和数据完成最小错误率贝叶斯分类器的设计，代码如下。为了加快计算速度、提高代码的简洁性，将原来的循环计算改为矩阵计算。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">x=[ <span class="number">-3.9847</span>  <span class="number">-3.5549</span>  <span class="number">-1.2401</span>  <span class="number">-0.9780</span>  <span class="number">-0.7932</span>  <span class="number">-2.8531</span>...</span><br><span class="line">    <span class="number">-2.7605</span>  <span class="number">-3.7287</span>  <span class="number">-3.5414</span>  <span class="number">-2.2692</span>  <span class="number">-3.4549</span>  <span class="number">-3.0752</span>...</span><br><span class="line">    <span class="number">-3.9934</span>  <span class="number">2.8792</span>  <span class="number">-0.9780</span>  <span class="number">0.7932</span>  <span class="number">1.1882</span>  <span class="number">3.0682</span>...</span><br><span class="line">    <span class="number">-1.5799</span>  <span class="number">-1.4885</span>  <span class="number">0.7431</span>  <span class="number">-0.4221</span>  <span class="number">-1.1186</span>   <span class="number">4.2532</span> ];</span><br><span class="line">pw1=<span class="number">0.9</span>; pw2=<span class="number">0.1</span>;</span><br><span class="line">e1=<span class="number">-2</span>; a1=<span class="number">0.5</span>;</span><br><span class="line">e2=<span class="number">2</span>;a2=<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">p_x_w1 = normpdf(x, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(x, e2, a2) * pw2;</span><br><span class="line">pw1_x = p_x_w1 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w1下的后验概率 </span></span><br><span class="line">pw2_x = p_x_w2 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w2下的后验概率 </span></span><br><span class="line">result = pw1_x &lt;= pw2_x;</span><br><span class="line"></span><br><span class="line">a = [<span class="number">-5</span>:<span class="number">0.05</span>:<span class="number">5</span>];                  <span class="comment">%取样本点以画图</span></span><br><span class="line">p_x_w1 = normpdf(a, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(a, e2, a2) * pw2;</span><br><span class="line">pw1_plot = p_x_w1 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w1的后验概率以画图</span></span><br><span class="line">pw2_plot = p_x_w2 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w2的后验概率以画图</span></span><br><span class="line"></span><br><span class="line">figure(<span class="number">1</span>);</span><br><span class="line">hold on</span><br><span class="line">h1=plot(a,pw1_plot,<span class="string">'b-'</span>);</span><br><span class="line">h2=plot(a,pw2_plot,<span class="string">'r-.'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">numel</span>(x)</span><br><span class="line">    <span class="keyword">if</span> result(k)==<span class="number">0</span> </span><br><span class="line">        h3=plot(x(k),<span class="number">-0.1</span>,<span class="string">'bp'</span>); <span class="comment">%正常细胞用五角星表示</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        h4=plot(x(k),<span class="number">-0.1</span>,<span class="string">'r*'</span>); <span class="comment">%异常细胞用*表示</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">legend([h1,h2,h3,h4],<span class="string">'正常细胞后验概率曲线'</span>,<span class="string">'异常细胞后验概率曲线'</span>,<span class="string">'正常细胞'</span>,<span class="string">'异常细胞'</span>);<span class="comment">%legend添加图例</span></span><br><span class="line">xlabel(<span class="string">'样本细胞的观察值'</span>);</span><br><span class="line">ylabel(<span class="string">'后验概率'</span>);</span><br><span class="line">title(<span class="string">'后验概率分布曲线'</span>);</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line">figure(<span class="number">2</span>);</span><br><span class="line">hold on</span><br><span class="line">a1=<span class="number">-2</span>;sigma1=<span class="number">0.5</span>;</span><br><span class="line">x1=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y1=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma1))*<span class="built_in">exp</span>(-((x1-a1).^<span class="number">2</span>)/(<span class="number">2</span>*sigma1.^<span class="number">2</span>));</span><br><span class="line">plot(x1,y1,<span class="string">'r'</span>);</span><br><span class="line">a2=<span class="number">2</span>;sigma2=<span class="number">2</span>;</span><br><span class="line">x2=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y2=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma2))*<span class="built_in">exp</span>(-((x2-a2).^<span class="number">2</span>)/(<span class="number">2</span>*sigma2.^<span class="number">2</span>));</span><br><span class="line">plot(x2,y2,<span class="string">'b'</span>);</span><br><span class="line">legend(<span class="string">'正常细胞类条件概率分布曲线'</span>,<span class="string">'异常细胞类条件概率分布曲线'</span>);</span><br><span class="line">title(<span class="string">'条件概率分布曲线'</span>);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>然后，根据风险决策表，完成最小风险贝叶斯分类器的设计，同样将循环计算改为矩阵计算，关键代码如下。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">x=[ <span class="number">-3.9847</span>  <span class="number">-3.5549</span>  <span class="number">-1.2401</span>  <span class="number">-0.9780</span>  <span class="number">-0.7932</span>  <span class="number">-2.8531</span>...</span><br><span class="line">    <span class="number">-2.7605</span>  <span class="number">-3.7287</span>  <span class="number">-3.5414</span>  <span class="number">-2.2692</span>  <span class="number">-3.4549</span>  <span class="number">-3.0752</span>...</span><br><span class="line">    <span class="number">-3.9934</span>  <span class="number">2.8792</span>  <span class="number">-0.9780</span>  <span class="number">0.7932</span>  <span class="number">1.1882</span>  <span class="number">3.0682</span>...</span><br><span class="line">    <span class="number">-1.5799</span>  <span class="number">-1.4885</span>  <span class="number">0.7431</span>  <span class="number">-0.4221</span>  <span class="number">-1.1186</span>   <span class="number">4.2532</span> ];</span><br><span class="line">pw1=<span class="number">0.9</span>; pw2=<span class="number">0.1</span>;</span><br><span class="line">e1=<span class="number">-2</span>; a1=<span class="number">0.5</span>;</span><br><span class="line">e2=<span class="number">2</span>;a2=<span class="number">2</span>;</span><br><span class="line">r1 = [<span class="number">0</span> <span class="number">4</span>]; </span><br><span class="line">r2 = [<span class="number">2</span> <span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">p_x_w1 = normpdf(x, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(x, e2, a2) * pw2;</span><br><span class="line">pw1_x = p_x_w1 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w1下的后验概率 </span></span><br><span class="line">pw2_x = p_x_w2 ./ (p_x_w1 + p_x_w2);        <span class="comment">%计算在w2下的后验概率 </span></span><br><span class="line"><span class="comment">%风险决策表</span></span><br><span class="line">R1 = r1 * [pw1_x;pw2_x];</span><br><span class="line">R2 = r2 * [pw1_x;pw2_x];</span><br><span class="line">result = R1 &gt; R2;</span><br><span class="line"></span><br><span class="line">a = [<span class="number">-5</span>:<span class="number">0.05</span>:<span class="number">5</span>];                  <span class="comment">%取样本点以画图</span></span><br><span class="line">p_x_w1 = normpdf(a, e1, a1) * pw1;</span><br><span class="line">p_x_w2 = normpdf(a, e2, a2) * pw2;</span><br><span class="line">pw1_plot = p_x_w1 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w1的后验概率以画图</span></span><br><span class="line">pw2_plot = p_x_w2 ./ (p_x_w1 + p_x_w2);         <span class="comment">%计算每个样本点对w2的后验概率以画图</span></span><br><span class="line">R1_plot = r1 * [pw1_plot;pw2_plot];</span><br><span class="line">R2_plot = r2 * [pw1_plot;pw2_plot];</span><br><span class="line"></span><br><span class="line">figure(<span class="number">1</span>);</span><br><span class="line">hold on</span><br><span class="line">h1=plot(a,R1_plot,<span class="string">'b-'</span>);</span><br><span class="line">h2=plot(a,R2_plot,<span class="string">'r-.'</span>);</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:<span class="built_in">numel</span>(x)</span><br><span class="line">    <span class="keyword">if</span> result(k)==<span class="number">0</span> </span><br><span class="line">        h3=plot(x(k),<span class="number">-0.1</span>,<span class="string">'bp'</span>);<span class="comment">%正常细胞用五角星表示</span></span><br><span class="line">    <span class="keyword">else</span>            </span><br><span class="line">        h4=plot(x(k),<span class="number">-0.1</span>,<span class="string">'r*'</span>);<span class="comment">%异常细胞用*表示</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">legend([h1,h2,h3,h4], <span class="string">'正常细胞条件风险曲线'</span>,<span class="string">'异常细胞条件风险曲线'</span>,<span class="string">'正常细胞'</span>,<span class="string">'异常细胞'</span>);</span><br><span class="line">xlabel(<span class="string">'细胞分类结果'</span>);</span><br><span class="line">ylabel(<span class="string">'条件风险'</span>);</span><br><span class="line">title(<span class="string">'风险判决曲线'</span>);</span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line">figure(<span class="number">2</span>);</span><br><span class="line">hold on</span><br><span class="line">a1=<span class="number">-2</span>;sigma1=<span class="number">0.5</span>;</span><br><span class="line">x1=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y1=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma1))*<span class="built_in">exp</span>(-((x1-a1).^<span class="number">2</span>)/(<span class="number">2</span>*sigma1.^<span class="number">2</span>));</span><br><span class="line">plot(x1,y1,<span class="string">'r'</span>);</span><br><span class="line">a2=<span class="number">2</span>;sigma2=<span class="number">2</span>;</span><br><span class="line">x2=<span class="number">-10</span>:<span class="number">0.0001</span>:<span class="number">10</span>;</span><br><span class="line">y2=(<span class="number">1</span>/((<span class="built_in">sqrt</span>(<span class="number">2</span>*<span class="built_in">pi</span>))*sigma2))*<span class="built_in">exp</span>(-((x2-a2).^<span class="number">2</span>)/(<span class="number">2</span>*sigma2.^<span class="number">2</span>));</span><br><span class="line">plot(x2,y2,<span class="string">'b'</span>);</span><br><span class="line">legend(<span class="string">'正常细胞类条件概率分布曲线'</span>,<span class="string">'异常细胞类条件概率分布曲线'</span>);</span><br><span class="line">title(<span class="string">'条件概率分布曲线'</span>);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><h1 id="实验结果与讨论"><a href="#实验结果与讨论" class="headerlink" title="实验结果与讨论"></a>实验结果与讨论</h1><p>由于实验两部分修改的仅仅是分类器，所以正常细胞和异常细胞的类条件概率分布曲线图是完全一样的，如下图所示：</p><p><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/3.png" alt=""></p><p>当然，由于分类器的不同，两者的后验概率曲线是完全不同的，如下图所示。可以看出， 样本-3.9934、-3.9847在错误率最小分类器中被分为“正常细胞”，在风险最小分类器中被分为“异常细胞”——风险最小分类器倾向于将细胞分类为异常细胞，这与常识相符。导致这一不同的主导因素显然是“风险”这一重要因素的引入。<br><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/4.png" alt=""><img src="/2018/10/08/《模式识别》实验2-贝叶斯分类器设计/5.png" alt=""></p><h1 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h1><p>在本次实验中，我独立完成了错误率最小贝叶斯分类器和风险最小贝叶斯分类器的设计，并使用矩阵计算的方法进行优化。这一方面提高了我对于matlab的掌握程度，另一方面加深了我对于两种贝叶斯分类器的理解，这必将有利于我进一步的学习。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实验目的&quot;&gt;&lt;a href=&quot;#实验目的&quot; class=&quot;headerlink&quot; title=&quot;实验目的&quot;&gt;&lt;/a&gt;实验目的&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;对模式识别有一个初步的理解&lt;/li&gt;
&lt;li&gt;能够根据自己的设计对贝叶斯决策理论算法有一个深刻地认识&lt;/li&gt;

      
    
    </summary>
    
      <category term="模式识别" scheme="http://wang22ti.com/categories/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-Anaconda</title>
    <link href="http://wang22ti.com/2018/09/25/%E7%AC%94%E8%AE%B0-Anaconda/"/>
    <id>http://wang22ti.com/2018/09/25/笔记-Anaconda/</id>
    <published>2018-09-25T15:53:06.000Z</published>
    <updated>2018-09-25T15:53:06.350Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>笔记-python标准包常见错误</title>
    <link href="http://wang22ti.com/2018/09/02/%E7%AC%94%E8%AE%B0-python%E6%A0%87%E5%87%86%E5%8C%85%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <id>http://wang22ti.com/2018/09/02/笔记-python标准包常见错误/</id>
    <published>2018-09-02T02:56:00.000Z</published>
    <updated>2018-09-02T14:59:15.689Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="python" scheme="http://wang22ti.com/categories/python/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-《数学之美》</title>
    <link href="http://wang22ti.com/2018/09/02/%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B/"/>
    <id>http://wang22ti.com/2018/09/02/笔记-《数学之美》/</id>
    <published>2018-09-02T00:34:30.000Z</published>
    <updated>2018-09-02T02:43:12.955Z</updated>
    
    <content type="html"><![CDATA[<p>本来买这本书只是因为名字——“数学是美的！是有趣的！”袁岚峰老师在讲蓝眼睛岛问题（<a href="https://www.bilibili.com/video/av29527174" target="_blank" rel="noopener">上</a>）（<a href="https://www.bilibili.com/video/av30113899" target="_blank" rel="noopener">下</a>）的时候就这么呼吁。翻了翻目录，却是讲自然语言处理的，而且几乎以Google作为模板，然而这并不服算妨碍啦！</p><h1 id="文字和语言vs数字和信息"><a href="#文字和语言vs数字和信息" class="headerlink" title="文字和语言vs数字和信息"></a>文字和语言vs数字和信息</h1><blockquote><p>语言和数学的产生都是为了记录和传播信息，但是直到香农提出信息论，人们才将两者自觉的联系起来。</p></blockquote><h1 id="自然语言处理——从规则到统计"><a href="#自然语言处理——从规则到统计" class="headerlink" title="自然语言处理——从规则到统计"></a>自然语言处理——从规则到统计</h1><h1 id="统计语言模型"><a href="#统计语言模型" class="headerlink" title="统计语言模型"></a>统计语言模型</h1><h1 id="谈谈分词"><a href="#谈谈分词" class="headerlink" title="谈谈分词"></a>谈谈分词</h1><h1 id="隐含马尔可夫模型"><a href="#隐含马尔可夫模型" class="headerlink" title="隐含马尔可夫模型"></a>隐含马尔可夫模型</h1><h1 id="信息的度量和作用"><a href="#信息的度量和作用" class="headerlink" title="信息的度量和作用"></a>信息的度量和作用</h1><h1 id="贾里尼克和现代语言处理"><a href="#贾里尼克和现代语言处理" class="headerlink" title="贾里尼克和现代语言处理"></a>贾里尼克和现代语言处理</h1><h1 id="简单之美——布尔代数和搜索引擎"><a href="#简单之美——布尔代数和搜索引擎" class="headerlink" title="简单之美——布尔代数和搜索引擎"></a>简单之美——布尔代数和搜索引擎</h1><h1 id="图论和网络爬虫"><a href="#图论和网络爬虫" class="headerlink" title="图论和网络爬虫"></a>图论和网络爬虫</h1><h1 id="PageRank——Google的民主表决式网页排名技术"><a href="#PageRank——Google的民主表决式网页排名技术" class="headerlink" title="PageRank——Google的民主表决式网页排名技术"></a>PageRank——Google的民主表决式网页排名技术</h1><h1 id="如何确定网页和查询的相关性"><a href="#如何确定网页和查询的相关性" class="headerlink" title="如何确定网页和查询的相关性"></a>如何确定网页和查询的相关性</h1><h1 id="有限状态机和动态规划——地图与本地搜索的核心技术"><a href="#有限状态机和动态规划——地图与本地搜索的核心技术" class="headerlink" title="有限状态机和动态规划——地图与本地搜索的核心技术"></a>有限状态机和动态规划——地图与本地搜索的核心技术</h1><h1 id="Google-AK-47的设计者——阿米特·辛格博士"><a href="#Google-AK-47的设计者——阿米特·辛格博士" class="headerlink" title="Google AK-47的设计者——阿米特·辛格博士"></a>Google AK-47的设计者——阿米特·辛格博士</h1><h1 id="余弦定理与新闻分类"><a href="#余弦定理与新闻分类" class="headerlink" title="余弦定理与新闻分类"></a>余弦定理与新闻分类</h1><h1 id="矩阵运算和文本处理中的两个分类问题"><a href="#矩阵运算和文本处理中的两个分类问题" class="headerlink" title="矩阵运算和文本处理中的两个分类问题"></a>矩阵运算和文本处理中的两个分类问题</h1><h1 id="信息指纹及其应用"><a href="#信息指纹及其应用" class="headerlink" title="信息指纹及其应用"></a>信息指纹及其应用</h1><h1 id="由电视剧《暗算》所想到的——谈谈密码学的数学原理"><a href="#由电视剧《暗算》所想到的——谈谈密码学的数学原理" class="headerlink" title="由电视剧《暗算》所想到的——谈谈密码学的数学原理"></a>由电视剧《暗算》所想到的——谈谈密码学的数学原理</h1><h1 id="闪光的不一定是金子——谈谈搜索引擎反作弊问题和搜索结果的权威性问题"><a href="#闪光的不一定是金子——谈谈搜索引擎反作弊问题和搜索结果的权威性问题" class="headerlink" title="闪光的不一定是金子——谈谈搜索引擎反作弊问题和搜索结果的权威性问题"></a>闪光的不一定是金子——谈谈搜索引擎反作弊问题和搜索结果的权威性问题</h1><h1 id="谈谈数学模型的重要性"><a href="#谈谈数学模型的重要性" class="headerlink" title="谈谈数学模型的重要性"></a>谈谈数学模型的重要性</h1><h1 id="不要把鸡蛋装在一个笼子里——谈谈最大熵模型"><a href="#不要把鸡蛋装在一个笼子里——谈谈最大熵模型" class="headerlink" title="不要把鸡蛋装在一个笼子里——谈谈最大熵模型"></a>不要把鸡蛋装在一个笼子里——谈谈最大熵模型</h1><h1 id="拼音输入法的数学原理"><a href="#拼音输入法的数学原理" class="headerlink" title="拼音输入法的数学原理"></a>拼音输入法的数学原理</h1><h1 id="自然语言处理的教父马库斯和他的优秀弟子们"><a href="#自然语言处理的教父马库斯和他的优秀弟子们" class="headerlink" title="自然语言处理的教父马库斯和他的优秀弟子们"></a>自然语言处理的教父马库斯和他的优秀弟子们</h1><h1 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h1><h1 id="马尔可夫链的扩展——贝叶斯网络"><a href="#马尔可夫链的扩展——贝叶斯网络" class="headerlink" title="马尔可夫链的扩展——贝叶斯网络"></a>马尔可夫链的扩展——贝叶斯网络</h1><h1 id="条件随机场、文法分析和其他"><a href="#条件随机场、文法分析和其他" class="headerlink" title="条件随机场、文法分析和其他"></a>条件随机场、文法分析和其他</h1><h1 id="维比特和他的维比特算法"><a href="#维比特和他的维比特算法" class="headerlink" title="维比特和他的维比特算法"></a>维比特和他的维比特算法</h1><h1 id="上帝的算法——期望最大化算法"><a href="#上帝的算法——期望最大化算法" class="headerlink" title="上帝的算法——期望最大化算法"></a>上帝的算法——期望最大化算法</h1><h1 id="逻辑回归和搜索广告"><a href="#逻辑回归和搜索广告" class="headerlink" title="逻辑回归和搜索广告"></a>逻辑回归和搜索广告</h1><h1 id="各个击破算法和Google云计算基础"><a href="#各个击破算法和Google云计算基础" class="headerlink" title="各个击破算法和Google云计算基础"></a>各个击破算法和Google云计算基础</h1><h1 id="Google大脑和人工神经网络"><a href="#Google大脑和人工神经网络" class="headerlink" title="Google大脑和人工神经网络"></a>Google大脑和人工神经网络</h1><h1 id="大数据的威力——谈谈数据的重要性"><a href="#大数据的威力——谈谈数据的重要性" class="headerlink" title="大数据的威力——谈谈数据的重要性"></a>大数据的威力——谈谈数据的重要性</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本来买这本书只是因为名字——“数学是美的！是有趣的！”袁岚峰老师在讲蓝眼睛岛问题（&lt;a href=&quot;https://www.bilibili.com/video/av29527174&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;上&lt;/a&gt;）（&lt;a hre
      
    
    </summary>
    
      <category term="自然语言处理" scheme="http://wang22ti.com/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
  </entry>
  
  <entry>
    <title>关于保研的一些总结</title>
    <link href="http://wang22ti.com/2018/09/02/%E5%85%B3%E4%BA%8E%E4%BF%9D%E7%A0%94%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93/"/>
    <id>http://wang22ti.com/2018/09/02/关于保研的一些总结/</id>
    <published>2018-09-02T00:34:07.000Z</published>
    <updated>2018-10-12T15:49:39.268Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>北京交通大学计算机与信息技术学院2015级</p><p>2年半排名11/198，保研排名3/198，六级526</p><p>无国奖，美赛H奖，一堆校级奖项，</p><p>做过几个项目，一篇EI在投</p></blockquote><p>转眼已经是2018年10月12日，一切早已在9月28日尘埃落定，我也终于安下心情，记录一下这段时光。如果想了解一些细节，尽管找我吧。</p><h1 id="未名湖"><a href="#未名湖" class="headerlink" title="未名湖"></a>未名湖</h1><p>5月，我忽然意识到要联系老师了。</p><p>现在来看，那时已经很迟了，很多同学不经意间已经实习了很久。托徐老师的福，我很幸运的联系到了北大计算所的冯老师，专业也是我一直很感兴趣的自然语言处理。然而这之后就犯了一个战略性的大错误。</p><p>咨询过学长学姐（感谢何、吴、苏、才、顼、由、宋、高、叶几位学长学姐），要机试要面试，却盯着第11不放，一直死扣几门课程的大作业。</p><p>很快审判日到了，经过期末考试后几天的仓促准备（感谢佳丽），北大叉院的机试仅仅做出3题（poj难度），虽然勉勉强强进了50%，但是面试又是一塌糊涂，关于自然语言处理的最基本问题都无法回答，自然就GG了。其中凌晨3点发的面试通知邮件，几乎一宿没睡，内心的挣扎在此不述（后来才知道一般来说做出来1道就可以进）。</p><p>很惨淡的是，虽然进了软件所的夏令营，但是和北大信科又冲突了。虽然知道没什么机会，但是还是没有打开那心结，挣扎着身心，又去数媒组试了一下。马老师是我在北大见过少数慈善的老师，但是后来才知道，没有提前联系老师的我，实力不够强劲的我，在硕士名额减少60%的北大，是没有什么机会的。</p><p>忽然有一种理想幻灭的感觉。</p><h1 id="桑基韬"><a href="#桑基韬" class="headerlink" title="桑基韬"></a>桑基韬</h1><p>完全失去了夏令营的机会，我开始考虑本校，第一次认真的了解一些基本常识。</p><p><a href="https://www.zhihu.com/question/23679630/answer/233282268" target="_blank" rel="noopener">求详细介绍下院士、长江、百人、千人、万人、青千、杰青、各类学者人才计划等等？</a></p><p><a href="https://www.zhihu.com/question/66251104/answer/239964441" target="_blank" rel="noopener">现在科研项目中的重点项目、重大项目、重大研究计划项目，重点研发计划有什么区别和联系？</a></p><p>意外地发现了使我成为迷弟的桑老师。85年的教授，高高瘦瘦的，给我一种意气风发的学长的感觉。他很开心的告诉我是一个“相信眼缘的人”。其实我也是，要不是父母对于平台的要求，以及后来的际遇，我真的不愿意离开他。</p><h1 id="紫金港"><a href="#紫金港" class="headerlink" title="紫金港"></a>紫金港</h1><p>没几天，我就踏上了前往浙大实习的路，这只是当时偶然的报名。</p><p>一个月的时间，学到了很多东西，也认识了很多好朋友（舍友兼知己倪、一同实习的李、谢、金、宁、赵），当然也很感谢刘新国老师的指导（还有学长学姐们的帮助）。当然，还有友鑫的款待。</p><p>老师推荐我和金参加实习直博面试。英语口语一直是我的弱项，对实习项目的介绍当然是很糟糕了，还有自我介绍部分，完全俗套，没有足够的突出综合素质。总之，老师只能招收一个人，我怀着极端复杂的心情回了趟家。</p><p>垓下一战的感觉。</p><h1 id="九推"><a href="#九推" class="headerlink" title="九推"></a>九推</h1><p>第一天上午，计算所VIPL笔试，90%的淘汰率让大家望而生畏，一共就来了20人。但是数学是真的全忘了，，</p><p>下午，机试，虽然vs环境很麻烦，但幸好题目难度并不是很大，马马虎虎吧</p><p>晚上，做面试ppt，真的很匆忙，，</p><p>第二天上午，参加计算所体检</p><p>下午面试，这次总结了前几次的教训，突出个人品质并结合实例说明，，</p><p>王树徽老师和我开玩笑：照片那么精神，为啥真人那么憔悴？（那可是99元的照片啊）</p><p>之傍晚火急火燎地赶上去杭州的火车，终于在12点半躺在湿漉漉的青旅床单上。</p><p>中途收到卿老师的电话，问我去不去国科大计算机学院。</p><p>第三天上午，准备面试；下午倒是比较顺利，选的2个英文题目应该还算可以，对老师的方向也很了解，不过课程相关的问题依旧一塌糊涂。</p><p>下午又火急火燎地回到北京，京城初秋的午夜真是冷冷清清。</p><p>第4填上午，去校医院体检。心想，应该结束了吧？</p><h1 id="转机"><a href="#转机" class="headerlink" title="转机"></a>转机</h1><p>吃完午饭准备上楼睡觉，许老师忽然打电话：</p><p>黄老师在信工所有一个名额，不过以后都是在计算所学习，你来不来？</p><p>当然！火急火燎地前往香山，火急火燎地面试，火急火燎地见黄老师，</p><p>大佬的笑容，慈祥的神色，可能这就是期待已久的场景吧。</p><p>无心插柳柳成荫。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;北京交通大学计算机与信息技术学院2015级&lt;/p&gt;
&lt;p&gt;2年半排名11/198，保研排名3/198，六级526&lt;/p&gt;
&lt;p&gt;无国奖，美赛H奖，一堆校级奖项，&lt;/p&gt;
&lt;p&gt;做过几个项目，一篇EI在投&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;转
      
    
    </summary>
    
      <category term="杂记" scheme="http://wang22ti.com/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>联想miix5pro连接技嘉GamingBox1080</title>
    <link href="http://wang22ti.com/2018/08/28/%E8%81%94%E6%83%B3miix5pro%E8%BF%9E%E6%8E%A5%E6%8A%80%E5%98%89GamingBox1080/"/>
    <id>http://wang22ti.com/2018/08/28/联想miix5pro连接技嘉GamingBox1080/</id>
    <published>2018-08-28T12:30:50.000Z</published>
    <updated>2018-09-02T02:49:01.019Z</updated>
    
    <content type="html"><![CDATA[<h1 id="购买"><a href="#购买" class="headerlink" title="购买"></a>购买</h1><p>想用GPU加速机器学习任务，但是买1060及以上的笔记本又大又重，而且很多钱花在144Hz的屏幕、机械键盘等零件上；如果买台式机也得1万多，而且宿舍没有什么地方放，毫无便携的可能，思前想后，想起来miix5pro是有一个满血的雷电3接口，有着40Gbps的吞吐率，正好买一个外接显卡。</p><p>主要考虑<a href="https://item.jd.com/5685757.html?dist=jd" target="_blank" rel="noopener">惠普的外接盒子</a>和<a href="https://detail.tmall.com/item.htm?id=559309220532&amp;ns=1&amp;abbucket=14" target="_blank" rel="noopener">技嘉的Gaming box</a>（还有<a href="http://cn.razerzone.com/razer-core-v2" target="_blank" rel="noopener">雷蛇的盒子</a>但是太贵了）。两者价格差不多，技嘉的优势在于1080、便携、送雷电3数据线和鼠标，惠普的优势在于盒子和接口的扩展性。于是查了不少相关的测评：</p><p><a href="https://www.bilibili.com/video/av12205290?from=search&amp;seid=12560254674047576198" target="_blank" rel="noopener">【开箱拆解】史上最小外置显卡盒AORUS GTX 1070 GAMING BOX全网首发开箱拆解，评测稍后发~</a></p><p><a href="https://www.zhihu.com/question/63245941" target="_blank" rel="noopener">如何评价技嘉的gaming box显卡拓展？</a></p><p><a href="https://www.zhihu.com/question/39218012" target="_blank" rel="noopener">如何评价雷蛇的外置显卡Razer Core？</a></p><p><a href="https://post.smzdm.com/p/724215/" target="_blank" rel="noopener">HP 惠普 GA1-1007cl OMEN 暗影精灵 显卡扩展坞简单开箱</a></p><p><a href="https://www.chiphell.com/forum.php?mod=viewthread&amp;tid=1837389&amp;page=1#pid38624312" target="_blank" rel="noopener">【MacBook Pro 2016外接 GTX 1080显卡】- 技嘉 AORUS GTX 1080 Gaming Box</a></p><p><a href="https://zhuanlan.zhihu.com/p/33071814" target="_blank" rel="noopener">MacbookPro搭配技嘉外置显卡拓展坞AORUS GTX 1070 GamingBox使用感受，神经网络训练和简明安装教程</a></p><p>另外一个评论总结比较到位</p><p><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/6.png" alt=""></p><p>正纠结着，又看到一个评论</p><p><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/1.png" alt=""></p><p>嗯……那就买技嘉的吧，已经1080了，2、3年内并不会不够用。</p><h1 id="开箱"><a href="#开箱" class="headerlink" title="开箱"></a>开箱</h1><p><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/2.jpg" alt=""><br><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/3.jpg" alt=""><br><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/4.jpg" alt=""><br><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/5.jpg" alt=""></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>由于重装过系统，所以直接插上并不能识别，所以要先安装雷电3的驱动，这是<a href="http://driverdl.lenovo.com.cn/lenovo/DriverFilesUploadFloder/52684/ThunderboltDriver-CZME06AF.exe" target="_blank" rel="noopener">miix5pro的</a>。实际上还有一个更好的方案更新所有驱动，就是安装<a href="https://downloadcenter.intel.com/" target="_blank" rel="noopener">Intel的升级助手</a></p><p>之后就可是识别雷电3啦，但是要识别显卡，还去<a href="https://www.nvidia.com/zh-cn/geforce/geforce-experience/" target="_blank" rel="noopener">英伟达官网</a>下载GEFORCE EXPERIENCE软件，它会提示安装对应的驱动并保持更新。安装之后可以使用控制面板设置在1080上跑的程序：</p><p><img src="/2018/08/28/联想miix5pro连接技嘉GamingBox1080/7.png" alt=""></p><p>注意不要安装技嘉的软件！！！我也不知道为什么，总之安装了之后，不仅设置显卡很慢，还会经常掉盘，体验极差，emmmmm</p><p>为了跑tensorflow，又折腾了一会，见<a href="http://wang22ti.com/2018/07/25/%E7%AC%94%E8%AE%B0-tensorflow/">tensorflow的笔记</a>。</p><h1 id="体验"><a href="#体验" class="headerlink" title="体验"></a>体验</h1><p>懒得跑分了，直接开了一局守望先锋，在极高的画质下人比较少时稳定在55帧以上，人很多很混乱的时候在45帧以上，作为二合一的本子，这样的性能已经让人很满意了，有着质的飞跃。</p><p>当然，由于低压CPU的限制，GPU图形部分并没有能够跑满，大概60-70%吧。此外如果作为鼠标的拓展坞，似乎流畅度不如直接插在电脑上。</p><p>装上CUDA之后跑tensorflow也没有问题，速度有明显的提高，没有亏本。</p><h1 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h1><p>不知道是显卡还是电脑的问题，主要出现了三个问题：</p><ol><li>连接上显卡后经常掉盘，即使是在跑神经网络的时候</li><li>有时连接不上显示器</li><li>鼠标接在显卡上会间歇性卡顿</li></ol><p>很扎心，于是联系客服寄过去修了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;购买&quot;&gt;&lt;a href=&quot;#购买&quot; class=&quot;headerlink&quot; title=&quot;购买&quot;&gt;&lt;/a&gt;购买&lt;/h1&gt;&lt;p&gt;想用GPU加速机器学习任务，但是买1060及以上的笔记本又大又重，而且很多钱花在144Hz的屏幕、机械键盘等零件上；如果买台式机也得1万多，
      
    
    </summary>
    
      <category term="杂记" scheme="http://wang22ti.com/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-Git实用教程</title>
    <link href="http://wang22ti.com/2018/08/13/mooc-Git%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <id>http://wang22ti.com/2018/08/13/mooc-Git实用教程/</id>
    <published>2018-08-13T06:02:27.000Z</published>
    <updated>2018-08-14T02:41:45.404Z</updated>
    
    <content type="html"><![CDATA[<p>注册GitHub有一段时间了，一直用它托管博客，觉得还是应该学一下git的原理，至少是最基础的部分吧！看的是小甲鱼的教程，<a href="https://www.bilibili.com/video/av27780400?zw" target="_blank" rel="noopener">哔哩哔哩</a>和<a href="http://study.163.com/course/courseMain.htm?courseId=1003109018" target="_blank" rel="noopener">网易云课堂</a>都有。</p><h1 id="git是个什么玩意"><a href="#git是个什么玩意" class="headerlink" title="git是个什么玩意"></a>git是个什么玩意</h1><p>讲了什么是版本管理，git的历史，不做赘述</p><h1 id="git理论基础"><a href="#git理论基础" class="headerlink" title="git理论基础"></a>git理论基础</h1><h2 id="git的安装"><a href="#git的安装" class="headerlink" title="git的安装"></a>git的安装</h2><p>Windows/mac去<a href="https://git-scm.com/" target="_blank" rel="noopener">官网</a>下载，ubuntu使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure><h2 id="git全局初始化"><a href="#git全局初始化" class="headerlink" title="git全局初始化"></a>git全局初始化</h2><p>git使用之前需要配置，让它知道主人是谁，注意不要使用中文</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">"****"</span></span><br><span class="line">git config --global user.email <span class="string">"****"</span></span><br></pre></td></tr></table></figure><p>之后使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --list</span><br></pre></td></tr></table></figure><p>就可以查看相关信息了。</p><h2 id="git记录的是什么"><a href="#git记录的是什么" class="headerlink" title="git记录的是什么"></a>git记录的是什么</h2><p>常规版本的思路是记录每一次的更改：</p><p><img src="https://xxx.ilovefishc.com/forum/201604/21/190850u33aqh9ku93k3kz3.png" alt=""></p><p>但是git记录的是每个版本的：</p><p><img src="https://xxx.ilovefishc.com/forum/201604/21/190850p05ig3nhe56eh0gp.png" alt=""></p><p>本地仓库有 Git 维护的三棵“树”组成——工作区域、暂存区域和 Git 仓库 ，这是 Git 的核心框架。</p><p><code>工作区域（Working Directory）</code>就是本地存放项目代码的地方。    </p><p><code>暂存区域（Stage）</code>事实上只是一个文件（比如隐藏文件<code>.git</code>），保存即将提交的文件信息。    </p><p><code>仓库（Repository）</code>就是安全存放数据的位置，其中有提交的所有版本的数据。其中，HEAD 指向最新放入仓库的版本。   </p><p>Git 的工作流程一般是：    </p><ol><li>在工作目录中添加、修改文件；    </li><li>将需要进行版本管理的文件放入暂存区域；    </li><li>将暂存区域的文件提交到 Git 仓库。    </li></ol><p>因此，Git 管理的文件有三种状态：<code>已修改（modified）</code>、<code>已暂存（staged）</code>和<code>已提交（committed）</code>，依次对应上边的每一个流程。 </p><p><img src="https://xxx.ilovefishc.com/forum/201604/21/185430j73kd854krr3p58d.png" alt=""> </p><h2 id="git局部初始化"><a href="#git局部初始化" class="headerlink" title="git局部初始化"></a>git局部初始化</h2><p>在项目的根目录执行初始化后，就会出现暂存区域文件夹<code>.git</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure><p>在该目录新建一个README.txt文件后将之加入暂存区域</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add README.md</span><br></pre></td></tr></table></figure><p>之后将新的版本提交，其中<code>-m</code>表示注释信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m <span class="string">"add a readme file"</span></span><br></pre></td></tr></table></figure><p>在操作的过程中，显示提交成功如下</p><p><img src="/2018/08/13/mooc-Git实用教程/1.png" alt=""></p><p>然而我在GitHub的两个仓库中并没有发现文件的影子！仔细一想，这和GitHub应该还没啥关系，但究竟去哪里了呢？先占一个坑</p><p>其实还在本机，，终于明白了，，commit和push不是一个意思，，</p><h1 id="查看工作状态和历史提交"><a href="#查看工作状态和历史提交" class="headerlink" title="查看工作状态和历史提交"></a>查看工作状态和历史提交</h1><p>使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><p>可以查看当前状态如下，在默认的分支master中，没有需要提交的，工作树是干净的。</p><p><img src="/2018/08/13/mooc-Git实用教程/2.png" alt=""></p><p>加入一个MIT协议文件<code>LIENSE</code>如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Copyright (C) &lt;year&gt; &lt;copyright holders&gt;</span><br><span class="line"></span><br><span class="line">　　Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</span><br><span class="line">　　</span><br><span class="line">　　The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</span><br></pre></td></tr></table></figure><p>这时再查看状态会提示有个一文件更改了但是还没有放入暂存区域</p><p><img src="/2018/08/13/mooc-Git实用教程/3.png" alt=""></p><p>将之add到缓存区域后再查看状态就会提示有一个新的文件可以被提交</p><p><img src="/2018/08/13/mooc-Git实用教程/4.png" alt=""></p><p>这时可以使用rest命令反悔，从而回到更改了但是没有放到暂存区域的状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset LISENCE</span><br></pre></td></tr></table></figure><p>重新add并commit后，又回到了没有需要提交的，工作树是干净的状态。修改LISENCE再查看状态，因为此时是工作目录文件和暂存区域文件不同，所以输出有所不同，第一个建议和之前相同，第二个会将暂存区域的文件覆盖掉工作目录修改后的文件。</p><p><img src="/2018/08/13/mooc-Git实用教程/5.png" alt=""></p><p>将之add到暂存区域后并commit，可以查看所有的版本信息，黄色的是唯一的版本ID。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span></span><br></pre></td></tr></table></figure><p><img src="/2018/08/13/mooc-Git实用教程/6.png" alt=""></p><h1 id="回到过去"><a href="#回到过去" class="headerlink" title="回到过去"></a>回到过去</h1><p>在3课树之间的转换有如下的示意图</p><p><img src="/2018/08/13/mooc-Git实用教程/7.png" alt=""></p><p>先退回到上一个版本，再查看日志就只有2个版本了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD~1</span><br></pre></td></tr></table></figure><p>该命令的选项如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rest --mix HEAD~</span><br><span class="line">git rest --soft HEAD~</span><br><span class="line">git rest --hard HEAD~</span><br></pre></td></tr></table></figure><p>其中soft表示只影响仓库；mix是缺省值，表示仓库回到以前的版本后并用以前版本覆盖暂存区域；hard则更进一步，还要覆盖工作目录。</p><p>进一步地，还可以通过指定ID切换版本（一般只要输入前几位），比如回到最后一个版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 82811</span><br></pre></td></tr></table></figure><h1 id="版本对比"><a href="#版本对比" class="headerlink" title="版本对比"></a>版本对比</h1><p>新建一个项目test2，其中有2个文件game.py和README.md，提交后修改两个文件。运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff</span><br></pre></td></tr></table></figure><p>可以查看工作目录和暂存区域之间的区别（似乎有点崩），其中a是暂存区临时目录，b是工作区临时目录。</p><p><img src="/2018/08/13/mooc-Git实用教程/8.png" alt=""></p><p>绿色表示新增加的，白色表示共有的。如果文件很长，会有交互命令，用<code>h</code>可以查看帮助，在此不赘述。当然也可以比较两个版本的快照：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff id1 id2</span><br></pre></td></tr></table></figure><p>当前工作目录和某个版本的快照：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当前工作目录和当前版本的快照：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff HEAD</span><br></pre></td></tr></table></figure><p>当前暂存区域和某个版本的快照：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff --cached [id]</span><br></pre></td></tr></table></figure><h1 id="修改最后一次提交、删除重命名文件"><a href="#修改最后一次提交、删除重命名文件" class="headerlink" title="修改最后一次提交、删除重命名文件"></a>修改最后一次提交、删除重命名文件</h1><p>如果提交后发现这个版本漏了一些东西，又不想制造一个新的版本，怎么办？使用如下命令即可，不需要回滚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit --amend [-m <span class="string">"****"</span>]</span><br></pre></td></tr></table></figure><p>删除了已经add的文件后，可以恢复</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- [filename]</span><br></pre></td></tr></table></figure><p>那如果想彻底删除已经提交的文件呢？因为有可能加入了不想加入的东西</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add *</span><br></pre></td></tr></table></figure><p>那么使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rm filename</span><br></pre></td></tr></table></figure><p>删除工作目录和暂存区内容后再软回滚版本。不过，如果工作目录和暂存区文件不一样，就会提示错误，这是要用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rm -f filename</span><br></pre></td></tr></table></figure><p>当然也可以只删除暂存区域的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rm --cached filename</span><br></pre></td></tr></table></figure><p>直接在系统中修改文件名会出错，需要使用命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git mv/ren oldfile newfile</span><br></pre></td></tr></table></figure><h1 id="创建和切换分支"><a href="#创建和切换分支" class="headerlink" title="创建和切换分支"></a>创建和切换分支</h1><p>优秀的分支管理是git的灵魂！分支的意义如下</p><p><img src="/2018/08/13/mooc-Git实用教程/9.png" alt=""></p><p>创建一个叫feature的分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch feature</span><br></pre></td></tr></table></figure><p>此时查看带有分支的日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> --decorate --oneline</span><br></pre></td></tr></table></figure><p>切换分支名称</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout feature</span><br></pre></td></tr></table></figure><p>当然也可以直接创建并切换</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b feature2</span><br></pre></td></tr></table></figure><p>在feature分支下做出修改并提交，再切换回master分支后，工作区和暂存区都回到master的状态！可以以图形化的方法看一下所有分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> --decoreate --oneline --graph --all</span><br></pre></td></tr></table></figure><h1 id="合并和删除分支"><a href="#合并和删除分支" class="headerlink" title="合并和删除分支"></a>合并和删除分支</h1><p>将指定的分支合并到本分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge branchname</span><br></pre></td></tr></table></figure><p>但是如果有2个同名文件但内容不同，自动合并就会失败，git会在冲突的文件中打入标记，修改后提交就会完成自动合并。删除分支也很简单，其实只是删除了一个指针</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d brachname</span><br></pre></td></tr></table></figure><h1 id="匿名分支与checkout"><a href="#匿名分支与checkout" class="headerlink" title="匿名分支与checkout"></a>匿名分支与checkout</h1><p>创建匿名分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout HEAD~</span><br></pre></td></tr></table></figure><p>实际上就是把HEAD指针向前指了，但是又没有告诉名字，所以再切换到其他分支的时候，会丢掉所有的更改，这可以用来做实验。切换到别的分支的时候如果想保留改匿名分支，可以立刻用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch new_branch_name id</span><br></pre></td></tr></table></figure><p>如果错过了又忘记了id，就再也找不到了。</p><p>check和reset命令都可以恢复指定快照的指定文件，并且不影响HEAD指针。区别是reset只恢复到暂存区（不允许和soft、hard使用），checkout同时覆盖暂存区和工作目录。因此reset要比checkout安全一些。</p><p>check和reset命令都可以恢复指定快照，都是通过移动指针和覆盖文件产生的。第一个不同在于checkout会检查工作状态是不是clean，因此比较reset —hard更加安全。另一个区别是reset会移动HEAD及其分支指向，而checkout只会移动HEAD。</p><h1 id="创建GitHub账户"><a href="#创建GitHub账户" class="headerlink" title="创建GitHub账户"></a>创建GitHub账户</h1><p>小甲鱼的免费教程只有这些，可是又发现了<a href="https://blog.csdn.net/qq_36974281/article/details/81427893" target="_blank" rel="noopener">大佬的教程</a>，结合起来应该没问题了。我尝试进行了一次操作：</p><ol><li>用git clone url把我再GitHub创建的仓库克隆下来</li><li>用<code>git remote add repository_name url</code>将本地库和远程库关联</li><li>对工作目录进行一定修改，add并commit</li><li>用<code>git push</code>将本地仓库提交到GitHub，这时会弹出窗口让输入GitHub的账号密码，输入后就正确地提交了！</li></ol><p>可能还有情况没有遇到，之后再琢磨啦，何况还有一本git的书再吃灰呢。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;注册GitHub有一段时间了，一直用它托管博客，觉得还是应该学一下git的原理，至少是最基础的部分吧！看的是小甲鱼的教程，&lt;a href=&quot;https://www.bilibili.com/video/av27780400?zw&quot; target=&quot;_blank&quot; rel=&quot;
      
    
    </summary>
    
      <category term="git" scheme="http://wang22ti.com/categories/git/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-深度学习工程师-5-序列模型</title>
    <link href="http://wang22ti.com/2018/08/12/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-5-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>http://wang22ti.com/2018/08/12/mooc-深度学习工程师-5-序列模型/</id>
    <published>2018-08-12T11:43:15.000Z</published>
    <updated>2018-08-25T07:43:51.411Z</updated>
    
    <content type="html"><![CDATA[<h1 id="循环序列模型"><a href="#循环序列模型" class="headerlink" title="循环序列模型"></a>循环序列模型</h1><h2 id="什么是序列数据"><a href="#什么是序列数据" class="headerlink" title="什么是序列数据"></a>什么是序列数据</h2><p><img src="/2018/08/12/mooc-深度学习工程师-5-序列模型/1.png" alt=""></p><h2 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h2><p>用$T_x^{(i)}$表示第$i$个样本的长度，$x^{(i)<t>}$表示第$i$个序列中的第$t$个单元。对于一个句子，首先用所有的单词制作一个一维词典，之后对于每一个词采用one-hot的方式编码。</t></p><h2 id="循环网络模型"><a href="#循环网络模型" class="headerlink" title="循环网络模型"></a>循环网络模型</h2><p>为什么不使用标准的神经网络呢？因为</p><ol><li>不同序列的长度不一定相同，即便使用填充的方法，这显然不是一个好的编码方法</li><li>无法共享在不同位置提取的特征，参数数量过多</li></ol><p>RNN解决了这个问题，</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;循环序列模型&quot;&gt;&lt;a href=&quot;#循环序列模型&quot; class=&quot;headerlink&quot; title=&quot;循环序列模型&quot;&gt;&lt;/a&gt;循环序列模型&lt;/h1&gt;&lt;h2 id=&quot;什么是序列数据&quot;&gt;&lt;a href=&quot;#什么是序列数据&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-深度学习工程师-4-卷积神经网络</title>
    <link href="http://wang22ti.com/2018/08/09/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://wang22ti.com/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/</id>
    <published>2018-08-09T04:02:01.000Z</published>
    <updated>2018-08-24T09:29:32.246Z</updated>
    
    <content type="html"><![CDATA[<p>总的来说，这门课程比CS229容易一些，也可能是神经网络发展时间的问题，很多内容是经验上的，所以在差不多一周的学习之后，来到了最重要的部分啦。</p><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><p>由于神经网络的发展，<code>计算机视觉（computer vision）</code>的研究再近几年取得了突飞猛进的发展，也给其他与计算机交叉的领域带来很多灵感。计算机视觉的任务主要有：图像分类（image classification）、物体检测（object detection）、图像风格转换等等。计算机视觉的挑战主要来自于巨大的输入，一张1000*1000*3的图像有3百万维度的输入特征，如果神经网络的第一层是大小为1000全连接层，那么第一层权重就有30亿个，很难有足够的数据防止不过拟合，对硬件的要求也很高——而这并不能算很大的图片。</p><p>所以，计算机视觉必须进行卷积操作。</p><h2 id="卷积的定义"><a href="#卷积的定义" class="headerlink" title="卷积的定义"></a>卷积的定义</h2><p>卷积是一个应用广泛的定义，在图像处理中实际上就是——以<code>过滤器（filter）</code>/<code>核（kernel）</code>为权重，对原图像相同大小的区域进行加权求和；一次卷积实际只生成了一个像素点的值，对图像的卷积操作实际上是多次卷积操作结果的拼接。</p><p>网上有很多用信号等概念对卷积进行解释，比如<a href="https://blog.csdn.net/bitcarmanlee/article/details/54729807" target="_blank" rel="noopener">最容易理解的对卷积(convolution)的解释</a>和<a href="https://blog.csdn.net/panglinzhuo/article/details/75207855" target="_blank" rel="noopener">深度学习中的卷积与反卷积</a>。实际上他们可能并没有什么必然的实际意义上的联系，只是数学上的形式相同，毕竟不同的卷积核作用大相径庭；他们为了佐证实际意义上的联系都选用了恰好有对应意义的核。用于竖直边缘检测的核如下图所示，在数学上就是图片对应区域左边减去右边。在非边缘的区域，像素的值比较接近，在完全相同（比如都是255）的的情况下卷积的计算结果就为0；在边缘区域，像素值相差较大，左边减去右边的绝对值就很大——因此可以检测竖直边缘。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/4.png" alt="1"></p><p>同理使用旋转180°的核就可以检测水平边缘。下面左图叫做Sobel filter，健壮性好于上面的那个；右图叫做Scharr filter；全是$\frac{1}{9}$的核可以对图片进行平滑处理。但是在卷积神经网络中，我们做的不是手动选择卷积核，而是通过梯度等手段让计算机选择卷积核，即选择提取的特征，这在之后的课程中会提到。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/2.png" alt="1"><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/3.png" alt="1"></p><h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h2><p>对于大小为$n^2$的图像和核$f^2$的卷积核，得到的是大小为$(n-f+1)^2$的图片，这样有两个缺点，一个是每做一次卷积操作图片就会变小一点，另一个是边缘的像素点没有被充分采样。所以通过对原图像用0进行扩充到$(n+f-1)^2$维，即外层增加$p=\frac{f-1}{2},f=2k-1,k\in \N_+$圈。之所以是奇数主要是计算机视觉中的惯例，这样更方便自然的padding和用中心点标记核的位置。</p><p>根据padding的情况，可以定义两种卷积。<code>valid convolution</code>是完全没有padding，而<code>same convolution</code>保证了卷积后的图像大小和原图相同。</p><h2 id="步长（stride）"><a href="#步长（stride）" class="headerlink" title="步长（stride）"></a>步长（stride）</h2><p>步长$s$就是每次卷积核在图上移动的距离，最终输出图像的大小为$\lfloor\frac{n+2p-f}{s}+1\rfloor^2$，向下取整是为了所有的卷积核都是完全在图像上的。</p><p>此外，吴老师在这里解释了计算机的卷积和其他地方的卷积的区别。数学或信号学定义的卷积需要把卷积核做竖直和水平的反转，再进行之前操作，目的是可以使用结合律，但是这在神经网络中并不重要。在数学上，之前介绍的卷积常常被称为<code>互相换（cross correlation）</code>，不过在计算机领域还是习惯叫做卷积。</p><h2 id="3D卷积"><a href="#3D卷积" class="headerlink" title="3D卷积"></a>3D卷积</h2><p>所谓3D卷积是指对具有多个通道（又称深度）的图像进行卷积，此时卷积核的通道数和图像的通道数相同，卷积过程如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/5.png" alt="1"></p><p>实际和2d的并没有什么不同，只不过每次计算量变大了一些。</p><h2 id="多个卷积核"><a href="#多个卷积核" class="headerlink" title="多个卷积核"></a>多个卷积核</h2><p>如果想要同时提取多个特征，就需要使用多个卷积核，分别对图像做卷积操作后堆叠在一起即可，如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/6.png" alt="1"></p><p>即卷积得到的图像如果是有第3维的，第3维的大小表示的是提取的特征的数量，而非其他！</p><h2 id="单层卷积网络"><a href="#单层卷积网络" class="headerlink" title="单层卷积网络"></a>单层卷积网络</h2><p>有了上面的铺垫，终于可以搭建神经网络啦，如下图所示是一个单层神经网络，其中原图是输入$a^{[0]}$，过滤器是参数$W^{[1]}$，卷积操作相当于传统神经网络的矩阵乘法，通过激活函数后各个特征堆叠在一起的就是$a^{[1]}$。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/7.png" alt="1"></p><p>举个例子，如果一层10个3×3×3的卷积核，一共又(3×3×3+1)×10个参数，这是输入图片的大小无关！这样就可以避免过拟合。于是，为了表示整个网络，就有超多的记号如下图</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/8.png" alt="1"></p><p>其中$m$是mini-batch的大小。</p><h2 id="简单CNN示例"><a href="#简单CNN示例" class="headerlink" title="简单CNN示例"></a>简单CNN示例</h2><p>一个简单的、完全由卷积层构成的神经网络如下图所示，在最后一个卷积层后通过平坦化提取到了1960个特征，再后面就是传统的神经网络了！注意到经过几层神经网络后，图片的大小逐渐减小，深度逐渐增大，一般是有这个趋势的。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/9.png" alt="1"></p><p>除了卷积层，CNN通常还有<code>池化层（pooling layers）</code>和<code>全连接层（full connecting layers）</code>，可以使得网络更加强大。</p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层通常用来缩减模型大小，提高计算速度，同时提高模型特征的健壮性。一般的池化层有两种，一个是<code>最大池化层（max pooling layer）</code>，如下图所示，和卷积很类似，不过是对选定范围内的值直接取最大值，可以理解为选择该范围中最突出的特征，过滤掉不重要的特征。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/10.png" alt="1"></p><p>还有一个是<code>平均池化层（average pooling layer）</code>，即将取最大值的操作改为取平均值。平均池化层很少使用，比如将一个具有很深的输入转化为只有$1\times1\times n_c$的形式。</p><p>当然，池化层的深度要和输入的通道数相同。最重要的是池化层并没有任何要学习的参数，只是一个固定的转换。至于池化层的padding，基本上都是0，极少的特例会在之后讲解。</p><h2 id="典型CNN示例"><a href="#典型CNN示例" class="headerlink" title="典型CNN示例"></a>典型CNN示例</h2><p>以下的神经网络基于经典神经网络<code>LeNet-5</code>，注意到由于池化层没有超参数，所以连同前面的卷积层被认为是同一层。这里有大量的超参数，设计的思路会在之后讲解，不过常规的做法不是自己设计，而是从别人的论文中汲取经验。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/11.png" alt="1"></p><p>观察这个典型神经网络的参数，可以发现：参数主要集中在全连接层；activation大小减小的速度不能太快；在卷积部分activation的长和宽逐渐减小而深度逐渐增大。很多CNN都有这样的模式。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/12.png" alt="1"></p><h2 id="为什么使用CNN"><a href="#为什么使用CNN" class="headerlink" title="为什么使用CNN"></a>为什么使用CNN</h2><p>和全连接层相比，为什么卷积在神经网络中很有效呢？因为它有着<code>参数共享（parameter sharing）</code>和<code>稀疏连接（sparsity of connections）</code>两个特性，使得它减少了参数，在防止过拟合的同时加快了训练速度。参数共享是指一个卷积核中的参数被图片中的不同区域反复使用，从而用很少的参数对图片所有区域实现了同一特征的提取；稀疏连接是指卷积得到的每一个像素点都只和对应区域的值有关，和其他区域的值没有任何关系。此外，CNN很擅长捕捉<code>平移不变性（translation invariance）</code>，即相同物体在图片中平移几个像素，CNN仍然可以提取出十分相似的特征。</p><p>了解CNN的结构后，如何训练它也就很简单啦，在此不做赘述。</p><h1 id="卷积神经网络实例探究"><a href="#卷积神经网络实例探究" class="headerlink" title="卷积神经网络实例探究"></a>卷积神经网络实例探究</h1><h2 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h2><p>Lecun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to  document recognition[J]. Proceedings of the IEEE, 1998,  86(11):2278-2324. </p><p>那时没有padding的概念，大家更喜欢使用平均池化，激活函数用的是sigmoid和tanh，最后的输出用了一个很古老的分类器而非softmax，整个网络规模也不大。同时，由于当时计算机很慢，所以论文中用很复杂的推导使得过滤器的通道数和输入通道数可能并不一样——现在已经不使用了。此外，还在池化层增加了激活函数，这是很难理解的地方。吴老师给的示意图如下</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/14.png" alt="1"></p><p>吴老师推荐精读文章的第二部分，有网络结构的详细说明；泛读第三部分，有有趣的实验结果。论文中的示意图如下</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/13.png" alt="1"></p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep  convolutional neural networks[C] International Conference on Neural  Information Processing Systems. Curran Associates Inc.  2012:1097-1105. </p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/15.png" alt="1"></p><p>AlexNet和LeNet非常相似，但是效果好得多，这篇论文也是深度学习在计算机视觉领域大规模应用的开端。效果好一方面是因为规模大得多，另一方面是因为使用了Relu函数。同时在几年前，GPU还没有那么快，文章中介绍了将模型拆分到两个GPU同时训练的方法。此外，文章中的网络还有<code>局部响应归一化层（local response normalization）</code>，不过后来发现对于效果的提升并不明显，所以现在很少使用了。原文的示意图如下</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/16.png" alt="1"></p><h2 id="VGG-16Net"><a href="#VGG-16Net" class="headerlink" title="VGG-16Net"></a>VGG-16Net</h2><p>Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. Computer Science, 2014. </p><p>这个网络十分地深邃，之所以名字中有16就是一共有16个卷积层核全连接层，一共有1.38亿个参数，这是最大的缺点。网络中所有的卷积层都是3×3的核，步长为1，same；所有的池化层都是2×2，步长为2的最大池化层；所以没有那么多超参数，最大的优势是简化了网络的结构。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/17.png" alt="1"></p><p>此外还有VGG-19，比VGG16更加深邃，但是性能核VGG-16不相上下，所以大家通常使用VGG-16。</p><h2 id="残差网络（ResNet）"><a href="#残差网络（ResNet）" class="headerlink" title="残差网络（ResNet）"></a>残差网络（ResNet）</h2><p>He K, Zhang X, Ren S, et al. Deep Residual Learning for Image Recognition[J].  2015:770-778. </p><p>很深的网络是很难训练的，因为存在梯度消失或者梯度爆炸，普通的网络训练误差和层数的关系如下图所示。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/19.png" alt="1"></p><p>所以何大佬提出残差网络，其思想是加入直接向更深层传导梯度的路径。从此，巨深的网络变为可能，甚至可以超过100层。其基本结构<code>残差块（residual block）</code>如下图所示，其中的弧线被称为<code>short cut</code>或者<code>skip connection</code></p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/18.png" alt="1"></p><p>即有</p><script type="math/tex; mode=display">a^{[l+2]}=g(z^{[l+2]}+w_sa^{[l]})=g(w^{[l+2]}a^{[l+1]}+b^{[l+2]}+w_sa^{[l]})</script><p>其中$w_s$为了保证，相加的矩阵维度相同；不过由于残差网络基本使用same卷积，所以常常为单位矩阵。假设$l+1$层和$l+2$层是在原网络基础上增加的；如果他们的参数均为0，即它们什么都没有学习到，那么考虑到Relu函数的特性与$a$基本大于0，$a^{[l]}$直接传导到最后，并没有什么危害；如果新加的两层学习到了一些特征，那么网络的效果就会增强，这是残差块效果的基本理解。典型的plain网络转化为残差网络如下图所示，很明显是在VGG的基础上改进的。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/20.png" alt="1"></p><h2 id="1×1的卷积核"><a href="#1×1的卷积核" class="headerlink" title="1×1的卷积核"></a>1×1的卷积核</h2><p>Lin M, Chen Q, Yan S. Network In Network[J]. Computer Science, 2013. </p><p>1×1卷积（又称<code>network in network</code>）看起来没什么作用，不过从另外一个角度来看，可以被认为是共用卷积核为权重的全连接网络。虽然在林敏的论文里的架构并没有得到广泛应用，但是1×1卷积却很有影响力，包括下节的Inception都受到它的启发。它的作用在于可以压缩或者增加通道的数量！</p><h2 id="Inception网络"><a href="#Inception网络" class="headerlink" title="Inception网络"></a>Inception网络</h2><p>Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]// IEEE  Conference on Computer Vision and Pattern Recognition. IEEE, 2015:1-9. </p><p>当构建卷积层的时候，要设计卷积核的大小、需不需要池化层，而Inception的作用在于代替人做决定。虽然导致了网络更加复杂，但是表现却非常好。其核心原理如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/21.png" alt="1"></p><p>它将左边的输入分别用不同大小的same卷积层和same池化层进行操作后拼接在一起，从而获得一个256通道的输出，由计算机决定各个卷积核的大小以及是否需要池化层。然而如果之后直接对深度为256的输入进行卷积操作，比如用32个5×5的same卷积核，那么浮点乘法计算量将到达1.2亿次！这是不能忍受的，所以还会加入一层1×1的卷积层，称为<code>瓶颈层（bootleneck layer）</code>从而减小计算量，如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/22.png" alt="1"></p><p>浮点计算量下降到了1.24千万次。事实证明，只要合理地设计好1×1的卷积层，并不会降低网络的性能。一个典型的Inception组件如下图所示。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/23.png" alt="1"></p><p>最后，典型的Inception网络十分地庞大。其中，黄色的分支是让隐藏层的输出也参与训练，从而避免过拟合。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/24.png" alt="1"></p><h2 id="使用经典模型的建议"><a href="#使用经典模型的建议" class="headerlink" title="使用经典模型的建议"></a>使用经典模型的建议</h2><h3 id="使用开源的解决方案"><a href="#使用开源的解决方案" class="headerlink" title="使用开源的解决方案"></a>使用开源的解决方案</h3><p>由于神经网络的复杂性，它们很难被复制，即便是顶尖大学的学生也很难通过阅读他人的论文复制研究成果（而复制是进行进一步研究的第一步）。幸运的是很多深度学习研究者都习惯吧自己的成果开源到Github之类的网站上，所以吴老师也推荐我们把代码放到上面。而在我们阅读文献后，吴老师建议我们去网上找一个开源的实现（实际上吴老师自己也常常这么做），通常比从头开始要容易得多。</p><p>下面吴老师竟然实操如何下载GitHub的代码！他用了一个更高端的方法如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> URL</span><br></pre></td></tr></table></figure><h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>迁移学习的概念此前已经有所叙述。将开源网络下载下来后，根据自己的需要对其进行修改，建议是冻结保留的开源网络的参数，只训练自己加入的参数，这样可能用很小的数据集就可以获得很强性能——幸运的是很多数据集都支持这种操作，常见的是设置<code>trainableParamer=0</code>或<code>freeze=1</code>。另外一个方法是先用保留的网络计算训练集，将得到的特征存入硬盘，再用这些训练比如一个简单的softmax网络。</p><p>如果自己的数据集比较大，可以冻结更少的层，没冻结的层可以接着用，也可以去掉换为自己的网络。如果自己的数据集特别大，那就不要冻结啦。计算机视觉应该是用迁移学习最多的领域了。</p><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>和其他领域不同，计算机视觉的数据集的大小总显得不足，因此需要扩充数据集。最简单的是镜像对称和随机裁剪，使用旋转、局部扭曲等方法也没有坏处，只是比较复杂。第二类方法是色彩转换，对RGB各通道进行一些操作，比较专业的有PCA采样。</p><p>一般是一个或多个现场进程数据的读取与增强，另一个线程进行训练。</p><h2 id="计算机视觉现状"><a href="#计算机视觉现状" class="headerlink" title="计算机视觉现状"></a>计算机视觉现状</h2><p>由于计算机视觉的复杂性，所以即便已经有很多数据集也显得不够，于是计算机视觉就更加依赖于hand-engineering，收集更多的数据、设计更复杂的模型等等。幸运的是我们还有迁移学习可以使用。</p><p>在竞赛中，为了在benchmark中脱颖而出，有以下两个建议，虽然不建议在工业界使用：</p><ol><li><code>集成（ensembling）</code>，独立训练多个神经网络并平均它们的输出。</li><li>在测试的时候使用<code>muti-crop</code>，即将一幅图及其镜面图取上下左右中共10个作为数据增强。</li></ol><p>使用开源资源的3个阶段：论文架构、架构的开源实现、迁移学习</p><h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="目标定位"><a href="#目标定位" class="headerlink" title="目标定位"></a>目标定位</h2><p><code>图像分类（Image Classification）</code>是指给每张图片打上一个标签，比如车；<code>目标分类定位（Object Classification with localization）</code>是指不仅打上一个标签，还要用方框指出，比如车的具体位置；<code>目标检测（Object Detection）</code>是本周的重点，也是近几年得益于自动驾驶研究快速发展的技术，是指识别图片中的多个物体并指出其位置，例如图中所有的车、人、路灯等等。由于分类与定位是检测的基础，所以从前两者开始讲起。</p><p>我们已经很熟悉图像分类问题了，先卷积再全连接最后用softmax输出结果。在目标定位中，需要在结果中加入位置信息，可以使用$b_x,b_y,b_h,b_w$来描述目标位置，其含义如下图所示。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/25.png" alt="1"></p><p>如果一共要分为3类，输出常见的形式如下所示</p><script type="math/tex; mode=display">y=\begin{bmatrix}  p_c \\ b_x\\ b_y\\ b_h\\ b_w \\ c_1 \\c_2 \\ c_3\end{bmatrix}</script><p>其中$p_c$指示是否有合理的分类，若$p_c=0$则其余的参数都没有任何意义。于是损失函数可以有如下的形式</p><script type="math/tex; mode=display">L(\hat{y},y)=y_1\sum_{i=1}^n{(\hat{y}_i-y_i)^2} + (1-y_1)(\hat{y}_1-y_1)^2</script><p>当然这只是举例，比如$p_c$也可以使用逻辑回归的形式。</p><h2 id="特征点检测"><a href="#特征点检测" class="headerlink" title="特征点检测"></a>特征点检测</h2><p>上一部分用方框表示物体的位置，完全可以推广为<code>特征点（landmark）</code>，比如人脸识别和<code>人体姿态检测（people pose detection）</code>：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/26.png" alt="1"></p><h2 id="基于滑动窗口的目标检测"><a href="#基于滑动窗口的目标检测" class="headerlink" title="基于滑动窗口的目标检测"></a>基于滑动窗口的目标检测</h2><p>有了图像识别乃至目标定位的神经网络，我们可以使用不同大小的矩形作为窗口并选择一定的步长进行滑动操作，使用神经网络对每一次分割得到的图片进行分类或定位，从而实现目标检测。如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/27.png" alt="1"></p><p>显然，这种方法计算量巨大。传统使用的简单的线性分类器，而在神经网络的时代，这似乎是无法忍受的。幸运的是，计算成本的问题已经有了很好的解决解决方案，大大提高了在CNN上应用滑动窗口方法的效率。</p><h2 id="滑动窗口的卷积实现"><a href="#滑动窗口的卷积实现" class="headerlink" title="滑动窗口的卷积实现"></a>滑动窗口的卷积实现</h2><p>Sermanet P, Eigen D, Zhang X, et al. OverFeat: Integrated Recognition,  Localization and Detection using Convolutional Networks[J]. Eprint  Arxiv, 2013. </p><p>全连接层是可以被卷积层代替的，只要卷积核和输入的大小完全相同即可：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/28.png" alt="1"></p><p>于是将上面的神经网络训练好后输入一张较大的图：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/29.png" alt="1"></p><p>同时输出了所有滑动窗口的结果！这就实现了加速。</p><h2 id="YOLO算法"><a href="#YOLO算法" class="headerlink" title="YOLO算法"></a>YOLO算法</h2><h3 id="边界矩形预测"><a href="#边界矩形预测" class="headerlink" title="边界矩形预测"></a>边界矩形预测</h3><p>Redmon J, Divvala S, Girshick R, et al. You only look once: Unified,  real-time object detection[C] Proceedings of the IEEE conference on  computer vision and pattern recognition. 2016: 779-788. </p><p>有了滑动窗口的卷积实现，结合目标定位的方法，就可以预测目标的<code>边界矩形（bounding box）</code>了，输出是一个3维的矩阵，通道数就是每个窗口的特征数，第一个通道$p_c$表示为某一分类的概率。这个算法被称为YOLO算法，由于采用卷积的方式，所以快到可以实时识别。此外，此时$b_x,b_y\in[0,1],b_h,b_w&gt;0$，因为边界矩阵可能不局限于一个窗口内。</p><p>实际上，原论文中的实现更加复杂，这里只是一个合理的方法。不过原论文的难度相当大，吴老师也是和其他大佬讨论后才搞明白的。</p><h3 id="交并比"><a href="#交并比" class="headerlink" title="交并比"></a>交并比</h3><p><code>交并比（intersection over union）</code>函数，即交集比上并集，可以用来改善上述网络的结果：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/30.png" alt="1"></p><p>通常认为交并比大于0.5就是一个正确的预测，当然也可以另外设定。更广泛的，交并比可以衡量任意两个box的重叠程度。</p><h3 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h3><p>目前为止学习的算法都存在一个问题：同一个物体会被多次检测。典型的情况如下图所示：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/31.png" alt="1"></p><p><code>非极大值抑制（non-max suppression）</code>可以解决这个问题其思路是：去除所有$p_c$过小（比如0.6以下）的边界矩形，然后重复选择$p_c$最大的矩形并删去与之有着较大（比如0.5以上）交并比的矩形直到所有矩形都被操作过。如果要检测多类物体，则需要对每一类物体单独执行一次算法。</p><h3 id="Anchor-boxes"><a href="#Anchor-boxes" class="headerlink" title="Anchor boxes"></a>Anchor boxes</h3><p>目前为止学习的算法都存在一个问题：一个窗口中只能检测出一个目标。典型的情况如下图所示：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/32.png" alt="1"></p><p>设置anchor box可以在一定程度上解决这个问题。其思想是预先定义多个不同的anchor box，比如一个站着的（anchor box 1），一个躺着的（anchor box 2），然后将特征按照anchor box的数量复制，并将训练集重新组合如下所示</p><script type="math/tex; mode=display">y=\begin{bmatrix}  p_c \\ b_x\\ b_y\\ b_h\\ b_w \\ c_1 \\c_2 \\ c_3 \\ p_c \\ b_x\\ b_y\\ b_h\\ b_w \\ c_1 \\c_2 \\ c_3\end{bmatrix}=\begin{bmatrix}  1 \\ b_x\\ b_y\\ b_h\\ b_w \\ 1 \\ 0 \\ 0 \\ 1 \\ b_x\\ b_y\\ b_h\\ b_w \\ 0 \\ 1 \\ 0\end{bmatrix}</script><p>不过如果只定义2个anchor box，并不能处理1个窗口中出现3个及以上目标的情况，也不能处理有相同anchor box的2个目标。不过考虑到当每个窗口设置得足够小的时候，这些情况发生的概率还是蛮低的。设置anchor box的意义更大程度上在于指导网络box的形状。</p><p>怎么选择anchor box呢？一般是手动指定，多达5到10个。还有一个在论文中给出的更高级的版本，使用了k-means算法对box进行聚类。</p><h3 id="整合到一起"><a href="#整合到一起" class="headerlink" title="整合到一起"></a>整合到一起</h3><p>将上述内容整合到一起就是完整的YOLO算法，再次不做赘述。YOLO几乎是目前最好的检测算法，整合了很多模型中精妙的部分。</p><h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><p>Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for  accurate object detection and semantic segmentation[C]//Proceedings of  the IEEE conference on computer vision and pattern recognition. 2014:  580-587. </p><p>在进行滑动窗口的时候，检测了很多其实并不会有什么的大块区域，所以<code>R-CNN（区域分割CNN，Region proposal CNN）</code>先将图像进行分割，之后再对相应的Window进行检测：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/33.png" alt="1"></p><p>因为整个过程有两步，所以R-CNN是很慢的，于是有很多的改进版本，包括以下的Fast R-CNN和Faster R-CNN：</p><p>Girshick R. Fast r-cnn[C] Proceedings of the IEEE international conference on computer vision. 2015: 1440-1448. </p><p>Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object  detection with region proposal networks[C] Advances in neural  information processing systems. 2015: 91-99. </p><p>吴老师还是认为YOLO算法更有前景，所以这里只是简要的介绍了一下。但是R-CNN在学界还是有很大影响力的，所以还是需要关注的。</p><h1 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h1><h2 id="什么是人脸识别"><a href="#什么是人脸识别" class="headerlink" title="什么是人脸识别"></a>什么是人脸识别</h2><p>展示了百度的刷脸进入的视频（去京东的时候也有使用），其中涉及到了<code>人脸识别（face recognition）</code>和<code>活体检测（liveness detection）</code>。活体检测也可以使用监督学习完成，但不是本部分的重点。</p><p><code>人脸验证（face verification）</code>输入图片和ID，判断是否为一个人。人脸识别较之困难多，数据库中有K个人，对于给定的输入图片，要输出图片对应人的ID或者输出没有匹配信息。如果通过人脸验证实现人脸识别，那么就对验证的准确率有很高的要求。</p><h2 id="One-shot-学习问题"><a href="#One-shot-学习问题" class="headerlink" title="One-shot 学习问题"></a>One-shot 学习问题</h2><p>人脸识别难度很大程度来自于One-shot学习问题，即训练某个人的样本很可能只有一张。一种简单的方法是用softmax网络输出，但是由于样本实在太少所以效果并不好，而且有新人加入就要重新学习整个网络吗？这显然不是一个好方法。</p><p>比较好的解决方法是学习一个“相似”函数，即输入时两张图片，输出为两者的相似度或者差异度。当两张图片的差异度小于某个阈值$\tau$，就认为时同一个人；反之则不是。</p><h2 id="Siamese-network"><a href="#Siamese-network" class="headerlink" title="Siamese network"></a>Siamese network</h2><p>Taigman Y, Yang M, Ranzato M A, et al. Deepface: Closing the gap to  human-level performance in face verification[C] Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 1701-1708. </p><p>正常的神经网络会通过softmax输出图片分类，在Siamese网络中并不会这样做，其输出就是一个，比如128维的向量（embedding）。可以理解为这个神经网络是一个巨大的函数，它的作用就是将图片转化为向量，相似的图片对应的向量间的距离比较小，不相似的图片对应的向量间距离远。</p><h2 id="triplet-loss"><a href="#triplet-loss" class="headerlink" title="triplet loss"></a>triplet loss</h2><p>Schroff F, Kalenichenko D, Philbin J. Facenet: A unified embedding for  face recognition and clustering[C]//Proceedings of the IEEE conference  on computer vision and pattern recognition. 2015: 815-823. </p><p>如何定义上述网络的损失，才能将神经网络训练好呢？通常使用三元组损失，即对于任意一个人A，再找一张ta的图片P，和一张不是ta的图片N，如果将神经网络看作函数f，我们希望有</p><script type="math/tex; mode=display">||f(A)-f(P)||^2 + \alpha \leq ||f(A)-f(N)||^2</script><p>其中$\alpha$是一个超参数，为了避免所有的输出均为$\vec{0}$。于是就可以定义损失函数：</p><script type="math/tex; mode=display">L(A,P,N)=\max(||f(A)-f(P)||^2  - ||f(A)-f(N)||^2 + \alpha,0) \\ J=\sum_{i=1}^m{L(A^{(i)},P^{(i)},N^{(i)})}</script><p>不过，随机选择的三元组是没有用的，要选择足够有难度分辩的才行：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/34.png" alt="1"></p><h2 id="人脸认证与二分类问题"><a href="#人脸认证与二分类问题" class="headerlink" title="人脸认证与二分类问题"></a>人脸认证与二分类问题</h2><p>上述模型可以改进为一个二分类问题，即将两幅图片分别输入网络，得到两个embedding后输入到一个逻辑回归的网络判别是否为同一个人。逻辑网络的训练用的损失函数很简单，比如</p><script type="math/tex; mode=display">\hat{y}=\sigma(w_i\sum_{k=1}^{128}{|f(x^{(i)})_k-f(x^{(j)})_k|}+b)</script><p>其中$x^i$是匹配的图片，$x^j$是数据库中的图片。或者是是$\kappa^2$相似度:</p><script type="math/tex; mode=display">\hat{y}=\sigma(w_i\sum_{k=1}^{128}{\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}}+b)</script><p>当然，为了计算的实时性，数据库中存储的不一定是图片，而是对应计算好的bedding。数据集如下所示：</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/35.png" alt="1"></p><h1 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h1><h2 id="什么是风格迁移"><a href="#什么是风格迁移" class="headerlink" title="什么是风格迁移"></a>什么是风格迁移</h2><p>如下图所示，不做赘述。</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/36.png" alt="1"></p><h2 id="深度学习网络究竟在学习什么"><a href="#深度学习网络究竟在学习什么" class="headerlink" title="深度学习网络究竟在学习什么"></a>深度学习网络究竟在学习什么</h2><p>Zeiler M D, Fergus R. Visualizing and  understanding convolutional networks[C] European conference on computer vision. Springer, Cham, 2014: 818-833. </p><p>通过对激活程度最高单元的可视化展示可知，神经网络的浅层往往学习的是线条、颜色、明暗等局部特征，而深层学习到的则是例如车轮、狗、人脸等高级的、全局的特征，如下图所示</p><p><img src="/2018/08/09/mooc-深度学习工程师-4-卷积神经网络/37.png" alt="1"></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>Gatys L A, Ecker A S, Bethge M. A neural algorithm of artistic style[J]. arXiv preprint arXiv:1508.06576, 2015. </p><p>最初生成网络生成的图片是一副随机初始化的早点，之后使用梯度下降优化损失函数，使得Generated图片的内容逐渐靠近Content图片，而风格逐渐靠近Style图片，所以损失函数有如下的形式：</p><script type="math/tex; mode=display">J(G)=\alpha J_{content}(C,G)+\beta J_{style}(S,G)</script><p>虽然说一般只会用一个参数，但是为了和论文保持一致用了2个。</p><h3 id="内容损失函数"><a href="#内容损失函数" class="headerlink" title="内容损失函数"></a>内容损失函数</h3><p>根据深度学习网络学习的内容，我们假设在一个预训练好的网络，比如VGG网络中第$l$层表达了图形的内容，令$a^{<a href="C">l</a>}$和$a^{<a href="G">l</a>}$是第$l$层的输出，则令</p><script type="math/tex; mode=display">J_{content}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2</script><h3 id="风格损失函数"><a href="#风格损失函数" class="headerlink" title="风格损失函数"></a>风格损失函数</h3><p>内容比较好定义，那如何定义风格呢？我们把通道数总是称为特征数，如果通道A与通道B总是同时被激活，即某两种特征总是一起出现，那么就可以认为是一种风格。令$a_{i,j,k}^{[l]}$是第$l$层在通道$k$上位于$(i,j)$的输出，则定义第$l$层的风格矩阵$G^{[l]}(n_c^{[l]}\times n_c^{[l]})$：</p><script type="math/tex; mode=display">G_{kk'}^{[l]}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}</script><p>则有</p><script type="math/tex; mode=display">J_{style}^{[l]}(S,G)=||G^{[l](S)}-G^{[l](G)}||_F^2 = \sum_{k}\sum_{k'}(G_{kk'}^{[l](S)}-G_{kk'}^{[l](G)})^2</script><p>由于加入的层数越多模拟的风格越好，所以</p><script type="math/tex; mode=display"> J_{style}(S,G)=\sum_l{\lambda^{[l]}J_{style}^{[l]}(S,G)}</script><p>综述就可以完成风格迁移。</p><h1 id="一维和三维的卷积"><a href="#一维和三维的卷积" class="headerlink" title="一维和三维的卷积"></a>一维和三维的卷积</h1><p>其实理解了2维之后，1维和3维的情况就很容易啦。1维又称序列模型，比如心电图峰值数据，典型使用RNN处理，但是仍然有人在使用CNN处理。3维由骨骼CT图像和电影。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;总的来说，这门课程比CS229容易一些，也可能是神经网络发展时间的问题，很多内容是经验上的，所以在差不多一周的学习之后，来到了最重要的部分啦。&lt;/p&gt;
&lt;h1 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积神经网络&quot; class=&quot;headerlink&quot; title=&quot;卷
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-深度学习工程师-3-结构化机器学习项目</title>
    <link href="http://wang22ti.com/2018/08/06/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-3-%E7%BB%93%E6%9E%84%E5%8C%96%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/"/>
    <id>http://wang22ti.com/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/</id>
    <published>2018-08-06T14:14:41.000Z</published>
    <updated>2018-08-09T03:54:57.965Z</updated>
    
    <content type="html"><![CDATA[<p>这一部分可能和<a href="http://wang22ti.com/2018/06/05/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE2%E2%80%94%E2%80%94%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/">学习理论</a>比较接近，但是听完后会发现十分的工程化、经验化。但是由于神经网络的复杂性，当模型表现不好时，有相当多可能的做法：</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/1.png" alt="1"></p><p>如何选择呢？</p><h1 id="正交化"><a href="#正交化" class="headerlink" title="正交化"></a>正交化</h1><p>所谓<code>正交化（orthogonalization）</code>，就是要求改变参数的时候只有一项性能指标发生改变，例如在汽车中方向盘只改变方向，油门只提高速度，刹车只减速。在机器学习中，有四个性能指标：</p><div class="table-container"><table><thead><tr><th style="text-align:center">性能指标</th><th style="text-align:center">正交化方法</th></tr></thead><tbody><tr><td style="text-align:center">fit training set well on cost function</td><td style="text-align:center">更复杂的神经网络、更好的优化算法、换一个网络架构</td></tr><tr><td style="text-align:center">fit dev set well on cost function</td><td style="text-align:center">正则化、更大的训练集、换一个网络架构</td></tr><tr><td style="text-align:center">fit test set on cost function</td><td style="text-align:center">更大的开发集</td></tr><tr><td style="text-align:center">performs well in real world</td><td style="text-align:center">改变开发集或者损失函数</td></tr></tbody></table></div><p>由于early stopping不是一个正交化的方法，所以吴老师很少使用。</p><h1 id="单一数字评估指标"><a href="#单一数字评估指标" class="headerlink" title="单一数字评估指标"></a>单一数字评估指标</h1><p>当开始机器学习项目的时候，设置单一的评估指标是很有效的，只要观察该指标就知道模型是变好了还是变坏了。比如<code>查全率（precision）</code>和<code>查准率（recall）</code>的调和平均数，比如各个分指标的加权平均数。另外一个方法是将某一个指标作为优化目标，其他指标作为约束条件，建立一个简单的优化模型。</p><p>其中精确率和召回率的定义如下</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/2.png" alt="1"></p><script type="math/tex; mode=display">Precision = \frac{TP}{TP+FP} \\ Recall = \frac{TP}{TP+FN}</script><h1 id="训练-开发-测试集划分（一）"><a href="#训练-开发-测试集划分（一）" class="headerlink" title="训练/开发/测试集划分（一）"></a>训练/开发/测试集划分（一）</h1><p>除了单一的指标，开发集的选择也是十分重要的，要保证训练集的分布和开发集是基本相同的。在机器学习时代，训练集和测试集的比例是7:3或者三者的比例是6:2:2。当数据比较少的时候是合理的，比如100到10000。但是在深度学习的时代需要更大的数据集，比例可能为98:1:1。由于测试集是用在系统开发完之后用以对系统性能进行评估的，所以大小要使得评估结果有足够的置信度。</p><p>如果发现评估指标和预期效果不一致的时候，需要改变开发/测试集或者指标。不一致的原因可能是有意想不到的额外因素，比如在对猫的分类中的色情图片；还有可能是测试集和开发集的分布意外的不同，比如一个是精美的专业的，另外一个是随意的业余的。</p><h1 id="和人的水平进行对比"><a href="#和人的水平进行对比" class="headerlink" title="和人的水平进行对比"></a>和人的水平进行对比</h1><p>比较机器和人的表现的原因为：机器学习的效果变好了，甚至在一些领域接近了人的水平；当机器的水平超过人类时，得益于其效率会有很好的产出。更重要的是，人在很多领域已经做得很好，十分接近理论最优（Bayes optimal），如下图所示</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/3.png" alt="1"></p><p>之所以机器在超过人之后进步会变慢，一方面是因为人的水平已经十分接近贝叶斯误差了，另一方面更重要的是在此之后又很多本来可以使用的方法变得无效了，比如通过人的努力获得标注的训练数据、依靠人的观察力分析哪里还可以提高，方便的误差方差分析……根本来说，此前是依靠人的基础的、感性的智慧取得进步，而后的进步则来自人更加抽象、高级的智慧了。</p><p>其中，什么是方便的误差方差分析呢？如果将人的水平作为贝叶斯误差的近似，则人小于训练集的误差称为<code>可避免误差（avoidable error）</code>，将训练集小于开发集上的误差称为方差，则当可避免误差大于方差的时候，可以认为模型还不够好，误差大于方差；反之则方差大于误差。这在很多场合比直接将贝叶斯误差设为0要好得多。</p><p>要知道常言道，人与人的差距比人与狗的差距还大，人的哪一种水平可以作为贝叶斯误差的估计呢？一般人的业余水平？普通职业水平？高的职业水平？高水平职业团队水平？比如在医学骨骼鉴别中分别为3%以上、1%、0.7%、0.5%，于是我们知道贝叶斯误差一定小于0.5%，所以尽可能使用最小的误差作为人类水平。当然，这样的训练样本也很难得，很多论文中对于人类水平的定义也不一样，一般只要超过普通职业水平，就也可以被认为也是人类水平，这样的系统也具备了部署的价值。</p><p>如果机器已经超过了人了，该怎么办呢？此时无法得知是模型过拟合了还是人类水平没有达到贝叶斯误差的水平。如果此前规定的人类水平是高水平职业团队的，那么很难依靠直觉判断进一步优化的方向。这样的问题包括在线广告推荐、产品推荐、物流预测、偿款预测等等，而这些问题都是有海量结构化的数据的，没有自然感知。而在自然感知领域，机器还是很难超过人类的，实现的包括部分的语音识别、图像识别、医学任务。</p><h1 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h1><p>当模型还没有达到人的水平的时候，应该人工检查算法中犯的错误，这就是<code>误差分析（error analysis）</code>，它可以告诉我们这个错误是否值得被改进。比如一个识别猫的程序，在预测值为猫的图片里存在一定数量的狗，要不要花很长时间去设计排除狗的算法呢？我们需要手动地一张一张看开发集中被标记为猫的图片里有多少的狗，如果狗占了50%，那么是可能值得的，因为可以使误差一下下降一半；如果是5%，那么就要很慎重地考虑了。这类似于体系结构中的Amdahl定律，把精力花在最重要的事情上。</p><p>有时在做误差分析的时候可以同时并行评估几个想法。比如有多个改进识别猫的程序，剔除狗的影响、剔除大型猫科动物的影响、更好地处理模糊图像，可以画出下面的这张表：</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/4.png" alt="1"></p><p>中途也可以加入新的列比如滤镜。最后很容易地，在这个例子中，应该优先优化模糊和大型猫科动物。</p><p>在误差分析中，如果发现有些训练样本中的标签是错误的该怎么办呢？由于深度学习算法对训练集中的随机误差具有相当好的健壮性，所以如果确认训练样本中的错误足够随机，比如偶然地敲错键盘，那么不管他可能也没什么问题。但是算法对于<code>系统性（systematic）</code>的误差就没有那么健壮了，比如某个人一直把白色的狗标记为猫。</p><p>如果错误是在开发集或者测试集上呢？那么就在上图中增加一列统计错误标记的比例，并增加一定的备注。如果发现这个比例已经影响到结果的评估了，即错误标记带来的误差在所有误差中的比例已经很大了，那么就去修正它。修正要同时在开发和测试集合进行，以确保它们是同分布的；同时无论算法是否预测正确的样本，都应该被修正，否则偏差可能更大；此外保持开发和测试集合同分布是很重要的，训练集是可以略有不同的，也是很常见的。</p><p>总之，要承认这种方法是有重大意义的，虽然没有什么技术含量，虽然十分无趣繁琐，但是确实要这么做，也不用羞于承认自己这么做。</p><h1 id="用快速原型-迭代的方法开发系统"><a href="#用快速原型-迭代的方法开发系统" class="headerlink" title="用快速原型+迭代的方法开发系统"></a>用快速原型+迭代的方法开发系统</h1><p>对于一个采用神经网络解决的问题，改进的方法实在是太多了，不可能面面俱到。所以一般的策略是</p><ol><li>设计开发/测试集以及单一的数字评估指标</li><li>建立快速简陋的模型</li><li>使用偏差/方差权衡以及误差分析确定主要因素</li><li>根据主要因素迭代改进</li></ol><p>如果在该领域十分有经验，那么原型可以稍微复杂一些；如果在该领域，准确的说是该问题已经有相当成熟的论文，那么可以更复杂一些。但是无论如何吴老师都不推荐第一次处理某问题就使用十分复杂的模型。大多数团队都是想得太复杂导致浪费了时间。</p><p>当然，如果目标不是解决某个问题，而是提出新的机器学习算法，就另当别论了，这是完全不同的目标。</p><h1 id="训练-开发-测试集划分（二）"><a href="#训练-开发-测试集划分（二）" class="headerlink" title="训练/开发/测试集划分（二）"></a>训练/开发/测试集划分（二）</h1><p>开发测试集的分布必须相同，而训练集和它们基本相同即可，并不需要完全相同。比如有20万张爬虫得到的图片，1万张用户上传的图片，正确的做法不是将它们完全混合打散后进行划分，而是留一部分用户的图片，比如5000张单独作为开发集和训练集，剩下的和所有爬虫得到的混合后作为训练集。</p><p>需不需要把收集到的数据都用掉？不一定。当在训练集表现良好而在开发集反之时，由于训练集的分布和开发集的分布不同，比如训练集都是清晰容易识别的图片而开发集都是模糊难识别的，所以此时并不能断言模型过拟合了。要弄清楚是过拟合还是分布不同，需要再定义一个<code>训练-开发集（Training-dev set）</code>，它的分布和训练集相同（即从训练集中随机抽取），但是不会用于训练，而是用来作为和开发集的对照组。在方差很大的情况下，如果训练-开发误差和训练误差相差很大，那么可以断言是过拟合了；反之则说明方差来自于训练集和开发集的分布不同，或者叫<code>数据不匹配（data mismatch）</code>。</p><p>所以最终关注的数据有人类水平误差、训练集误差、训练-开发集误差、开发误差、测试误差，在大多数情况下它们是递增的，相邻两项的差距分别表示了可避免偏差、方差、数据不匹配、开发集过拟合几个问题。在不同的情况下，牢记它们的定义和分布这个概念，分析起来不会吃力的。还可以结合下面这张表</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/5.png" alt="1"></p><h1 id="处理数据不匹配"><a href="#处理数据不匹配" class="headerlink" title="处理数据不匹配"></a>处理数据不匹配</h1><p>如果误差主要是数据不匹配导致的，该如何处理呢？其实并无完全系统的方法，不过可以手动查看进行误差分析，搞清楚训练集和开发集之间的不同。比如语音后视镜的输入可能比一般语音输入有更多的地址，比室内的输入有更多的噪音。这样可以用各种方法，比如用<code>人工合成数据（artificial data synthesis）</code>加入噪音，使用生成对抗模型，有意识地收集更多相似数据，使得训练集更像开发集。</p><p>合成数据的时候需要注意的是，如果有1万小时的纯净语言和1小时的噪声，虽然人听起来没什么问题，但是模型很容易对噪音过拟合。同样的，用模型生成的车，或者一个游戏中出现的车来训练车的识别网络，也很有可能对那些车过拟合。</p><h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p>当在开发智能后视镜的时候，如果已经有1万小时一般语音输入训练好的网络，而专门用于后视镜的语音只有1小时，怎么办呢？有人提出了<code>迁移学习（transfer learning）</code>，即利用已经训练好的网络对底层特征的把握，对其作修改后利用少量数据就可以完成模型的训练。如下图所示，将最后一层网络更换为了随机初始化的多层网络。</p><p><img src="/2018/08/06/mooc-深度学习工程师-3-结构化机器学习项目/6.png" alt="1"></p><p>如果新的数据很少，那么只训练新的最后的网络；反之可以对所有参数重新训练，对原网络的训练称为<code>预训练（pre-training）</code>，对新网络中原网络部分的训练称为微调<code>（fine tuning）</code>。</p><p>什么时候迁移学习是有效的呢？当然，任务A和任务B必须有相同的输入，比如图片或语音，其次任务A的数据比任务B的多得多，最后是任务A的特征对任务B是有意义的。由于单个任务A的数据对于任务B的价值一定小于任务B本身的数据，所以当没有满足第二个条件的时候，就不必如此劳神了。</p><h1 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h1><p>迁移学习的过程是串行的，在<code>多任务学习（muti-task learning）</code>中，单个神经网络同时进行多个任务，从每个任务学习到的知识都可以帮助其他任务的应用。比如在图像识别中要辨别有没有车、人、路牌、信号灯，正常是训练4个网络，但也可以只训练一个。该网络的输出是一个4维0-1向量，分别指示有没有对应的物体，和softmax不同的是可以判定同时出现了多个物体。其损失函数为</p><script type="math/tex; mode=display">\frac{1}{m}\sum_{i=1}^{m}{ \sum_{j=1}^4{L(\hat{y}_j^{(i)},y_j^{(i)})} }</script><p>其中$L$通常是用逻辑回归的交叉熵。由于识别这几个物体都需要使用几个十分底层的特征，所以同时训练4个任务反而比分别训练效果要好。如果一张图片只有部分标签，如有人无车，而不知道有没有路牌和信号灯怎么办呢？并不影响，求和中只对有标记的操作即可。总结起来，多任务学习使用的条件有：</p><ol><li>多个任务之间共享相同的底层特征</li><li>通常情况下，每个任务的数据量是相似的</li><li>可以训练一个可以处理所有任务的大型网络</li></ol><p>多任务学习和迁移学习相比并不那么常用，不过物体检测是个例外。</p><h1 id="端到端学习"><a href="#端到端学习" class="headerlink" title="端到端学习"></a>端到端学习</h1><p>近期神经网络最大的进展就是<code>端到端学习（end-to-end learning）</code>的兴起，简而言之以前一些任务需要多个环节才能完成，而现在用一个神经网络去代替（这让很多从事多年中间件的人很头大）。端到端学习的一个挑战是需要大量的数据。所以在数据量小的时候，传统的方法也是很好的。比如门禁系统先识别脸的位置，之后再用所有员工的脸与之比对；机器翻译中需要先提取文本特征，之后逐个转换并组合；从图片判断骨骼年龄需要分割每块骨骼，然后根据每一块的结果得到结论。</p><p>如何判断端到端学习是否适用呢？首先要理解端到端学习的优缺点。其优点包括</p><ol><li>真正的“让数据说话”，即完全依靠神经网络去提取统计特征，不加入任何人类的知识，尤其是成见。比如早期语音识别系统中强迫机器识别音节——这可能对人类语言学家来说是有意义的，但是可能对机器来说是没有意义的。</li><li>减少了组件的设计，简化了工作流程。</li></ol><p>其缺点包括：</p><ol><li>需要大量的端到端数据。</li><li>排除了一些的确很有用的人工设计的组件，即没有利用已有的人的智慧，虽然机器学习研究者都很鄙视手动设计的东西。但是神经网络的知识一方面来自数据，另一方面来自人；当有成吨的数据的时候，人的知识当然并不重要，不过在数据不大的时候，精心设计的组件确实可以将知识直接注入网络。</li></ol><p>于是，决定时候使用端到端学习的因素就是：是否有足够多的端到端数据，使得网络能够学到足够复杂的端到端映射。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这一部分可能和&lt;a href=&quot;http://wang22ti.com/2018/06/05/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-深度学习工程师-1-神经网络和深度学习</title>
    <link href="http://wang22ti.com/2018/07/31/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://wang22ti.com/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/</id>
    <published>2018-07-31T11:56:00.000Z</published>
    <updated>2018-08-12T06:55:58.975Z</updated>
    
    <content type="html"><![CDATA[<p>这部分是在学习完斯坦福CS229中监督学习和学习理论两部分后学习的，分类还是机器学习。</p><p><a href="http://wang22ti.com/2018/05/25/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE1%E2%80%94%E2%80%94%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">mooc-吴恩达老师在斯坦福大学的机器学习公开课1——监督学习</a></p><p><a href="http://wang22ti.com/2018/06/05/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE2%E2%80%94%E2%80%94%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/">mooc-吴恩达老师在斯坦福大学的机器学习公开课2——学习理论</a></p><p>这是第一章——神经网络与深度学习。</p><h1 id="深度学习概论"><a href="#深度学习概论" class="headerlink" title="深度学习概论"></a>深度学习概论</h1><h2 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a>什么是神经网络</h2><p>标准的开头，是以房屋价格预测引出了<code>Relu（Rectified Linear Unit，修正线性单元）</code>函数和<code>神经元（neuron）</code>的概念，以及如下图的多层神经网络：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/1.png" alt="1"></p><h2 id="用神经网络进行监督学习"><a href="#用神经网络进行监督学习" class="headerlink" title="用神经网络进行监督学习"></a>用神经网络进行监督学习</h2><p>现有的有实际应用价值的神经网络大多数属于监督学习，对于分类和回归的基本介绍，给出了一些例子：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/2.png" alt="2"></p><p>给出了<code>卷积神经网络（CNN，Convolution Neural Network）</code>、<code>循环神经网络（RNN，Recurrent Neural Network）</code>、<code>结构化数据（structured data）</code>、<code>非结构化数据（Unstructured data）</code>的概念。其中CNN主要用于处理图片，RNN主要用于处理一维序列数据，在自动驾驶中需要使用混合的网络。</p><h2 id="为什么深度学习会兴起"><a href="#为什么深度学习会兴起" class="headerlink" title="为什么深度学习会兴起"></a>为什么深度学习会兴起</h2><p>深度学习的兴起得益于信息化社会产生的大量数据、更快的运算速度和神经网络算法的发展创新。和传统的机器学习算法相比，深度学习的优势表现在处理大规模<code>带有标记（labeled）</code>的数据上。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/3.png" alt=""></p><p>其中，更快的运算速度也给算法的改进带来的便捷与可能：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/4.png" alt=""></p><h1 id="神经网络基础"><a href="#神经网络基础" class="headerlink" title="神经网络基础"></a>神经网络基础</h1><h2 id="二分分类（binary-classification）"><a href="#二分分类（binary-classification）" class="headerlink" title="二分分类（binary classification）"></a>二分分类（binary classification）</h2><p>在图像的二分类问题（判断是不是猫）中，将$64<em>64</em>3$的图片的特征向量定义为$x_{(64<em>64</em>3)*1}$。目标是以$x$作为输入，输出结果标签$y\in\{0,1\}$。和之前不同的是，在样本矩阵$x\in\R^{n\times m}$中，单个样本是以列向量的形式出现的；而$y \in \R^{1\times m}$。</p><h2 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a>logistic回归</h2><p>先介绍了sigmoid函数，不赘述。</p><p>接着是logistic回归的损失函数，由于最小二乘法在这里不是凸优化问题，所以使用Loss函数和Cost函数（前者用于单样本，后者用于多样本）：</p><script type="math/tex; mode=display">L(\hat{y},y)= -(y\log{\hat{y}}+(1-y)\log{(1-\hat{y})})  \\ J(\theta)=\frac{1}{m}\sum_{i=1}^{m}{L(\hat{y}^{(i)},y^{(i)})}</script><p>之后讲了梯度下降和导数，不赘述。</p><h2 id="计算图（Computation-Graph）"><a href="#计算图（Computation-Graph）" class="headerlink" title="计算图（Computation Graph）"></a>计算图（Computation Graph）</h2><p>计算图解释了神经网络优化过程中的前向和后向，如下图所示</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/5.png" alt=""></p><h2 id="logistic回归中的梯度下降"><a href="#logistic回归中的梯度下降" class="headerlink" title="logistic回归中的梯度下降"></a>logistic回归中的梯度下降</h2><p>先将了逻辑回归中单样本的梯度下降，即计算每一个参数的偏导数后减去与学习率的乘积，这里用到了链式法则。和在机器学习课程中学到的，最后的形式和梯度下降很像。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/6.png" alt=""></p><p>之后是$m$个样本的情况：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/7.png" alt=""></p><h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>注意到上述的优化算法有2层显式循环，在数据量越来越大、规模越来越大的神经网络中，这显然是不可接受的，所以引入<code>向量化（Vectorization）</code>对其加速。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(<span class="number">10000000</span>)</span><br><span class="line">b = np.random.rand(<span class="number">10000000</span>)</span><br><span class="line"></span><br><span class="line">tic = time.time()</span><br><span class="line">c = np.dot(a, b)</span><br><span class="line">toc = time.time()</span><br><span class="line">print(c)</span><br><span class="line">print(<span class="string">"Vectorized version:"</span>, <span class="number">1000</span> * (toc - tic), <span class="string">"ms"</span>)</span><br><span class="line"></span><br><span class="line">tic = time.time()</span><br><span class="line">c = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> a_, b_ <span class="keyword">in</span> zip(a, b):</span><br><span class="line">    c += a_*b_</span><br><span class="line">toc = time.time()</span><br><span class="line">print(c)</span><br><span class="line">print(<span class="string">"Vectorized version:"</span>, <span class="number">1000</span> * (toc - tic), <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure><p>从表面上看，向量化只是使用了<code>np.dot()</code>一类的函数代替了for-loop的过程；实质上是因为这一类函数使用了<code>SIMD（single instruction multiple data）</code>的并行指令，这在CPU和GPU上都是成立了，只不过GPU更擅长。在吴恩达老师的电脑上取得了约300的加速比，我的也差不多：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/8.png" alt=""></p><p>经验法则是：<code>尽可能地避免使用显式的For-loop循环</code>。在python中numpy中就有很多向量化的函数。</p><h2 id="向量化的logistic回归"><a href="#向量化的logistic回归" class="headerlink" title="向量化的logistic回归"></a>向量化的logistic回归</h2><p>利用向量化的表达方式，可以将logistic中的for-loop循环替代掉，示意代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loop = <span class="number">100</span></span><br><span class="line">m, n = <span class="number">10</span>, <span class="number">3</span></span><br><span class="line">b = <span class="number">0</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">X = np.zeros(shape=(n, m))</span><br><span class="line">Y = np.zeros(shape=(<span class="number">1</span>, m))</span><br><span class="line">W = np.zeros(shape=(n, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(loop):</span><br><span class="line">    <span class="comment"># 正向</span></span><br><span class="line">    Z = np.dot(W.T, X) + b</span><br><span class="line">    A = sigmoid(Z)</span><br><span class="line">    <span class="comment"># 反向</span></span><br><span class="line">    dZ = A - Y</span><br><span class="line">    dW = np.dot(X, dZ.T) / m</span><br><span class="line">    db = np.sum(dZ) / m</span><br><span class="line">    W -= alpha * dW</span><br><span class="line">    b -= alpha * db</span><br></pre></td></tr></table></figure><h2 id="python中的广播与向量"><a href="#python中的广播与向量" class="headerlink" title="python中的广播与向量"></a>python中的广播与向量</h2><p>为了使得代码更加高效、简洁，numpy引入了<code>广播（broadcast）</code>的机制，可以让shape不同的ndarray直接按元素进行四则运算。上述代码中已经有所展示，其基本规则如下图所示：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/9.png" alt=""></p><p>其优势在于提高了代码的表现力，一行代码可以完成很多操作；缺点在于可能因此写出很难修改的bug。类似地可以运行以下的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.random.randn(<span class="number">5</span>)</span><br><span class="line">print(X.shape)</span><br><span class="line">print(np.dot(X, X.T))</span><br><span class="line"></span><br><span class="line">X = np.random.randn(<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">print(X.shape)</span><br><span class="line">print(np.dot(X, X.T))</span><br></pre></td></tr></table></figure><p>会有如此输出：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/10.png" alt=""></p><p>之所以不同是因为X = np.random.randn(5)返回的ndarray的<code>秩（rank）</code>为1，即它既不是一个行向量也不是一个列向量。所以为了避免如此带来的错误，在编写神经网络的时候要避免使用rank=1的ndarray；如果因为某种原因生成了，要使用reshape()函数将之转换为行向量或列向量。同时也可以使用声明机制保证避免这样的事情发生：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span>(a.shape == (<span class="number">5</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h2 id="Jupyter-Ipython笔记本的快速指南"><a href="#Jupyter-Ipython笔记本的快速指南" class="headerlink" title="Jupyter/Ipython笔记本的快速指南"></a>Jupyter/Ipython笔记本的快速指南</h2><p>哇，看到这里简直被吴老师的良心所感动，一个泰山北斗级的巨佬亲自教我们如何避免写代码的bug也就罢了，还专门教如何使用工具。他的ipython是用在Coursera，不过很快我也发现Pycharm也支持：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/11.png" alt=""></p><p>这个东西充分利用了makrdown和python的交互特性，使得可以在markdown中嵌入可执行的代码块，名副其实地适合当Notebook。不过我的笔记都是放在博客上的，所以就还是使用py的格式吧哈哈。</p><h2 id="logistic回归损失函数的解释"><a href="#logistic回归损失函数的解释" class="headerlink" title="logistic回归损失函数的解释"></a>logistic回归损失函数的解释</h2><p>见监督学习的笔记，不赘述。</p><h1 id="浅层神经网络"><a href="#浅层神经网络" class="headerlink" title="浅层神经网络"></a>浅层神经网络</h1><h2 id="神经网络概览"><a href="#神经网络概览" class="headerlink" title="神经网络概览"></a>神经网络概览</h2><p>最基本的神经网络可以看作神经元的叠加，其中用带有中括号的上标表示表示层数，比如</p><script type="math/tex; mode=display">z^{[1]}=W^{[1]}x+b^{[1]}</script><p>不用小括号是因为小括号的上标表示样本数。</p><h2 id="神经网络的表示"><a href="#神经网络的表示" class="headerlink" title="神经网络的表示"></a>神经网络的表示</h2><p>如蓝色所示，神经网络分为输入层、隐藏层和输出层。在计算层数的时候，不考虑输入层，所以如红色所示，这是一个2层的神经网络。为了统一的表达，输入向量$X$被记为$a^{[0]}$，输出$\hat{y}$被记为$a^{[2]}$，a表示activation即激活的意思。类似的，每一层的参数如右下角的紫色所示。除了输入层每一层的激活函数都有参数，如绿色所示。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/12.png" alt=""></p><p>对于上图的神经网络，需要注意的是向量化后每层输入输出的维数，这是单样本的情况：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/13.png" alt=""></p><p>多样本的情况，实际就是继续进行<code>堆叠（stack）</code>，从表示上换成大写字母，上述维度为1的矩阵换为样本数量：</p><script type="math/tex; mode=display">Z^{[1]}= W^{[1]}X+b^{[1]} \\ A^{[1]}=\sigma(z^{[1]}) \\ Z^{[2]}=W^{[2]}A^{[2]}+b^{[2]} \\ A^{[2]}=\sigma(Z^{[2]})</script><p>于是我们完成了2层神经网络的向量化，其实更深的神经网络大多是重复这样的过程。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>在搭建神经网络的时候，重要的是选择隐藏层和输出层的激活函数。迄今为止我们用的激活函数都是logistic函数，这并不是唯一的选择，<a href="https://www.jiqizhixin.com/articles/2017-10-10-3" target="_blank" rel="noopener">机器之心</a>对此有所总结。</p><h3 id="tanh-z"><a href="#tanh-z" class="headerlink" title="tanh(z)"></a>tanh(z)</h3><p>双曲正切函数几乎总是比sigmoid函数表现得好，它可以看作是sigmoid函数的平移，将输出的平均值控制在0附近。</p><script type="math/tex; mode=display">g(z)=\tanh{z}=\frac{e^z-e^{-z}}{e^z+e^{-z}}\in (-1, 1)</script><p>现在几乎不使用sigmoid函数了，唯一的例外的输出层。由于不同层的激活函数可能不同，所以会在函数符号上也加上带有方括号的上标。</p><h3 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h3><p>sigmoid函数和Relu函数都有一个缺点，即当$z$过大或过小的时候函数的斜率很小，会拖慢梯度下降的速度。所以机器学习中最受欢迎的是Relu函数</p><script type="math/tex; mode=display">g(z)=max(0, z)</script><p>虽然在$z=0$处导数不存在，但是实际上遇到0向量是很罕见的，何况还可以定义一下$z=0$处的导数。Relu函数几乎已经成为激活函数的默认选择了。</p><h3 id="带泄露的Relu（leaky-Relu）"><a href="#带泄露的Relu（leaky-Relu）" class="headerlink" title="带泄露的Relu（leaky Relu）"></a>带泄露的Relu（leaky Relu）</h3><p>虽然Relu函数在$z&lt;0$时的导数为0，但是在实践中这并不影响，而且它还有一个变种叫<code>带泄露的Relu（leaky Relu）</code>，在在$z&lt;0$时的导数是一个较小的常数，在实践中带泄露的Relu表现比Relu好些。</p><script type="math/tex; mode=display">g(z)=max(\alpha z, z),\alpha \in (0, 1)</script><h2 id="为什么需要非线性的激活函数"><a href="#为什么需要非线性的激活函数" class="headerlink" title="为什么需要非线性的激活函数"></a>为什么需要非线性的激活函数</h2><p>如果使用的是恒等激活函数（线性激活函数），那么无论有多少层，输出的只不过是出入特征的线性组合，所以不如去掉隐藏层。除非引入非线性的函数，否则是得不到比线性函数更复杂的函数的。</p><p>除了一些和压缩有关的非常特殊的情况，只有在输出层才会使用线性激活函数。</p><h2 id="激活函数的导数"><a href="#激活函数的导数" class="headerlink" title="激活函数的导数"></a>激活函数的导数</h2><p>在进行反向传播的时候，必须要计算激活函数的导数。对于sigmoid函数</p><script type="math/tex; mode=display">g'(x)=g(x)(1-g(x))=a(1-a)</script><p>对于tanh函数</p><script type="math/tex; mode=display">g'(x)=1-(g(x))^2=1-a^2</script><p>Relu函数就不必赘述啦。</p><h2 id="神经网络中的梯度下降"><a href="#神经网络中的梯度下降" class="headerlink" title="神经网络中的梯度下降"></a>神经网络中的梯度下降</h2><p>2层神经网络的梯度下降在单样本的情况下如下图所示，需要牢记的是$dz$是$\frac{\part L}{\part z}$的简写，之后用链式法则从后往前求解即可。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/14.png" alt=""></p><p>在多样本的情况下很类似，其中参数<code>axis=1</code>表示横向求和，<code>keepdims=True</code>是为了避免秩为1的ndarray出现。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/15.png" alt=""></p><h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>在logistic回归中，将权重全都初始化为0是OK的，但是在神经网络中怎么做会使得梯度下降完全失效。因为所有的神经元都完全对称的，这导致所有参数每一行都是一样的，通过归纳可知在任何轮迭代之后所有的神经元都是一样的，这就提取不出新的特征，网络完全无效。所以在python中可以如此初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w_1 = np.random.randn((<span class="number">2</span>, <span class="number">2</span>)) * <span class="number">0.01</span></span><br><span class="line">b_1 = np.zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment">#......</span></span><br></pre></td></tr></table></figure><p>之所以要加上0.01的系数是防止使用sigmoid函数或tanh函数的时候梯度很小，在深层的神经网络中，可能要尝试0.01以外的数。</p><h1 id="深层神经网络"><a href="#深层神经网络" class="headerlink" title="深层神经网络"></a>深层神经网络</h1><p>深浅是相对的，有些任务只有深层的神经网络才能解决，用参数$l$表示神经网络的层数。</p><h2 id="深层网络中的前向传播"><a href="#深层网络中的前向传播" class="headerlink" title="深层网络中的前向传播"></a>深层网络中的前向传播</h2><p>有了此前的学习，可以写出前向传播的递推形式：</p><script type="math/tex; mode=display">Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} \\ A^{[l]}=g^{[l]}(Z^{[l]})</script><p>整个前向传播就是递推公式关于层数$l$的循环。</p><h2 id="核对矩阵的维数"><a href="#核对矩阵的维数" class="headerlink" title="核对矩阵的维数"></a>核对矩阵的维数</h2><p>为了减少代码中的错误，一个比较好的方法是仔细核对每一层矩阵的维数。令$n^{l}$表示第$l$行特征的数量（神经元的个数），则有：</p><script type="math/tex; mode=display">W^{[l]},dW^{[l]}:(n^{[l]},n^{[n-1]}) \\ Z^{[l]},dZ^{[l]},A^{[l]},dA^{[l]}:(n^{[l]}, m) \\ b^{[l]},db^{[l]}:(n^{[l]},1)</script><h2 id="为什么深层网络是有效的"><a href="#为什么深层网络是有效的" class="headerlink" title="为什么深层网络是有效的"></a>为什么深层网络是有效的</h2><p>一种解释是最早提取的是简单的特征，例如边缘，之后的层通过这个特征的组合可以提取更加复杂的特征，例如眼睛的轮廓，如下图所示：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/16.png" alt=""></p><p>另一种理论来自于电路理论，为了实现相同功能的电路，浅层的电路网络需要的电子原件是以指数的方式增加的：</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/17.png" alt=""></p><p>实际上“深层网络”只是“具有很多隐藏层的神经网络”的包装说法。不管公关层面的问题，深层网络的确是有效的，但是真正搭建神经网络的时候往往是从逻辑回归开始，把层数作为超参数进行调试。不过有些人十分喜欢使用特别特别深邃的神经网络，其实只有一小部分问题的确适合这么做。</p><h2 id="搭建深层神经网络"><a href="#搭建深层神经网络" class="headerlink" title="搭建深层神经网络"></a>搭建深层神经网络</h2><p>整个神经网络的计算分为前向传播和后向传播，其过程如下图中绿色箭头所示，红色箭头表示反向传播。需要注意的是前向传播的过程中需要缓存$Z^{[l]},W^{[l]},b^{[l]}$。</p><p><img src="/2018/07/31/mooc-深度学习工程师-1-神经网络和深度学习/18.png" alt=""></p><p>于是有反向传播的递推形式：</p><script type="math/tex; mode=display">dZ^{[l]}=dA^{[l]}*{g^{[l]}}'(Z^{[l]}) \\ dW^{[l]}=\frac{1}{m}dZ^{[l]}A^{[l-1]^T} \\ db^{[l]}=\frac{1}{m}np.sum(dZ^{[l]},axis=1,keepdim=True) \\ dA^{[l-1]}=W^{[l]^T}dZ^{[l]}</script><p>其实可以发现整个算法即使只使用numpy来实现也不需要特别多的代码，然而网络输出的效果有时令吴老师都吃惊，这是因为复杂性不是来自算法而是来自数据。</p><h2 id="参数与超参数"><a href="#参数与超参数" class="headerlink" title="参数与超参数"></a>参数与超参数</h2><p>神经网络的参数是指$W,b$，超参数包括学习率$\alpha$、学习的轮数、隐藏层的数量、每个隐藏层神经元的数量、激活函数的选择等等，它们控制了$W,b$最后的值，即控制参数的参数。</p><p>其实深度学习还有其他一些超参数，包括momentum、mini bathch的大小、regularizations……会在第2部分进行讲解。</p><p>由于有如此多的超参数，实际上深度学习是一个很需要经验的过程，甚至由于数据的改变同一网络也会随时间改变。简而言之就是尝试，不停地尝试直到管用。下一部分的学习就是如何用系统化的方法尝试各种超参数的设置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这部分是在学习完斯坦福CS229中监督学习和学习理论两部分后学习的，分类还是机器学习。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://wang22ti.com/2018/05/25/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化</title>
    <link href="http://wang22ti.com/2018/07/31/mooc-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88-2-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/"/>
    <id>http://wang22ti.com/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/</id>
    <published>2018-07-31T11:51:15.000Z</published>
    <updated>2018-08-12T06:58:05.982Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习的实用层面"><a href="#深度学习的实用层面" class="headerlink" title="深度学习的实用层面"></a>深度学习的实用层面</h1><h2 id="训练-开发-测试集"><a href="#训练-开发-测试集" class="headerlink" title="训练/开发/测试集"></a>训练/开发/测试集</h2><p>通常将所有的数据分为训练/开发/测试（train/development/test）三个集合，其中在传统的机器学习中占比为60/20/20，在大数据时代占比可以达到98/1/1，甚至是99.5/0.4/0.1。</p><p>有时候为了获得更大的数据集，可能导致训练集和开发测试集的分布并不相同。例如在识别猫的任务中训练集来自网络爬去，开发测试集来自网友上传，很有可能前者是制作精良的专业的而后者很随意很模糊。但无论如何开发集的数据要来自同一分布。</p><p>此外，如果不需要获得无偏误差，是可以不需要测试集的。</p><h2 id="偏差-方差"><a href="#偏差-方差" class="headerlink" title="偏差/方差"></a>偏差/方差</h2><p>几乎所有机器学习的从业人员都希望深刻理解偏差与方差，但它们易学难精，尤其是在深度学习中很少考虑偏差-方差权衡。在机器学习的基础上，该部分引入了最优误差（贝叶斯误差），提出了先偏差后方差的思路，此外不做赘述。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>当怀疑过拟合的时候，首先想到的应该是正则化，在逻辑回归中很常见的L2正则化：</p><script type="math/tex; mode=display">J(w,b) = \frac{1}{m}\sum_{i=1}^m{l(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}||w||_2^2</script><p>其中$||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^Tw$。不加上$b$的正则化项只是因为考虑到$w$已经是一个高位向量了，完全也可以加上。另外一个正则化的方法是L1正则化：</p><script type="math/tex; mode=display">\frac{\lambda}{2m}\sum_{j=1}^{n_x}|w_j|=\frac{\lambda}{2m}||w||_1</script><p>这样的正则化会导致$w$比较稀疏，有人说目的是压缩模型，但是吴老师反对这种观点。还有一个细节是lambda是python的保留字，所以要使用lambd来命名。</p><p>在神经网络中，有如下正则化表达式：</p><script type="math/tex; mode=display">J(w^{[1]},b^{[1]},\dots,w^{[l]}, b^{[l]})=\frac{1}{m}\sum_{i=1}^m{l(\hat{y}^{(i)},y^{(i)})}+\frac{\lambda}{2m}\sum_{l=1}^l{||w^{[l]}||_F^2}</script><p>其中$||w^{[l]}||_F^2=\sum_{i=1}^{n^{[l-1]}}{\sum_{j=1}^{n^{[l]}}{(w_{ij}^{[l]})^2}}$，被称为<code>弗罗贝尼乌斯范数（Frobenius norm）</code>，用下标F表示。由于线性代数的种种原因，没有叫“矩阵L2范数”，虽然这样看起来更自然。</p><p>于是就有反向传播：</p><script type="math/tex; mode=display">dw^{[l]}=(from \ back \ propgation) + \frac{\lambda}{m}{w^{[l]}}</script><p>因此弗罗贝尼乌斯范数有时被称为<code>权重衰减参数</code>，即它会占用原来反向传播的权重。吴老师在这门课对于正则化的有效性的解释也来自于此，即将模型像线性化的方向转变，从而了降低方差。</p><h3 id="Dropout正则化"><a href="#Dropout正则化" class="headerlink" title="Dropout正则化"></a>Dropout正则化</h3><p>还有一个非常实用的正则化——<code>Dropout（随机失活）正则化</code>，其基本思想是在训练每一个样本过程中随机令某些神经元失效，如下图所示：</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/1.png" alt="1"></p><p>常见gropout的实现方法是<code>反向随机失活inverted dropout</code>，以3层神经网络为例其基本过程为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">d3 = np.random.rand(a3.shape[<span class="number">0</span>], a3.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">a3 = np.multiply(a3, d3)</span><br><span class="line">a3 /= keep_prob</span><br></pre></td></tr></table></figure><p>之所以有最后一行是为了确保a3的期望不发生变化，这在测试阶段是很重要的，由于我们不希望输出是随机的，所以此时也不会有dropout。当然，keep_prob的设置完全可以根据每一层神经元的数量而不同，在神经元较多的层中较低，反之则较高甚至是1.</p><p>为什么dropout正则化是有效的？因为它使得神经网络的权重不会集中于某个参数，相当于起到了收缩权重的效果，这和L2正则化是类似的。</p><p>dropout正则化的缺点是训练过程中的损失函数$J$是难以表达的。一个处理方法是先将所有的keep_prob设置为1，确保此时的损失函数是单调减的，然后再设置为期望的值。</p><h3 id="其他正则化方法"><a href="#其他正则化方法" class="headerlink" title="其他正则化方法"></a>其他正则化方法</h3><p><code>数据扩增（data augmentation）</code>：在处理图片的时候，可以通过反转、裁剪、扭曲等操作扩大训练集，不过这不如新的图片。</p><p><code>early stopping</code>：在训练过程中同时计算training error和dev error，会发现有曲线</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/2.jpg" alt="1"></p><p>在紫色点的时候有着中等大小的佛罗贝尼乌斯范数，停止训练即可。这种方法的缺点是不能独立的处理优化损失函数和防止过拟合两个过程，于是需要考虑的东西更加复杂。不过和L2正则化相比只需要进行一次梯度下降，不需要对超参数$\lambda$进行搜索。吴老师还是倾向于使用L2正则化的。</p><h2 id="正则化输入（Normalizing-inputs）"><a href="#正则化输入（Normalizing-inputs）" class="headerlink" title="正则化输入（Normalizing inputs）"></a>正则化输入（Normalizing inputs）</h2><p>正则化输入可以加快训练速度，它分为两步，第一步是零均值化：</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum_{i=1}^m{x^{(i)}} \\ x=x-\mu</script><p>第二步是方差归一化：</p><script type="math/tex; mode=display">\sigma^2=\frac{1}{m}\sum_{i=1}^m{x^{(i)}}^2 \\ x =x/ \sigma^2</script><p>注意的是这个过程是在整个数据集上完成的。为什么这是有效的呢？直观的理解如下图所示</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/3.jpg" alt="1"></p><p>通过输入正则化，将样本空间从扁平状变为圆形，即将特征束缚在相似的范围中，因此就可以设置较大的学习率以提高训练速度。由于正则化并不会带来什么危害，所以吴老师经常不管特征差距如何也进行一次输入正则化操作。</p><h2 id="梯度爆炸与梯度消失"><a href="#梯度爆炸与梯度消失" class="headerlink" title="梯度爆炸与梯度消失"></a>梯度爆炸与梯度消失</h2><p>训练神经网络遇到的一个重要问题是<code>梯度爆炸与梯度消失（vanishing/exploding gradients）</code>，是指梯度在训练的过程中快速变大或变小，甚至以指数的方式。这也是此前神经网络无法向深层发展的重要原因。以最简单的例子说明，假设神经网络的每层仅有2个神经元，激活函数均为恒等函数，$b^{[l]}=0$。故有</p><script type="math/tex; mode=display">\hat{y}=w^{[l]}w^{[l-1]}\dots w^{[2]}w^{[1]}x</script><p>当初始化$w^{[l]}=1.5I$时有</p><script type="math/tex; mode=display">\hat{y}=w^{[l]}(1.5I)^{l-1}x</script><p>若L很大，则发生梯度爆炸。反之若$w^{[l]}=0.5I$，则发生梯度消失。</p><p>为了尽量避免梯度爆炸与梯度消失，有一种初始化的方法叫<code>Xavier初始化</code>，它令每一层$w$的方差初始化为输入特征数量的倒数。比如如果激活函数为Relu，则有</p><script type="math/tex; mode=display">w^{[l]}=np.randon.randn(shape) * np.sqrt(\frac{2}{n^{[l-1]}})</script><p>如果是tanh函数，则有</p><script type="math/tex; mode=display">w^{[l]}=np.randon.randn(shape) * np.sqrt(\frac{1}{n^{[l-1]}})</script><p>还有方法如下，但是吴老师并不常用：</p><script type="math/tex; mode=display">w^{[l]}=np.randon.randn(shape) * np.sqrt(\frac{2}{n^{[l-1]}+n^{[l]}})</script><p>其他参数都不如$w$重要。</p><h2 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h2><p>在进行反向传播的时候，如果不确定偏导$g(\theta)$是否正确，可以使用</p><script type="math/tex; mode=display">\frac{f(\theta+\epsilon)+f(\theta-\epsilon)}{2\epsilon}-g(\theta)</script><p>来检验，这实际是简单的微积分知识。实际操作中将所有的参数$w,b$联接为一个超大的向量$\theta$，于是有</p><script type="math/tex; mode=display">for\ each \ i: \\ d\theta_{approx}=\frac{J(\theta_1,\theta_2,\dots,\theta_i+\epsilon,\dots)+J(\theta_1,\theta_2,\dots,\theta_i-\epsilon,\dots)}{2\epsilon}</script><p>之后计算</p><script type="math/tex; mode=display">\frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||_2}</script><p>当$\epsilon=10^{-7}$时，若结果$<10^{-7}$，那就比较稳；如果$>10^{-3}$，就很不稳了。</10^{-7}$，那就比较稳；如果$></p><p>梯度检验很慢，只能用于debug的时候，在训练的时候需要关掉；在发现问题的时候，仔细检查是在哪个$i$；不要与dropout同时使用；使用的时候记得正则化项。</p><h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><p>这个部分的重点在于如何提高训练的速度。</p><h2 id="mini-batch"><a href="#mini-batch" class="headerlink" title="mini-batch"></a>mini-batch</h2><p>向量化使得一次性可以计算全部样本，可是当训练样本很大，比如5,000,000的时候，一次计算要花的时间也不少，却也只能进行一次梯度下降，所以一次使用$m$个样本进行训练，将之视为一个mini-batch并记为$x^{\{1\}}$。每一次梯度下降称为一个<code>iterator</code>，每一次完全遍历样本集称为一个<code>epoch</code>。</p><p>当使用mini-batch进行训练的时候，损失函数是抖动下降的</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/4.png" alt="1"></p><p>和随机梯度下降相比由于每次考虑了较多的样本，所以梯度的方向比较稳定。下图中蓝色表示batch梯度下降，紫色表示随机梯度下降，绿色表示mini-batch梯度下降。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/5.png" alt="1"></p><p>通常，当样本数量大于2000的时候考虑使用mini-batch梯度下降，每个mini-batch的大小取2的整数幂为佳，一般不超过1024。</p><h2 id="指数加权平均"><a href="#指数加权平均" class="headerlink" title="指数加权平均"></a>指数加权平均</h2><p><code>指数加权平均（exponentially weighted average）</code>是很多优化算法的基础，从最基本的对气温的处理来看，设$\theta_t$为1年中第$t$天的气温，则使用</p><script type="math/tex; mode=display">v_0=0 \\ v_t=\beta v_{t-1}+(1-\beta)\theta_t</script><p>得到的向量$v_\theta$可以看作是对气温进行$\frac{1}{1-\beta}$天的平均，如下图所示，其中蓝色的点为原始气温数据，黄色线$\beta=0.5$，红色线$\beta=0.9$，绿色线$\beta=0.98$。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/6.png" alt="1"></p><p>之所以名字中带有“指数”，是因为将递推式展开后较早数据的权重是以指数的方式递减的。虽然这种方法的精度不如滑动窗口平均，但是有着极小的内存开销和极快的速度，因此在机器学习中更常用。</p><p>实际上，由于初期有$v_0=0$，所以导致初期的数据较小，比如$\beta=0.98$时绿色线在初期应该很低。所以要使用如下公式进行<code>偏差修正（bias correction）</code>：</p><script type="math/tex; mode=display">v_t=\frac{v_t}{1-\beta^t}</script><p>从而才能真正得到上图绿色的线。</p><h2 id="动量梯度下降法"><a href="#动量梯度下降法" class="headerlink" title="动量梯度下降法"></a>动量梯度下降法</h2><p><code>动量（momentum）梯度下降算法</code>的速度总是快于标准的梯度下降，其基本思想时对梯度做指数加权平均，并用平均梯度做梯度下降。在进行mini-batch梯度下降的过程中，梯度总会沿着某个方向抖动，因此在做平均后可以在一定程度上消除这种抖动，减少无谓的下降，进而可以采用更大的学习率。如下图的三维图所示，蓝色是标准的梯度下降过程，红色是经过指数平均后的梯度下降过程，可见减少了$z$方向的抖动，增加了$xy$平面上每步的距离。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/7.png" alt="1"></p><p>具体的实现为初始化$v_{dW}=v_{db}=\vec{0}$，之后在每轮迭代中有</p><script type="math/tex; mode=display">v_{dW}=\beta v_{dW}+(1-\beta)dW \\ v_{db}=\beta v_{db}+(1-\beta)db \\ W=W-\alpha v_{dW},b=b-v_{db}</script><p>其中$\beta=0.9$是一个健壮性很好的超参数。由于在10轮迭代之后就没有多少偏差了，所以一般不需要对其修正。</p><h2 id="RMSprop算法"><a href="#RMSprop算法" class="headerlink" title="RMSprop算法"></a>RMSprop算法</h2><p><code>root mean square prop, RMSprop算法</code>也可以加快梯度下降的速度，其基本过程和动量梯度下降很像，也是为了减小非重要方向上的梯度从而提高学习率：</p><script type="math/tex; mode=display">S_{dW}=\beta S_{dW}+(1-\beta)(dW)^2 \\ S_{db}=\beta S_{db}+(1-\beta)(db)^2 \\ W=W-\alpha\frac{dW}{\sqrt{S_{dW}+\epsilon}},b=b-\alpha\frac{db}{\sqrt{S_{db}+\epsilon}}</script><p>其中$\epsilon$是一个比较小的常数例如$10^{-8}$，为了避免$S_{dW}$过小。</p><h2 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h2><p>在深度学习领域，大佬们提出过很多优化算法，但是很快被证明没有足够的泛化能力，不能应用在多种模型中。而<code>Adam，Adaptive Moment Estimation算法</code>和RMSprop算法算是在动量梯度算法之后的特例，前者的基本思想是将动量梯度下降和RMSprop算法结合起来。</p><p>首先初始化$v_{dW}=S_{dW}=v_{db}=S_{db}=\vec{0}$，有了此前的铺垫，很容易理解有</p><script type="math/tex; mode=display">v_{dW}=\beta_1 v_{dW}+(1-\beta_1)dW , v_{db}=\beta_1 v_{db}+(1-\beta_1)db  \\ S_{dW}=\beta_2 S_{dW}+(1-\beta_2)(dW)^2 ,S_{db}=\beta_2 S_{db}+(1-\beta_2)(db)^2 \\ v_{dW}^{corrected}=\frac{v_{dW}}{1-\beta_1^t}, v_{db}^{corrected}=\frac{v_{db}}{1-\beta_1^t} \\ S_{dW}^{corrected}=\frac{S_{dW}}{1-\beta_2^t}, S_{db}^{corrected}=\frac{S_{db}}{1-\beta_2^t} \\ W=W-\alpha\frac{v_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\epsilon},b=b-\alpha\frac{v_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\epsilon}</script><p>其中$\beta_1=0.9,\beta_2=0.999,\epsilon=10^{-8}$是一个比较常见的设置，一般只调整$\alpha$。</p><h2 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h2><p>一个加快神经网络训练速度的方法是随着时间慢慢减少学习率，即<code>学习率衰减（learning rate decay）</code>，其基本思路是将学习率设置为epoch的函数，比如</p><script type="math/tex; mode=display">\alpha=\frac{1}{1+\#epoch *decay \ rate}</script><p>或者</p><script type="math/tex; mode=display">\alpha = 0.95^{\#epoch}\alpha_0 \\ \alpha=\frac{k}{\sqrt{\#epoch}}\alpha_0</script><p>或者手动设置的分段函数。</p><h2 id="局部最优的问题"><a href="#局部最优的问题" class="headerlink" title="局部最优的问题"></a>局部最优的问题</h2><p>和直觉不同，实际上在具有很多特征的神经网络中遇到局部最小点的概率是非常非常小的，往往遇到的都是鞍点。当然这里必须贴出吴老师讲鞍点的图片。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/8.png" alt="1"></p><p>真正麻烦的是梯度很小的<code>平台（plateaus）</code>，这也是此前优化算法所解决的问题。</p><h1 id="超参数调试、Batch正则化和程序框架"><a href="#超参数调试、Batch正则化和程序框架" class="headerlink" title="超参数调试、Batch正则化和程序框架"></a>超参数调试、Batch正则化和程序框架</h1><h2 id="超参数调试"><a href="#超参数调试" class="headerlink" title="超参数调试"></a>超参数调试</h2><h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><p>上面一堆加快训练速度的方法也带来了很多超参数，如下图所示</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/9.png" alt="1"></p><p>其中在吴老师看来，学习率是最重要的，打黄色框次之，紫色框又次之，没打框的几乎不<code>调试（tune）</code>。怎么调试呢？总体的思路是<code>随机生成，由粗糙到精细</code>。不使用网格（grid）是由于无法提前得知哪个参数最重要，因此可以试验多个独立的参数。</p><h3 id="超参数范围"><a href="#超参数范围" class="headerlink" title="超参数范围"></a>超参数范围</h3><p>在对$\alpha$的调试中，往往采用对数坐标轴：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = <span class="number">-4</span> * np.random.rand()</span><br><span class="line">alpha = <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure><p>而对于$\beta$的调试，由于其集中于0.9到0.99999，往往对$1-\beta$采用对数坐标轴。</p><h3 id="超参数训练实践：pandas-vs-caviar"><a href="#超参数训练实践：pandas-vs-caviar" class="headerlink" title="超参数训练实践：pandas vs caviar"></a>超参数训练实践：pandas vs caviar</h3><p>当硬件资源有限的时候，我们只能盯着一个模型并观察其运行状况，每隔一段时间对超参数进行改变；当有很多硬件资源的时候，我们可以同时跑多个模型。前者的行为像熊猫，后者的行为像鱼类，当然在硬件充分的情况下当然使用后一种方法。</p><h2 id="Batch-归一化"><a href="#Batch-归一化" class="headerlink" title="Batch 归一化"></a>Batch 归一化</h2><p>batch归一化可以使得参数搜索更加容易，从而更方便地训练大型网络。</p><h3 id="归一化的过程"><a href="#归一化的过程" class="headerlink" title="归一化的过程"></a>归一化的过程</h3><p>此前讨论过正则化输入，如果可以应用在隐藏层，岂不是更好？一个版本是对$a$操作，另一个版本是对$z^{<a href="i">l</a>}$操作，也是吴老师默认的方法，以下的公式省略了层数信息：</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum_i{z^{(i)}} \\ \sigma^2=\frac{1}{m}\sum_i(z_i-\mu)^2 \\ z_{norm}^{(i)}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}} \\ \tilde{z}^{(i)}=\gamma z_{norm}^{(i)}+\beta</script><p>其中$\gamma$和$\beta$是和$w$、$b$地位等同的学习变量，会用$\tilde{z}^{<a href="i">l</a>}$代替$z^{<a href="i">l</a>}$的计算如下图所示，（又增加了很多参数）在tensorflow中使用函数<code>tf.nn.batch_normalization</code>完成这些操作。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/10.png" alt="1"></p><p>要注意的是这里的$\beta$和优化算法中的没有任何关系，易知其维度为$(n^{[l]}, 1)$。另外，由于均值会被归一化为0，所以此时参数$b$根本不起作用，完全可以去掉：</p><script type="math/tex; mode=display">z^{[l]}=w^{[l]}z^{[l-1]}\\ \dots\\ \tilde{z}^{[l]}=\gamma^{[l]} z_{norm}^{[l]}+\beta^{[l]}</script><h3 id="归一化有效性的解释"><a href="#归一化有效性的解释" class="headerlink" title="归一化有效性的解释"></a>归一化有效性的解释</h3><p>为什么归一化可以加快训练速度呢？直观来看是将正则化输入的过程加在了所有的隐藏层上。</p><p>更深层的第一个原因要结合<code>covariate shift</code>，即如何已经学习到了映射$x\to y$，如果$x$的分布发生了变化，那么需要重新进行学习。在神经网络中，中间层$l$可以看作是映射，前$l-1$层的输出可以看作是$x$，在训练的过程中$x$是不停改变的，所以$l$层也会不停变化。而batch的作用是限制了$x$的变化，即$z^{[l]}$的均值始终为0，方差始终为1，因此它减弱了前后层的关联，使得每一层的学习更加独立，这有助于训练的加速——当然这也很感性了。</p><p>另外一个原因是在mini-batch中输入本来就是有噪声的，加入归一化后又增加了一部分噪声，这和dropout很相似，因此微微加入了正则化的功能。不过这种正则化是很微弱的，如果想要正则化还是要和dropout一起用。此外，对于dropout来说mini-batch越大，其正则化效果就越弱，这是个有趣的性质。</p><h3 id="测试阶段的处理"><a href="#测试阶段的处理" class="headerlink" title="测试阶段的处理"></a>测试阶段的处理</h3><p>由于在测试阶段没有mini-batch的概念，所以要通过别的方法获得对测试样本归一化的$\mu,\sigma$。一种方法是考虑到网络一旦训练完毕，参数都是固定的，这个时候即使是每批训练样本进入网络，那么BN层计算的均值标准差都是固定不变的。我们可以采用这些数值来作为测试样本所需要的均值、标准差。</p><script type="math/tex; mode=display">E[x]:E_B[\mu_B] \\ Var[x]:\frac{m}{m-1}E_B[\sigma_B^2] \\ y=\frac{\gamma}{\sqrt{Var[x]+\epsilon}}x+(\beta-\frac{\gamma E[x]}{\sqrt{Var[x]+\epsilon}})</script><p>emmm，这部分实际参考的是<a href="https://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener">CSDN</a>。</p><h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>多分类问题中用$C$表示分类的数量，在神经网络中则有$n^{[l]}=C$，输出特征$y$的每一维表示分类的概率。由于概率之和必须为1，所以需要再加上一个softmax层，计算方法为</p><script type="math/tex; mode=display">t = \exp(z^{[l]}) \\ a^{[l]}=\frac{t}{\sum_{i=1}^4{t_i}}</script><p>softmax是相对与hardmax的，可以看作是逻辑回归的推广，后者会输出一个one-hot向量。没有隐藏层的softmax分类器的作用如下图所示</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/11.png" alt="1"></p><p>其损失函数为</p><script type="math/tex; mode=display">L(\hat{y}, y)=-\sum_{j=1}^Cy_j\log\hat{y}_j \\ J(W,b)=\frac{1}{m}\sum_{i=1}^m{L(\hat{y}^{(i)}, y^{(i)})}</script><p>要注意的是在向量化的表示中$Y,\hat{Y}$的维度均为$(C,m)$。反向传播的公式为</p><script type="math/tex; mode=display">dz^{[l]}=\hat{y}-y</script><h2 id="深度学习框架tensorflow"><a href="#深度学习框架tensorflow" class="headerlink" title="深度学习框架tensorflow"></a>深度学习框架tensorflow</h2><p>用numpy实现CNN、RNN或者交大规模神经网络并不现实，这时需要借助各种优秀的程序框架，这和知道矩阵乘法的过程但是仍然调用numpy一样，由于深度学习已经成熟了，所以可以提高工作的效率。常见的框架即选择标准如下所示，他们每个月都在进化，所以优劣在此不赘述。</p><p><img src="/2018/07/31/mooc-深度学习工程师-2-改善深层神经网络：超参数调试、正则化以及优化/12.png" alt="1"></p><p>当然，吴老师介绍的是tensorflow，其作用只要需要用内置函数完成前向传播后可以自动得到反向传播，同时提供了大量优化函数。需要注意的是tensorflow的计算图和吴老师课程使用的并不一样，其他就不赘述了，参见我的博客<a href="http://wang22ti.com/2018/07/25/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">tensorflow学习笔记</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深度学习的实用层面&quot;&gt;&lt;a href=&quot;#深度学习的实用层面&quot; class=&quot;headerlink&quot; title=&quot;深度学习的实用层面&quot;&gt;&lt;/a&gt;深度学习的实用层面&lt;/h1&gt;&lt;h2 id=&quot;训练-开发-测试集&quot;&gt;&lt;a href=&quot;#训练-开发-测试集&quot; class
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-matlab</title>
    <link href="http://wang22ti.com/2018/07/29/%E7%AC%94%E8%AE%B0-matlab/"/>
    <id>http://wang22ti.com/2018/07/29/笔记-matlab/</id>
    <published>2018-07-29T02:00:10.000Z</published>
    <updated>2018-09-05T13:56:27.736Z</updated>
    
    <content type="html"><![CDATA[<p>本准备完全自学的，正好《模式识别》和《人工智能》这两门课的首选语言都是Matlab，就提前学一下吧！</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>最新版（2018a，即2018年上半年版本）的安装参考博客<a href="https://blog.csdn.net/josslyn/article/details/79898261" target="_blank" rel="noopener">MATLAB2018a 64安装</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本准备完全自学的，正好《模式识别》和《人工智能》这两门课的首选语言都是Matlab，就提前学一下吧！&lt;/p&gt;
&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;p&gt;最新版（2018a，即2
      
    
    </summary>
    
      <category term="matlab" scheme="http://wang22ti.com/categories/matlab/"/>
    
    
  </entry>
  
  <entry>
    <title>学习-caffe</title>
    <link href="http://wang22ti.com/2018/07/29/%E7%AC%94%E8%AE%B0-caffe/"/>
    <id>http://wang22ti.com/2018/07/29/笔记-caffe/</id>
    <published>2018-07-29T01:59:59.000Z</published>
    <updated>2018-08-13T03:05:50.102Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-GAN</title>
    <link href="http://wang22ti.com/2018/07/29/%E7%AC%94%E8%AE%B0-GAN/"/>
    <id>http://wang22ti.com/2018/07/29/笔记-GAN/</id>
    <published>2018-07-29T01:58:15.000Z</published>
    <updated>2018-08-13T03:03:06.853Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>mooc-吴恩达老师在斯坦福大学的机器学习机器学习公开课3——无监督学习</title>
    <link href="http://wang22ti.com/2018/07/26/mooc-%E5%90%B4%E6%81%A9%E8%BE%BE%E8%80%81%E5%B8%88%E5%9C%A8%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE3%E2%80%94%E2%80%94%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://wang22ti.com/2018/07/26/mooc-吴恩达老师在斯坦福大学的机器学习机器学习公开课3——无监督学习/</id>
    <published>2018-07-26T06:22:28.000Z</published>
    <updated>2018-07-26T09:27:15.604Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>笔记-tensorflow</title>
    <link href="http://wang22ti.com/2018/07/25/%E7%AC%94%E8%AE%B0-tensorflow/"/>
    <id>http://wang22ti.com/2018/07/25/笔记-tensorflow/</id>
    <published>2018-07-25T01:40:44.000Z</published>
    <updated>2018-09-13T09:23:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>以下内容主要来自<a href="http://www.tensorfly.cn/tfdoc/get_started/introduction.html" target="_blank" rel="noopener">tensorflow中文官网教程</a></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>windows下直接以管理员身份在cmd输入即可，下载速度很快</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure><p>不过如果电脑上没有Anaconda或者vs2017会报<code>ImportError: DLL load failed: 找不到指定的模块</code>的错误，只需要在<a href="https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=53587下载缺少的环境即可。" target="_blank" rel="noopener">https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=53587下载缺少的环境即可。</a></p><h1 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h1><h2 id="图和会话"><a href="#图和会话" class="headerlink" title="图和会话"></a>图和会话</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">matrix1 = tf.constant([[<span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line">matirx2 = tf.constant([[<span class="number">4.</span>], [<span class="number">5.</span>]])</span><br><span class="line"></span><br><span class="line">product = tf.matmul(matrix1, matirx2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    res = sess.run([product])   <span class="comment"># 返回的类型是list</span></span><br><span class="line">    print(res)</span><br></pre></td></tr></table></figure><h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">counter = tf.Variable(<span class="number">0</span>, name=<span class="string">'counter'</span>)</span><br><span class="line">constant = tf.constant(<span class="number">2</span>)</span><br><span class="line">op_add = tf.add(counter, constant)</span><br><span class="line">update = tf.assign(counter, op_add)</span><br><span class="line"><span class="comment"># update = tf.assign_add(counter, constant)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># init = tf.initialize_all_variables() 官网上用的是这个，不过过时了</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    print(sess.run(counter))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        sess.run(op_add)</span><br><span class="line">        res = sess.run(update)</span><br><span class="line">        print(res)</span><br><span class="line">    sub_output = tf.subtract(res, constant)</span><br><span class="line">    update2 = tf.assign(counter, sub_output)</span><br><span class="line">    print(sess.run([update, sub_output]))</span><br></pre></td></tr></table></figure><h2 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 官网的类型在tf.types里，应该过时了</span></span><br><span class="line">input1 = tf.placeholder(dtype=tf.float32)</span><br><span class="line">input2 = tf.placeholder(dtype=tf.float32)</span><br><span class="line">out1 = tf.multiply(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    res = sess.run(out1, feed_dict=&#123;input1: <span class="number">7.</span>, input2: <span class="number">3.</span>&#125;)</span><br><span class="line">    print(res)</span><br></pre></td></tr></table></figure><h1 id="mnist手写体识别入门"><a href="#mnist手写体识别入门" class="headerlink" title="mnist手写体识别入门"></a>mnist手写体识别入门</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># from tensorflow.examples.tutorials.mnist import input_data</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.learn.python.learn.datasets.mnist <span class="keyword">import</span> read_data_sets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 独热法编码方式</span></span><br><span class="line">mnist = read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(dtype=tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># 中括号不能丢</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]), dtype=tf.float32)</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]), dtype=tf.float32)</span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br><span class="line">y_ = tf.placeholder(dtype=tf.float32, shape=[<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</span><br><span class="line">res = sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure><h1 id="mnist手写体识别进阶"><a href="#mnist手写体识别进阶" class="headerlink" title="mnist手写体识别进阶"></a>mnist手写体识别进阶</h1><p>以下参照的是<a href="https://www.bilibili.com/video/av25566267/?p=45" target="_blank" rel="noopener">哔哩哔哩的视频</a>，不过有所改动，神经网络示意图如下。</p><p><img src="/2018/07/25/笔记-tensorflow/1.jpg" alt=""></p><p>深度学习没有显卡果然是不行的，这么简单的一个神经网络的训练，在我i7 7500U无独显的本子上跑了52分钟才收敛，而且最终的正确率只有94.71%。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.contrib.learn.python.learn.datasets.mnist <span class="keyword">import</span> read_data_sets</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># (55000 * 28 * 28)</span></span><br><span class="line">mnist = read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">input_x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">28</span> * <span class="number">28</span>]) / <span class="number">255</span></span><br><span class="line">output_y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">input_x_image = tf.reshape(input_x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">test_x = mnist.test.images[:<span class="number">3000</span>]</span><br><span class="line">test_y = mnist.test.labels[:<span class="number">3000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层卷积，输出为28 * 28 * 32</span></span><br><span class="line">conv1 = tf.layers.conv2d(</span><br><span class="line">    inputs=input_x_image,  <span class="comment"># 输入为28 * 28 * 1</span></span><br><span class="line">    filters=<span class="number">32</span>,  <span class="comment"># 过滤器的数量，输出的深度为32</span></span><br><span class="line">    kernel_size=[<span class="number">5</span>, <span class="number">5</span>],  <span class="comment"># 过滤器的大小</span></span><br><span class="line">    strides=<span class="number">1</span>,  <span class="comment"># 步长为1</span></span><br><span class="line">    padding=<span class="string">'same'</span>,  <span class="comment"># 输出的大小仍然为28 * 28，需要对输入补零</span></span><br><span class="line">    activation=tf.nn.relu  <span class="comment"># 激活函数为relu</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层池化（亚采样），输出为14 * 14 * 32</span></span><br><span class="line">pool1 = tf.layers.max_pooling2d(</span><br><span class="line">    inputs=conv1,</span><br><span class="line">    pool_size=[<span class="number">2</span>, <span class="number">2</span>],  <span class="comment"># 过滤器大小为2 * 2</span></span><br><span class="line">    strides=<span class="number">2</span>,  <span class="comment"># 步长大小为2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层卷积，输出为14 * 14 * 64</span></span><br><span class="line">conv2 = tf.layers.conv2d(</span><br><span class="line">    inputs=pool1,</span><br><span class="line">    filters=<span class="number">64</span>,  <span class="comment"># 过滤器的数量，输出的深度为64</span></span><br><span class="line">    kernel_size=[<span class="number">5</span>, <span class="number">5</span>],  <span class="comment"># 过滤器的大小</span></span><br><span class="line">    strides=<span class="number">1</span>,  <span class="comment"># 步长为1</span></span><br><span class="line">    padding=<span class="string">'same'</span>,  <span class="comment"># 输出的大小仍然为28 * 28，需要对输入补零</span></span><br><span class="line">    activation=tf.nn.relu  <span class="comment"># 激活函数为relu</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层池化，输出为7 * 7 * 64</span></span><br><span class="line">pool2 = tf.layers.max_pooling2d(</span><br><span class="line">    inputs=conv2,</span><br><span class="line">    pool_size=[<span class="number">2</span>, <span class="number">2</span>],  <span class="comment"># 过滤器大小为2 * 2</span></span><br><span class="line">    strides=<span class="number">2</span>,  <span class="comment"># 步长大小为2</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平坦化</span></span><br><span class="line">flat = tf.reshape(pool2, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1024个神经元全连接层</span></span><br><span class="line">dense = tf.layers.dense(</span><br><span class="line">    inputs=flat,</span><br><span class="line">    units=<span class="number">1024</span>,  <span class="comment"># 1024个神经元</span></span><br><span class="line">    activation=tf.nn.relu  <span class="comment"># 激活函数为relu</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 丢弃50%</span></span><br><span class="line">dropout = tf.layers.dropout(</span><br><span class="line">    inputs=dense,</span><br><span class="line">    rate=<span class="number">0.5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 10个神经元的全连接层，不需要激活函数做非线性化</span></span><br><span class="line">logits = tf.layers.dense(</span><br><span class="line">    inputs=dropout,</span><br><span class="line">    units=<span class="number">10</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算误差</span></span><br><span class="line">loss = tf.losses.softmax_cross_entropy(</span><br><span class="line">    onehot_labels=output_y,</span><br><span class="line">    logits=logits</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adam优化器最小化误差</span></span><br><span class="line">train_op = tf.train.AdamOptimizer(learning_rate=<span class="number">0.005</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line"><span class="comment"># 会返回两个局部变量，所以初始化的时候要注意</span></span><br><span class="line">accuracy = tf.metrics.accuracy(</span><br><span class="line">    labels=tf.arg_max(output_y, dimension=<span class="number">1</span>),</span><br><span class="line">    predictions=tf.arg_max(logits, dimension=<span class="number">1</span>)</span><br><span class="line">)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练神经网络</span></span><br><span class="line">start = time()</span><br><span class="line">old_accuracy = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    train_op.run(feed_dict=&#123;input_x: batch[<span class="number">0</span>], output_y: batch[<span class="number">1</span>]&#125;)</span><br><span class="line">    test_accuracy = accuracy.eval(feed_dict=&#123;input_x: test_x, output_y: test_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> abs(test_accuracy - old_accuracy) &lt; <span class="number">0.00001</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    old_accuracy = test_accuracy</span><br><span class="line">    print(<span class="string">"Step=%d [Test accuracy=%.4f, time=%ds]"</span> % (i, test_accuracy, time() - start))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出测试集上的正确率</span></span><br><span class="line">final_accuracy = accuracy.eval(feed_dict=&#123;input_x: mnist.test.images, output_y: mnist.test.labels&#125;)</span><br><span class="line">print(<span class="string">"final test accuracy is %.4f"</span> % final_accuracy)</span><br></pre></td></tr></table></figure><p>另一份代码和tensorflow官网差不多，计算速度很快，不过准确率抖动很厉害，几分钟后在测试集的准确率为94.32%。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)  <span class="comment"># 下载并加载mnist数据</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])  <span class="comment"># 输入的数据占位符</span></span><br><span class="line">y_actual = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">10</span>])  <span class="comment"># 输入的标签占位符</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，用于初始化所有的权值 W</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，用于初始化所有的偏置项 b</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，用于构建卷积层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，用于构建池化层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建网络</span></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])  <span class="comment"># 转换输入数据shape,以便于用于网络中</span></span><br><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)  <span class="comment"># 第一个卷积层</span></span><br><span class="line">h_pool1 = max_pool(h_conv1)  <span class="comment"># 第一个池化层</span></span><br><span class="line"></span><br><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)  <span class="comment"># 第二个卷积层</span></span><br><span class="line">h_pool2 = max_pool(h_conv2)  <span class="comment"># 第二个池化层</span></span><br><span class="line"></span><br><span class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])  <span class="comment"># reshape成向量</span></span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  <span class="comment"># 第一个全连接层</span></span><br><span class="line"></span><br><span class="line">keep_prob = tf.placeholder(<span class="string">"float"</span>)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line">y_predict = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)  <span class="comment"># softmax层</span></span><br><span class="line"></span><br><span class="line">cross_entropy = -tf.reduce_sum(y_actual * tf.log(y_predict))  <span class="comment"># 交叉熵</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">1e-3</span>).minimize(cross_entropy)  <span class="comment"># 梯度下降法</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_predict, <span class="number">1</span>), tf.argmax(y_actual, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))  <span class="comment"># 精确度计算</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:  <span class="comment"># 训练100次，验证一次</span></span><br><span class="line">        train_acc = accuracy.eval(feed_dict=&#123;x: batch[<span class="number">0</span>], y_actual: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">        print(<span class="string">'step'</span>, i, <span class="string">'training accuracy'</span>, train_acc)</span><br><span class="line">        train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_actual: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line"></span><br><span class="line">test_acc = accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_actual: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">print(<span class="string">"test accuracy"</span>, test_acc)</span><br></pre></td></tr></table></figure><p>此外，Session()和InteractiveSession()的区别参见<a href="https://blog.csdn.net/M_Z_G_Y/article/details/80416226" target="_blank" rel="noopener">博客</a>。run()和eval()的区别参见<a href="https://blog.csdn.net/chengshuhao1991/article/details/78554743" target="_blank" rel="noopener">博客</a>。</p><h1 id="GPU版本的安装"><a href="#GPU版本的安装" class="headerlink" title="GPU版本的安装"></a>GPU版本的安装</h1><p>有外置显卡，当然要安装GPU版本的Tensorflow啦，主要参考<a href="https://www.cnblogs.com/fanfzj/p/8521728.html" target="_blank" rel="noopener">博客</a>。不过该博文提供的版本是9.0的，而我安装的时候（2018年8月30日）已经有了9.2。此外，根据<a href="https://github.com/google/prettytensor/issues/1" target="_blank" rel="noopener">GitHub的讨论</a>，要修改会话的设置，否则会报Cannot assign a device to node的错误，以下是改进的GPU版本的手写体GAN程序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">tf_device = <span class="string">'/gpu:1'</span></span><br><span class="line"><span class="keyword">with</span> tf.device(tf_device):</span><br><span class="line">    sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=<span class="keyword">True</span>))</span><br><span class="line"></span><br><span class="line">    mb_size = <span class="number">128</span></span><br><span class="line">    Z_dim = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_var</span><span class="params">(shape, name)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.get_variable(name=name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bias_var</span><span class="params">(shape, name)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tf.get_variable(name=name, shape=shape, initializer=tf.constant_initializer(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># discriminater net</span></span><br><span class="line"></span><br><span class="line">    X = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>], name=<span class="string">'X'</span>)</span><br><span class="line"></span><br><span class="line">    D_W1 = weight_var([<span class="number">784</span>, <span class="number">128</span>], <span class="string">'D_W1'</span>)</span><br><span class="line">    D_b1 = bias_var([<span class="number">128</span>], <span class="string">'D_b1'</span>)</span><br><span class="line"></span><br><span class="line">    D_W2 = weight_var([<span class="number">128</span>, <span class="number">1</span>], <span class="string">'D_W2'</span>)</span><br><span class="line">    D_b2 = bias_var([<span class="number">1</span>], <span class="string">'D_b2'</span>)</span><br><span class="line"></span><br><span class="line">    theta_D = [D_W1, D_W2, D_b1, D_b2]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generator net</span></span><br><span class="line"></span><br><span class="line">    Z = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">100</span>], name=<span class="string">'Z'</span>)</span><br><span class="line"></span><br><span class="line">    G_W1 = weight_var([<span class="number">100</span>, <span class="number">128</span>], <span class="string">'G_W1'</span>)</span><br><span class="line">    G_b1 = bias_var([<span class="number">128</span>], <span class="string">'G_B1'</span>)</span><br><span class="line"></span><br><span class="line">    G_W2 = weight_var([<span class="number">128</span>, <span class="number">784</span>], <span class="string">'G_W2'</span>)</span><br><span class="line">    G_b2 = bias_var([<span class="number">784</span>], <span class="string">'G_B2'</span>)</span><br><span class="line"></span><br><span class="line">    theta_G = [G_W1, G_W2, G_b1, G_b2]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z)</span>:</span></span><br><span class="line">        G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)</span><br><span class="line">        G_log_prob = tf.matmul(G_h1, G_W2) + G_b2</span><br><span class="line">        G_prob = tf.nn.tanh(tf.nn.relu(G_log_prob))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> G_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(x)</span>:</span></span><br><span class="line">        D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)</span><br><span class="line">        D_logit = tf.matmul(D_h1, D_W2) + D_b2</span><br><span class="line">        D_prob = tf.nn.sigmoid(D_logit)</span><br><span class="line">        <span class="keyword">return</span> D_prob, D_logit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    G_sample = generator(Z)</span><br><span class="line">    D_real, D_logit_real = discriminator(X)</span><br><span class="line">    D_fake, D_logit_fake = discriminator(G_sample)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># # reduce_mean(-log(sigmoid(D_logit_real)))</span></span><br><span class="line">    <span class="comment"># D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span></span><br><span class="line">    <span class="comment">#     logits=D_logit_real, labels=tf.ones_like(D_logit_real)))</span></span><br><span class="line">    <span class="comment"># # reduce_mean(-log(1-sigmoid(D_logit_real)))</span></span><br><span class="line">    <span class="comment"># D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span></span><br><span class="line">    <span class="comment">#     logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))</span></span><br><span class="line">    <span class="comment"># D_loss = D_loss_real + D_loss_fake</span></span><br><span class="line">    <span class="comment"># # reduce_mean(-log(sigmoid(D_logit_fake)))</span></span><br><span class="line">    <span class="comment"># G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span></span><br><span class="line">    <span class="comment">#     logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))</span></span><br><span class="line">    D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(<span class="number">1.</span> - D_fake))</span><br><span class="line">    G_loss = -tf.reduce_mean(tf.log(D_fake))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 需要指定更新的变量，不然几乎不收敛</span></span><br><span class="line">    D_optimizer = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)</span><br><span class="line">    G_optimizer = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sample_Z</span><span class="params">(m, n)</span>:</span></span><br><span class="line">        <span class="string">'''Uniform prior for G(Z)'''</span></span><br><span class="line">        <span class="keyword">return</span> np.random.uniform(<span class="number">-1.</span>, <span class="number">1.</span>, size=[m, n])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(samples)</span>:</span></span><br><span class="line">        fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">        gs = gridspec.GridSpec(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">        gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):  <span class="comment"># [i,samples[i]] imax=16</span></span><br><span class="line">            ax = plt.subplot(gs[i])</span><br><span class="line">            plt.axis(<span class="string">'off'</span>)</span><br><span class="line">            ax.set_xticklabels([])</span><br><span class="line">            ax.set_aspect(<span class="string">'equal'</span>)</span><br><span class="line">            plt.imshow(sample.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap=<span class="string">'Greys_r'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> fig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'out/'</span>):</span><br><span class="line">        os.makedirs(<span class="string">'out/'</span>)</span><br><span class="line"></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">1000000</span>):</span><br><span class="line">        <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            samples = sess.run(G_sample, feed_dict=&#123;</span><br><span class="line">                Z: sample_Z(<span class="number">16</span>, Z_dim)&#125;)  <span class="comment"># 16*784</span></span><br><span class="line">            fig = plot(samples)</span><br><span class="line">            plt.savefig(<span class="string">'out/&#123;&#125;.png'</span>.format(str(i).zfill(<span class="number">3</span>)), bbox_inches=<span class="string">'tight'</span>)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            plt.close(fig)</span><br><span class="line"></span><br><span class="line">        X_mb, _ = mnist.train.next_batch(mb_size)</span><br><span class="line"></span><br><span class="line">        _, D_loss_curr = sess.run([D_optimizer, D_loss], feed_dict=&#123;</span><br><span class="line">            X: X_mb, Z: sample_Z(mb_size, Z_dim)&#125;)</span><br><span class="line">        _, G_loss_curr = sess.run([G_optimizer, G_loss], feed_dict=&#123;</span><br><span class="line">            Z: sample_Z(mb_size, Z_dim)&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Iter: &#123;&#125;'</span>.format(it))</span><br><span class="line">            print(<span class="string">'D loss: &#123;:.4&#125;'</span>.format(D_loss_curr))</span><br><span class="line">            print(<span class="string">'G_loss: &#123;:.4&#125;'</span>.format(G_loss_curr))</span><br><span class="line">            print()</span><br></pre></td></tr></table></figure><h1 id="GPU版本的其他事项"><a href="#GPU版本的其他事项" class="headerlink" title="GPU版本的其他事项"></a>GPU版本的其他事项</h1><p>更换了台式机后，安装cuda9.0的时候会提示硬件问题云云，必须要安装9.2。结果安装好9.2之后又说和tensorflow的版本不兼容，emmm，真是配环境配死人。还好，针对windows+CUDA9.2+python3.6的环境是存在的，详见<a href="https://blog.csdn.net/wwtor/article/details/80603296" target="_blank" rel="noopener">博文</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以下内容主要来自&lt;a href=&quot;http://www.tensorfly.cn/tfdoc/get_started/introduction.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;tensorflow中文官网教程&lt;/a&gt;&lt;/p&gt;
&lt;h1
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wang22ti.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>《编译原理》实验6-简易编译器前端</title>
    <link href="http://wang22ti.com/2018/06/22/%E3%80%8A%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E3%80%8B%E5%AE%9E%E9%AA%8C6-%E7%AE%80%E6%98%93%E7%BC%96%E8%AF%91%E5%99%A8%E5%89%8D%E7%AB%AF/"/>
    <id>http://wang22ti.com/2018/06/22/《编译原理》实验6-简易编译器前端/</id>
    <published>2018-06-21T16:01:18.000Z</published>
    <updated>2018-07-03T12:16:12.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="程序功能描述"><a href="#程序功能描述" class="headerlink" title="程序功能描述"></a>程序功能描述</h1><p>​        本次实验中，我用python3.5实现了一个简单的类C语言代码块文法的编译器前端，具有以下功能：</p><ol><li><p>根据输入文法，自动生成终结符号集、非终结符号集、first集、follow集、项目集、状态集和分析表，对无法分析的语法报错</p></li><li><p>从txt文件中读取赋值语句，通过词法分析生成对应的二元式文件，对不符合文法的词法报错</p></li><li><p>根据词法分析的二元式序列，对其进行语法分析</p></li><li><p>根据设定log级别将分析过程与结果输出在前端上</p></li><li><p>良好的扩展性，可以很方便地加入新的词法与语法</p></li></ol><h1 id="文法描述"><a href="#文法描述" class="headerlink" title="文法描述"></a>文法描述</h1><p>​        为了分析更为复杂的输入串，设计了以下文法，基本包括了变量类型、变量定义、数组定义、变量赋值、逻辑运算、算术运算、条件语句、循环语句、循环控制等常见的高级语言输入串。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># P -&gt; &#123; &#125; | &#123; AA &#125;</span><br><span class="line"># AA-&gt; A | A AA</span><br><span class="line"># A -&gt; DD | SS</span><br><span class="line"># DD-&gt; D DD | D</span><br><span class="line"># D -&gt; T ID FH</span><br><span class="line"># ID-&gt; id | id = id | id = num | ID , ID</span><br><span class="line"># T -&gt; T [ num ] | TY</span><br><span class="line"># TY-&gt;int | float | char | bool</span><br><span class="line"># SS-&gt; S | S SS</span><br><span class="line"># S -&gt; L = E FH | if ( B ) S | if ( B ) S else S | while ( B ) S | do S while ( B ) FH | break FH | continue FH | P</span><br><span class="line"># B -&gt; B or B | B and B | ! B | ( B ) | E &lt; E | E &gt; E | E &lt;= E | E &gt;= E | E == E | E != E | true | false</span><br><span class="line"># E -&gt; E + E | E - E | E * E | E / E | L | ( E ) | num | id</span><br><span class="line"># L -&gt; id [ E ] | id</span><br><span class="line"># FH-&gt; ; | FH ;</span><br></pre></td></tr></table></figure><h1 id="数据结构与程序描述"><a href="#数据结构与程序描述" class="headerlink" title="数据结构与程序描述"></a>数据结构与程序描述</h1><h2 id="SLRAnalyzer"><a href="#SLRAnalyzer" class="headerlink" title="SLRAnalyzer"></a>SLRAnalyzer</h2><p>​        实验中实现的SLR语法分析类名为SLRAnalyzer，具体描述信息如下：<br><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/1.png" alt=""><br><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/2.png" alt=""><br><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/3.png" alt=""></p><h2 id="FrontEnd"><a href="#FrontEnd" class="headerlink" title="FrontEnd"></a>FrontEnd</h2><p>​        实验中主要使用python的标准GUI库tkinter编写前端类FrontEnd，具体描述如下。</p><p><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/4.png" alt=""></p><h1 id="程序测试及结果"><a href="#程序测试及结果" class="headerlink" title="程序测试及结果"></a>程序测试及结果</h1><h2 id="测试样例1"><a href="#测试样例1" class="headerlink" title="测试样例1"></a>测试样例1</h2><p>​        使用了如下的默认样例进行测试。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="keyword">int</span>[<span class="number">10</span>] i;</span><br><span class="line">   <span class="keyword">int</span> j = <span class="number">1</span>, k = <span class="number">10</span>, m = mm;</span><br><span class="line">   <span class="keyword">int</span> k;</span><br><span class="line">   <span class="keyword">if</span> (<span class="literal">false</span>)&#123;</span><br><span class="line">       i = <span class="number">1</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">       a = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">int</span>[<span class="number">10</span>] ii;;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">while</span> ( a &lt;= b)</span><br><span class="line">       j = <span class="number">2</span>;</span><br><span class="line">       <span class="keyword">if</span> (i &lt; <span class="number">1</span>) &#123;</span><br><span class="line">           <span class="keyword">break</span>;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在log_level=0的情况下查看分析结果，输入串符合文法，与预期相匹配。 </p><p><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/image2.png" alt="image2"></p><p>在log_level=1的情况如下，输出了二元式序列与状态栈、符号栈的详细变化过程 </p><p><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/image3.png" alt="image3"></p><p><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/image4.png" alt="image4"></p><h2 id="测试样例2"><a href="#测试样例2" class="headerlink" title="测试样例2"></a>测试样例2</h2><p>​        使用了如下样例进行测试，和默认样例相比增加了一处不符合语法的输入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">int[10] i;</span><br><span class="line">int j = 1, k = 10, m = mm;</span><br><span class="line">int k;</span><br><span class="line">if (false)&#123;</span><br><span class="line">    i = 1;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">    a = 1;</span><br><span class="line"></span><br><span class="line">int[10] ii;;</span><br><span class="line"></span><br><span class="line">while ( a &lt;&gt; b)</span><br><span class="line">    j = 2;</span><br><span class="line">    if (i &lt; 1) &#123;</span><br><span class="line">        break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出了输入串分析失败的的信息，包括当前符号、符号在二元式序列中的索引、状态栈栈顶元素，符合预期。</p><p><img src="/2018/06/22/《编译原理》实验6-简易编译器前端/image5.png" alt="image5"></p><h1 id="学习总结"><a href="#学习总结" class="headerlink" title="学习总结"></a>学习总结</h1><p>​        由于有此前词法分析器的积累，同时对人工生成分析表的过程有较好的掌握，本次实验在相关领域比较顺利。遇到的困难及解决方法主要包括：分析表数据结构的设计，通过一步一步改造结构，从而实现与其他变量的；closure函数的实现，通过使用递归实现。</p><p>​        本程序的优点包括：很好地实现了实验要求的基本功能，在分析失败的时候输出对应的出错信息，根据日志等级输出日志信息，并再次基础上又一定的扩充；良好的用户接口，只需要输入起始符号、产生式就可以自动生成必需的终结符号集、非终结符号集、follow集、项目集、状态集和分析表，并判断文法类型，分析文法时只需要输入存储输入串的文件名即可。</p><p>​        本程序还存在可以优化的地方，主要包括：进一步设计扩充文法，通过生成语法树对输入串进行语义分析生成四元式乃至计算结果，从而实现更强大的编译器。</p><p>本次实验中，通过实现简易编译器前端，学习了python标准GUI编程方法，提高了对问题的抽象与分析能力。</p><h1 id="附录：程序源码"><a href="#附录：程序源码" class="headerlink" title="附录：程序源码"></a>附录：程序源码</h1><p>​        本实验项目共包括3个文件，其中compiler.py实现了Compiler类，front_end.py实现了分析程序的前端，set_productions.py用来在后台修改文法。</p><h2 id="compiler-py"><a href="#compiler-py" class="headerlink" title="compiler.py"></a>compiler.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_productions_to_file</span><span class="params">(start, productions, path=<span class="string">'productions.txt'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(start) + <span class="string">'\n'</span>)</span><br><span class="line">        f.write(json.dumps(productions) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Compiler</span>:</span></span><br><span class="line">    overs = set()</span><br><span class="line">    reserved = set()</span><br><span class="line">    one_op_set = set()</span><br><span class="line">    two_next = dict()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, log_level=<span class="number">0</span>, sharp=<span class="string">'#'</span>, point=<span class="string">'.'</span>, acc=<span class="string">'acc'</span>, productions_file=<span class="string">'productions.txt'</span>)</span>:</span></span><br><span class="line">        self.log_level = log_level</span><br><span class="line">        <span class="keyword">with</span> open(productions_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            lines = f.readlines()</span><br><span class="line">            self.start = json.loads(lines[<span class="number">0</span>])</span><br><span class="line">            self.productions = json.loads(lines[<span class="number">1</span>])</span><br><span class="line">        self.nonterminals = self.productions.keys()</span><br><span class="line">        self.get_overs_reserved()</span><br><span class="line"></span><br><span class="line">        self.sharp = sharp</span><br><span class="line">        self.first = &#123;nontermainal: &#123;&#125; <span class="keyword">for</span> nontermainal <span class="keyword">in</span> self.nonterminals&#125;</span><br><span class="line">        self.follow = &#123;nontermainal: set() <span class="keyword">for</span> nontermainal <span class="keyword">in</span> self.nonterminals&#125;</span><br><span class="line">        self.get_first_follow()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算文法项目</span></span><br><span class="line">        self.new_start = self.start + <span class="string">"'"</span></span><br><span class="line">        self.point = point</span><br><span class="line">        self.items = &#123;key: list() <span class="keyword">for</span> key <span class="keyword">in</span> self.nonterminals&#125;</span><br><span class="line">        self.get_items()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算文法的状态和分析表</span></span><br><span class="line">        self.status_list = [</span><br><span class="line">            self.closure([(self.new_start, [self.point, self.start])]), ]</span><br><span class="line">        self.analyse_table = dict()</span><br><span class="line">        self.acc = acc</span><br><span class="line">        self.get_analyse_table()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_overs_reserved</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> nonterminal <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">            <span class="keyword">for</span> right <span class="keyword">in</span> self.productions[nonterminal]:</span><br><span class="line">                <span class="keyword">for</span> sign <span class="keyword">in</span> right:</span><br><span class="line">                    <span class="keyword">if</span> sign <span class="keyword">not</span> <span class="keyword">in</span> self.nonterminals <span class="keyword">and</span> len(sign) &gt; <span class="number">0</span>:</span><br><span class="line">                        self.overs.add(sign)</span><br><span class="line">                        <span class="keyword">if</span> len(sign) &gt;= <span class="number">2</span> <span class="keyword">and</span> <span class="keyword">not</span> sign[<span class="number">0</span>].isalpha():</span><br><span class="line">                            <span class="keyword">if</span> sign[<span class="number">0</span>] <span class="keyword">in</span> self.two_next.keys():</span><br><span class="line">                                self.two_next[sign[<span class="number">0</span>]].add(sign[<span class="number">1</span>:])</span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                self.two_next[sign[<span class="number">0</span>]] = &#123;sign[<span class="number">1</span>:], &#125;</span><br><span class="line">                        <span class="keyword">elif</span> sign[<span class="number">0</span>].isalpha():</span><br><span class="line">                            self.reserved.add(sign)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            self.one_op_set.add(sign)</span><br><span class="line">        remove_set = set()</span><br><span class="line">        <span class="keyword">for</span> sign <span class="keyword">in</span> self.one_op_set:</span><br><span class="line">            <span class="keyword">if</span> sign[<span class="number">0</span>] <span class="keyword">in</span> self.two_next.keys():</span><br><span class="line">                self.two_next[sign[<span class="number">0</span>]].add(<span class="string">''</span>)</span><br><span class="line">                remove_set.add(sign)</span><br><span class="line">        <span class="keyword">for</span> sign <span class="keyword">in</span> remove_set:</span><br><span class="line">            self.one_op_set.remove(sign)</span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">2</span>:</span><br><span class="line">            print(<span class="string">'over sign set:'</span>)</span><br><span class="line">            pprint(self.overs)</span><br><span class="line">            print(<span class="string">'reserved word set:'</span>)</span><br><span class="line">            pprint(self.reserved)</span><br><span class="line">            print(<span class="string">'one_op_set:'</span>)</span><br><span class="line">            pprint(self.one_op_set)</span><br><span class="line">            print(<span class="string">'two_next dict:'</span>)</span><br><span class="line">            pprint(self.two_next)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_first_follow</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 求first第一轮，产生式右部首字符为终结符号</span></span><br><span class="line">        self.first_first = list()</span><br><span class="line">        <span class="keyword">for</span> nontermainal <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">            <span class="keyword">for</span> right <span class="keyword">in</span> self.productions[nontermainal]:</span><br><span class="line">                <span class="keyword">if</span> right[<span class="number">0</span>] <span class="keyword">in</span> self.overs:</span><br><span class="line">                    self.first[nontermainal][right[<span class="number">0</span>]] = right</span><br><span class="line">                    self.first_first.append((nontermainal, right))</span><br><span class="line">        <span class="comment"># 求first第二轮</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            old_first = deepcopy(self.first)</span><br><span class="line">            <span class="keyword">for</span> nontermainal <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">                new_dict = &#123;&#125;</span><br><span class="line">                <span class="keyword">for</span> right <span class="keyword">in</span> self.productions[nontermainal]:</span><br><span class="line">                    <span class="keyword">if</span> (nontermainal, right) <span class="keyword">in</span> self.first_first:</span><br><span class="line">                        new_dict = self.first[nontermainal]</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">if</span> right[<span class="number">0</span>] != <span class="string">''</span>:</span><br><span class="line">                        <span class="keyword">if</span> right[<span class="number">0</span>] <span class="keyword">in</span> self.overs:</span><br><span class="line">                            new_dict.update(&#123;right[<span class="number">0</span>]: right&#125;)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">for</span> sign <span class="keyword">in</span> right:</span><br><span class="line">                                <span class="keyword">if</span> sign <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">                                    first_ = self.first[sign]</span><br><span class="line">                                    new_dict.update(&#123;key: right <span class="keyword">for</span> key <span class="keyword">in</span> first_.keys()&#125;)</span><br><span class="line">                                    <span class="keyword">if</span> <span class="string">''</span> <span class="keyword">not</span> <span class="keyword">in</span> first_.keys():</span><br><span class="line">                                        <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        new_dict.update(&#123;<span class="string">''</span>: <span class="string">''</span>&#125;)</span><br><span class="line">                self.first[nontermainal].update(new_dict)</span><br><span class="line">            <span class="keyword">if</span> old_first == self.first:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 起始符号follow集</span></span><br><span class="line">        self.follow[self.start].add(self.sharp)</span><br><span class="line">        <span class="comment"># 循环直到follow集不再变化</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            old_follow = deepcopy(self.follow)</span><br><span class="line">            <span class="keyword">for</span> nontermainal <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">                <span class="keyword">for</span> right <span class="keyword">in</span> self.productions[nontermainal]:</span><br><span class="line">                    <span class="keyword">if</span> right[<span class="number">0</span>] == <span class="string">''</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">for</span> i, sign <span class="keyword">in</span> enumerate(right):</span><br><span class="line">                        <span class="keyword">if</span> sign <span class="keyword">in</span> self.overs:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                        <span class="keyword">if</span> i == len(right) - <span class="number">1</span>:</span><br><span class="line">                            self.follow[sign] |= self.follow[nontermainal]</span><br><span class="line">                        <span class="keyword">elif</span> right[i + <span class="number">1</span>] <span class="keyword">in</span> self.overs:</span><br><span class="line">                            self.follow[sign].add(right[i + <span class="number">1</span>])</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            next_set = &#123;key <span class="keyword">for</span> key <span class="keyword">in</span> self.first[right[i + <span class="number">1</span>]].keys()&#125;</span><br><span class="line">                            next_set_without_null = &#123;key <span class="keyword">for</span> key <span class="keyword">in</span> self.first[right[i + <span class="number">1</span>]].keys() <span class="keyword">if</span> key != <span class="string">''</span>&#125;</span><br><span class="line">                            self.follow[sign] |= next_set_without_null</span><br><span class="line">                            <span class="keyword">if</span> <span class="string">''</span> <span class="keyword">in</span> next_set:</span><br><span class="line">                                self.follow[sign] |= self.follow[nontermainal]</span><br><span class="line">            <span class="keyword">if</span> old_follow == self.follow:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">2</span>:</span><br><span class="line">            print(<span class="string">'follow:'</span>)</span><br><span class="line">            pprint(self.follow)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_items</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.items[self.new_start] = [[self.point, self.start], [self.start, self.point]]</span><br><span class="line">        <span class="keyword">for</span> nonterminal <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">            <span class="keyword">for</span> right <span class="keyword">in</span> self.productions[nonterminal]:</span><br><span class="line">                <span class="keyword">if</span> right[<span class="number">0</span>] == <span class="string">''</span>:</span><br><span class="line">                    self.items[nonterminal].append([self.point, ])</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(len(right)):</span><br><span class="line">                    self.items[nonterminal].append(</span><br><span class="line">                        right[:i] + [self.point, ] + right[i:]</span><br><span class="line">                    )</span><br><span class="line">                self.items[nonterminal].append(right + [self.point, ])</span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">2</span>:</span><br><span class="line">            print(<span class="string">'items:'</span>)</span><br><span class="line">            pprint(self.items)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 递归求解输入项目集合的闭包</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">closure</span><span class="params">(self, production_list)</span>:</span></span><br><span class="line">        ret = production_list.copy()</span><br><span class="line">        <span class="comment"># 对于每一个项目，找到分隔符，如果后面有非终结符号，执行闭包操作</span></span><br><span class="line">        <span class="keyword">for</span> production <span class="keyword">in</span> production_list:</span><br><span class="line">            right = production[<span class="number">1</span>]</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; len(right) <span class="keyword">and</span> right[i] != self.point:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i + <span class="number">1</span> &lt; len(right) <span class="keyword">and</span> right[i + <span class="number">1</span>] <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> self.items[right[i + <span class="number">1</span>]]:</span><br><span class="line">                    <span class="keyword">if</span> self.point == item[<span class="number">0</span>] <span class="keyword">and</span> (right[i + <span class="number">1</span>], item) <span class="keyword">not</span> <span class="keyword">in</span> ret:</span><br><span class="line">                        ret.append((right[i + <span class="number">1</span>], item))</span><br><span class="line">        <span class="keyword">if</span> ret == production_list:</span><br><span class="line">            <span class="keyword">return</span> ret</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.closure(ret)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实现go函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">go</span><span class="params">(self, production_list, sign)</span>:</span></span><br><span class="line">        new_production_list = list()</span><br><span class="line">        <span class="comment"># 找到接受sign的项目，将分隔符后移一位</span></span><br><span class="line">        <span class="keyword">for</span> production <span class="keyword">in</span> production_list:</span><br><span class="line">            right = production[<span class="number">1</span>]</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; len(right) <span class="keyword">and</span> right[i] != self.point:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i + <span class="number">1</span> &lt; len(right) <span class="keyword">and</span> right[i + <span class="number">1</span>] == sign:</span><br><span class="line">                new_right = list(right)</span><br><span class="line">                temp = new_right[i]</span><br><span class="line">                new_right[i] = new_right[i + <span class="number">1</span>]</span><br><span class="line">                new_right[i + <span class="number">1</span>] = temp</span><br><span class="line">                <span class="keyword">if</span> (production[<span class="number">0</span>], new_right) <span class="keyword">not</span> <span class="keyword">in</span> new_production_list:</span><br><span class="line">                    new_production_list.append((production[<span class="number">0</span>], new_right))</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 返回新的状态的闭包</span></span><br><span class="line">        <span class="keyword">return</span> self.closure(new_production_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 求解项目集与分析表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_analyse_table</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># last_index指示现有状态集个数</span></span><br><span class="line">        <span class="comment"># index是正在分析的状态的索引</span></span><br><span class="line">        last_index = <span class="number">0</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="comment"># 首先得到该状态接受的符号及其对应项目</span></span><br><span class="line">            receive_sign_dict = &#123;&#125;</span><br><span class="line">            <span class="comment"># 遍历状态集中的每一个项目</span></span><br><span class="line">            <span class="keyword">for</span> (left, right) <span class="keyword">in</span> self.status_list[index]:</span><br><span class="line">                <span class="comment"># 找到分隔符</span></span><br><span class="line">                i = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> i &lt; len(right) <span class="keyword">and</span> right[i] != self.point:</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 如果分隔符不在末尾，将则其后的符号为接受符号</span></span><br><span class="line">                <span class="keyword">if</span> i + <span class="number">1</span> &lt; len(right):</span><br><span class="line">                    <span class="keyword">if</span> right[i + <span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> receive_sign_dict.keys():</span><br><span class="line">                        receive_sign_dict[right[i + <span class="number">1</span>]] = [(left, right)]</span><br><span class="line">                    <span class="keyword">elif</span> (left, right) <span class="keyword">not</span> <span class="keyword">in</span> receive_sign_dict[right[i + <span class="number">1</span>]]:</span><br><span class="line">                        receive_sign_dict[right[i + <span class="number">1</span>]].append((left, right))</span><br><span class="line">                <span class="comment"># 如果分隔符在末尾</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果左部为拓广文法起始符号，则记录acc</span></span><br><span class="line">                    <span class="keyword">if</span> left == self.new_start:</span><br><span class="line">                        self.analyse_table[index] = &#123;self.sharp: [self.acc, ]&#125;</span><br><span class="line">                    <span class="comment"># 否则找到对应的产生式</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        production_index = <span class="number">0</span></span><br><span class="line">                        <span class="keyword">for</span> left_ <span class="keyword">in</span> self.nonterminals:</span><br><span class="line">                            <span class="keyword">for</span> right_ <span class="keyword">in</span> self.productions[left_]:</span><br><span class="line">                                new_right = deepcopy(right)</span><br><span class="line">                                new_right.remove(self.point)</span><br><span class="line">                                <span class="keyword">if</span> (left, new_right) == (left_, right_):</span><br><span class="line">                                    <span class="comment"># 根据左部的follow集将r填入分析表</span></span><br><span class="line">                                    self.analyse_table[index] = &#123;</span><br><span class="line">                                        over: [production_index, <span class="string">'r'</span>, (left_, right_)]</span><br><span class="line">                                        <span class="keyword">for</span> over <span class="keyword">in</span> (self.follow[left_])</span><br><span class="line">                                    &#125;</span><br><span class="line">                                production_index += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 遍历接受符号</span></span><br><span class="line">            <span class="keyword">for</span> sign, production_set <span class="keyword">in</span> receive_sign_dict.items():</span><br><span class="line">                <span class="comment"># 用函数go求出新的状态</span></span><br><span class="line">                new_status = self.go(production_set, sign)</span><br><span class="line">                new_action = []</span><br><span class="line">                <span class="comment"># 如果新状态没有和已有的状态重复，讲起加入状态列表</span></span><br><span class="line">                <span class="keyword">if</span> new_status <span class="keyword">not</span> <span class="keyword">in</span> self.status_list:</span><br><span class="line">                    self.status_list.append(new_status)</span><br><span class="line">                    last_index += <span class="number">1</span></span><br><span class="line">                    new_action.append(last_index)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    new_action.append(self.status_list.index(new_status))</span><br><span class="line">                <span class="comment"># 更新分析表</span></span><br><span class="line">                <span class="keyword">for</span> production <span class="keyword">in</span> production_set:</span><br><span class="line">                    new_action.append(production)</span><br><span class="line">                <span class="keyword">if</span> index <span class="keyword">not</span> <span class="keyword">in</span> self.analyse_table.keys():</span><br><span class="line">                    self.analyse_table[index] = &#123;sign: new_action&#125;</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.analyse_table[index].update(&#123;sign: new_action&#125;)</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 如果没有状态可以分析，结束循环</span></span><br><span class="line">            <span class="keyword">if</span> index &gt; last_index:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">2</span>:</span><br><span class="line">            print(<span class="string">'stauts list:'</span>)</span><br><span class="line">            pprint(self.status_list)</span><br><span class="line">            print(<span class="string">'analyse table:'</span>)</span><br><span class="line">            pprint(self.analyse_table)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 词法分析函数</span></span><br><span class="line">    <span class="comment"># 检查是否为保留字</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lookup</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span> <span class="keyword">if</span> self.token <span class="keyword">in</span> self.reserved <span class="keyword">else</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 记录tag与string，清空token</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">out</span><span class="params">(self, c=<span class="string">''</span>)</span>:</span></span><br><span class="line">        self.tag_list.append(self.token <span class="keyword">if</span> c == <span class="string">''</span> <span class="keyword">else</span> c)</span><br><span class="line">        self.string_list.append(self.token)</span><br><span class="line">        self.token = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取下一个输出符号，没有返回False</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_char</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.index == len(self.raw_string):</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        self.ch = self.raw_string[self.index]</span><br><span class="line">        self.token += self.ch</span><br><span class="line">        self.index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.ch</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 回退一个符号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">retract</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.index = max(self.index - <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        self.ch = self.raw_string[max(self.index - <span class="number">1</span>, <span class="number">0</span>)]</span><br><span class="line">        self.token = self.token[:<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果是字母，循环调用get_char，最后调用out</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">alpha</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> self.index &lt; len(self.raw_string) <span class="keyword">and</span> self.raw_string[self.index].isalnum() <span class="keyword">and</span> self.get_char():</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        self.out(<span class="string">''</span> <span class="keyword">if</span> self.lookup() <span class="keyword">else</span> <span class="string">'id'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果是数字，循环调用get_char，最后调用out</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">digit</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> self.index &lt; len(self.raw_string) <span class="keyword">and</span> self.raw_string[self.index].isdigit() <span class="keyword">and</span> self.get_char():</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        self.out(<span class="string">'num'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果是单符号终结符，直接调用out</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">one_op</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.out()</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果可能是多符号终结符，先判断后一个是不是，不是回退</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">two_op</span><span class="params">(self)</span>:</span></span><br><span class="line">        now_ch = self.ch</span><br><span class="line">        <span class="keyword">if</span> self.get_char() <span class="keyword">not</span> <span class="keyword">in</span> self.two_next[now_ch]:</span><br><span class="line">            self.retract()</span><br><span class="line">        self.out()</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果是空格，清空token</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">blank</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.token = <span class="string">''</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    switch = &#123;</span><br><span class="line">        <span class="string">'alpha'</span>: alpha,</span><br><span class="line">        <span class="string">'digit'</span>: digit,</span><br><span class="line">        <span class="string">'one_op'</span>: one_op,</span><br><span class="line">        <span class="string">'two_op'</span>: two_op,</span><br><span class="line">        <span class="string">'blank'</span>: blank</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">analyse_cifa</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.token = <span class="string">''</span></span><br><span class="line">        self.index = <span class="number">0</span></span><br><span class="line">        self.ch = <span class="string">''</span></span><br><span class="line">        self.tag_list = []</span><br><span class="line">        self.string_list = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> self.get_char():</span><br><span class="line">            <span class="keyword">if</span> self.ch == <span class="string">' '</span>:</span><br><span class="line">                case = <span class="string">'blank'</span></span><br><span class="line">            <span class="keyword">elif</span> self.ch.isalpha():</span><br><span class="line">                case = <span class="string">'alpha'</span></span><br><span class="line">            <span class="keyword">elif</span> self.ch.isdigit():</span><br><span class="line">                case = <span class="string">'digit'</span></span><br><span class="line">            <span class="keyword">elif</span> self.ch <span class="keyword">in</span> self.one_op_set:</span><br><span class="line">                case = <span class="string">'one_op'</span></span><br><span class="line">            <span class="keyword">elif</span> self.ch <span class="keyword">in</span> self.two_next.keys():</span><br><span class="line">                case = <span class="string">'two_op'</span></span><br><span class="line">            <span class="comment"># 不合法字符，报错退出循环</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'error index %s: unkown character "%s"'</span> % (self.index, self.ch), end=<span class="string">'\n\n'</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">            <span class="comment"># 词法分析出错，报错退出循环</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.switch[case](self):</span><br><span class="line">                print(<span class="string">'error index %s: unkown character "%s"'</span> % (self.index, self.token), end=<span class="string">'\n\n'</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">with</span> open(self.file_name + <span class="string">'.two'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">                print(<span class="string">'lexical analyse:'</span>)</span><br><span class="line">            <span class="keyword">for</span> s, t <span class="keyword">in</span> zip(self.string_list, self.tag_list):</span><br><span class="line">                f.write(<span class="string">'%s %s\n'</span> % (s, t))</span><br><span class="line">                <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">                    print(s, t)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">analyse_yufa</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">            print(<span class="string">'grammar analyse:'</span>)</span><br><span class="line">        <span class="comment"># 初始化输入串列表、状态栈、符号栈</span></span><br><span class="line">        self.tag_list += self.sharp</span><br><span class="line">        string_index = <span class="number">0</span></span><br><span class="line">        status_stack = [<span class="number">0</span>, ]</span><br><span class="line">        sign_stack = [self.sharp, ]</span><br><span class="line">        <span class="comment"># 初始化语义分析的四元式列表、分析栈</span></span><br><span class="line">        siyuanshi_list = []</span><br><span class="line">        <span class="comment"># 不停分析直到接受</span></span><br><span class="line">        <span class="keyword">while</span> self.analyse_table[status_stack[<span class="number">-1</span>]][self.tag_list[string_index]][<span class="number">0</span>] != self.acc:</span><br><span class="line">            <span class="comment"># 如果不是r，则为s</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'r'</span> != self.analyse_table[status_stack[<span class="number">-1</span>]][self.tag_list[string_index]][<span class="number">1</span>]:</span><br><span class="line">                <span class="comment"># push</span></span><br><span class="line">                status_stack.append(self.analyse_table[status_stack[<span class="number">-1</span>]][self.tag_list[string_index]][<span class="number">0</span>])</span><br><span class="line">                sign_stack.append(self.tag_list[string_index])</span><br><span class="line">                <span class="comment"># advance</span></span><br><span class="line">                string_index += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">                    print(status_stack, sign_stack)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 为r，取出对应产生式的左部与右部</span></span><br><span class="line">                left = self.analyse_table[status_stack[<span class="number">-1</span>]][self.tag_list[string_index]][<span class="number">2</span>][<span class="number">0</span>]</span><br><span class="line">                right = self.analyse_table[status_stack[<span class="number">-1</span>]][self.tag_list[string_index]][<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 语义分析，四元式</span></span><br><span class="line">                <span class="comment"># TO-DO</span></span><br><span class="line">                <span class="comment"># 语义分析结束</span></span><br><span class="line">                <span class="comment"># pop(第i个产生式右部文法符号的个数)</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(len(right)):</span><br><span class="line">                    sign_stack.pop()</span><br><span class="line">                    status_stack.pop()</span><br><span class="line">                <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">                    print(status_stack, sign_stack)</span><br><span class="line">                <span class="comment"># push(GOTO[新的栈顶状态][第i个产生式的左部])</span></span><br><span class="line">                status_stack.append(self.analyse_table[status_stack[<span class="number">-1</span>]][left][<span class="number">0</span>])</span><br><span class="line">                sign_stack.append(left)</span><br><span class="line">                <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">                    print(status_stack, sign_stack)</span><br><span class="line">            <span class="comment"># error，退出循环</span></span><br><span class="line">            <span class="keyword">if</span> self.tag_list[string_index] <span class="keyword">not</span> <span class="keyword">in</span> self.analyse_table[status_stack[<span class="number">-1</span>]].keys():</span><br><span class="line">                print(<span class="string">'fail1'</span>, string_index, self.tag_list[string_index], status_stack[<span class="number">-1</span>])</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">            pprint(siyuanshi_list)</span><br><span class="line">        <span class="keyword">with</span> open(self.file_name + <span class="string">'.four'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> siyuanshi <span class="keyword">in</span> siyuanshi_list:</span><br><span class="line">                f.write(<span class="string">'%s %s %s %s\n'</span> % (siyuanshi[<span class="number">0</span>], siyuanshi[<span class="number">1</span>], siyuanshi[<span class="number">2</span>], siyuanshi[<span class="number">3</span>],))</span><br><span class="line">        print(<span class="string">'ok'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">analyse</span><span class="params">(self, file)</span>:</span></span><br><span class="line">        raw_string = open(file, <span class="string">'r'</span>).read()</span><br><span class="line">        self.raw_string = raw_string.replace(<span class="string">'\t'</span>, <span class="string">''</span>).replace(<span class="string">'\n'</span>, <span class="string">''</span>)</span><br><span class="line">        self.file_name = file[ :file.rindex(<span class="string">'.'</span>)]</span><br><span class="line">        print(<span class="string">'analysing: '</span> + file, end=<span class="string">'\n\n'</span>)</span><br><span class="line">        <span class="keyword">if</span> self.log_level &gt;= <span class="number">1</span>:</span><br><span class="line">            print(raw_string, end=<span class="string">'\n\n'</span>)</span><br><span class="line"></span><br><span class="line">        self.analyse_cifa() <span class="keyword">and</span> self.analyse_yufa()</span><br></pre></td></tr></table></figure><h2 id="front-end-py"><a href="#front-end-py" class="headerlink" title="front_end.py"></a>front_end.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> compiler</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> ttk</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tkinter.filedialog</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FrontEnd</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.temp_file = <span class="string">'temp.txt'</span></span><br><span class="line">        self.log_level = <span class="number">0</span></span><br><span class="line">        self.in_file = <span class="string">'input.txt'</span></span><br><span class="line"></span><br><span class="line">        self.root = Tk()</span><br><span class="line">        self.root.title(<span class="string">'a simple compiler'</span>)</span><br><span class="line">        <span class="comment"># self.root.state("zoomed")</span></span><br><span class="line"></span><br><span class="line">        self.label = Label(self.root, text=self.in_file, wraplength=<span class="number">300</span>, justify=<span class="string">'left'</span>)</span><br><span class="line">        self.label.grid(row=<span class="number">0</span>, column=<span class="number">0</span>, columnspan=<span class="number">3</span>)</span><br><span class="line">        self.botton_file = Button(self.root, text=<span class="string">"选择文件"</span>, command=self.select_file)</span><br><span class="line">        self.botton_file.grid(row=<span class="number">0</span>, column=<span class="number">3</span>, sticky=W + E + N + S)</span><br><span class="line"></span><br><span class="line">        self.boxlist_value = tkinter.StringVar()  <span class="comment"># 窗体自带的文本，新建一个值</span></span><br><span class="line">        self.boxlist = ttk.Combobox(self.root, textvariable=self.boxlist_value)  <span class="comment"># 初始化</span></span><br><span class="line">        self.boxlist[<span class="string">"values"</span>] = (<span class="string">"0"</span>, <span class="string">"1"</span>, <span class="string">"2"</span>)</span><br><span class="line">        self.boxlist.current(<span class="number">0</span>)  <span class="comment"># 选择第一个</span></span><br><span class="line">        self.boxlist.grid(row=<span class="number">1</span>, column=<span class="number">0</span>, columnspan=<span class="number">3</span>, sticky=W + E + N + S)</span><br><span class="line">        self.botton_log = Button(self.root, text=<span class="string">"设置log等级"</span>, command=self.set_log_level)</span><br><span class="line">        self.botton_log.grid(row=<span class="number">1</span>, column=<span class="number">3</span>, sticky=W + E + N + S)</span><br><span class="line"></span><br><span class="line">        self.out_text = Text(self.root)</span><br><span class="line">        self.out_text.grid(row=<span class="number">2</span>, column=<span class="number">0</span>, sticky=W + E + N + S, columnspan=<span class="number">4</span>)</span><br><span class="line">        self.scrol = Scrollbar(self.out_text)</span><br><span class="line">        self.scrol.config(command=self.out_text.yview)</span><br><span class="line">        self.out_text.config(yscrollcommand=self.scrol.set)</span><br><span class="line"></span><br><span class="line">        self.button_analyse = Button(self.root, text=<span class="string">'分析'</span>, command=self.analyse)</span><br><span class="line">        self.button_analyse.grid(row=<span class="number">3</span>, column=<span class="number">0</span>, sticky=W + E + N + S, columnspan=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.root.mainloop()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">analyse</span><span class="params">(self)</span>:</span></span><br><span class="line">        console = sys.stdout</span><br><span class="line">        <span class="keyword">with</span> open(self.temp_file, <span class="string">'w'</span>) <span class="keyword">as</span> temp_file:</span><br><span class="line">            sys.stdout = temp_file</span><br><span class="line">            self.compiler = compiler.Compiler(log_level=self.log_level)</span><br><span class="line">            self.compiler.analyse(self.in_file)</span><br><span class="line">        sys.__stdout__ = console</span><br><span class="line">        <span class="keyword">with</span> open(self.temp_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.out_text.insert(END, f.read())</span><br><span class="line">            self.out_text.see(END)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select_file</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.in_file = tkinter.filedialog.askopenfilename()</span><br><span class="line">        <span class="keyword">if</span> self.in_file != <span class="string">''</span>:</span><br><span class="line">            self.label.config(text=self.in_file)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.label.config(text=<span class="string">"您没有选择任何文件"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_log_level</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.log_level = int(self.boxlist.get())</span><br><span class="line"></span><br><span class="line">front_end = FrontEnd()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_productions.py</span><br><span class="line"><span class="keyword">import</span> compiler</span><br><span class="line"></span><br><span class="line"><span class="comment"># P -&gt; &#123; &#125; | &#123; AA &#125;</span></span><br><span class="line"><span class="comment"># AA-&gt; A | A AA</span></span><br><span class="line"><span class="comment"># A -&gt; DD | SS</span></span><br><span class="line"><span class="comment"># DD-&gt; D DD | D</span></span><br><span class="line"><span class="comment"># D -&gt; T ID FH</span></span><br><span class="line"><span class="comment"># ID-&gt; id | id = id | id = num | ID , ID</span></span><br><span class="line"><span class="comment"># T -&gt; T [ num ] | TY</span></span><br><span class="line"><span class="comment"># TY-&gt;int | float | char | bool</span></span><br><span class="line"><span class="comment"># SS-&gt; S | S SS</span></span><br><span class="line"><span class="comment"># S -&gt; L = E FH | if ( B ) S | if ( B ) S else S | while ( B ) S | do S while ( B ) FH | break FH | continue FH | P</span></span><br><span class="line"><span class="comment"># B -&gt; B or B | B and B | ! B | ( B ) | E &lt; E | E &gt; E | E &lt;= E | E &gt;= E | E == E | E != E | true | false</span></span><br><span class="line"><span class="comment"># E -&gt; E + E | E - E | E * E | E / E | L | ( E ) | num | id</span></span><br><span class="line"><span class="comment"># L -&gt; id [ E ] | id</span></span><br><span class="line"><span class="comment"># FH-&gt; ; | FH ;</span></span><br><span class="line"></span><br><span class="line">productions = &#123;</span><br><span class="line">    <span class="string">'P'</span>: [</span><br><span class="line">        [<span class="string">'&#123;'</span>, <span class="string">'AA'</span>, <span class="string">'&#125;'</span>],</span><br><span class="line">        [<span class="string">'&#123;'</span>, <span class="string">'&#125;'</span>],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'AA'</span>: [</span><br><span class="line">        [<span class="string">'A'</span>, ],</span><br><span class="line">        [<span class="string">'A'</span>, <span class="string">'AA'</span>]</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'A'</span>: [</span><br><span class="line">        [<span class="string">'DD'</span>, ],</span><br><span class="line">        [<span class="string">'SS'</span>, ]</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'DD'</span>: [</span><br><span class="line">        [<span class="string">'D'</span>, <span class="string">'DD'</span>],</span><br><span class="line">        [<span class="string">'D'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'D'</span>: [</span><br><span class="line">        [<span class="string">'T'</span>, <span class="string">'ID'</span>, <span class="string">'FH'</span>],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'ID'</span>: [</span><br><span class="line">        [<span class="string">'id'</span>, ],</span><br><span class="line">        [<span class="string">'id'</span>, <span class="string">'='</span>, <span class="string">'id'</span>],</span><br><span class="line">        [<span class="string">'id'</span>, <span class="string">'='</span>, <span class="string">'num'</span>],</span><br><span class="line">        [<span class="string">'ID'</span>, <span class="string">','</span>, <span class="string">'ID'</span>],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'T'</span>: [</span><br><span class="line">        [<span class="string">'T'</span>, <span class="string">'['</span>, <span class="string">'num'</span>, <span class="string">']'</span>],</span><br><span class="line">        [<span class="string">'TY'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'TY'</span>: [</span><br><span class="line">        [<span class="string">'int'</span>, ],</span><br><span class="line">        [<span class="string">'float'</span>, ],</span><br><span class="line">        [<span class="string">'char'</span>, ],</span><br><span class="line">        [<span class="string">'bool'</span>, ],</span><br><span class="line">        [<span class="string">'double'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'SS'</span>: [</span><br><span class="line">        [<span class="string">'S'</span>, <span class="string">'SS'</span>],</span><br><span class="line">        [<span class="string">'S'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'S'</span>: [</span><br><span class="line">        [<span class="string">'L'</span>, <span class="string">'='</span>, <span class="string">'E'</span>, <span class="string">'FH'</span>],</span><br><span class="line">        [<span class="string">'if'</span>, <span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>, <span class="string">'S'</span>],</span><br><span class="line">        [<span class="string">'if'</span>, <span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>, <span class="string">'S'</span>, <span class="string">'else'</span>, <span class="string">'S'</span>],</span><br><span class="line">        [<span class="string">'while'</span>, <span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>, <span class="string">'S'</span>],</span><br><span class="line">        [<span class="string">'while'</span>, <span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>, <span class="string">'FH'</span>],</span><br><span class="line">        [<span class="string">'do'</span>, <span class="string">'S'</span>, <span class="string">'while'</span>, <span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>, <span class="string">'FH'</span>],</span><br><span class="line">        [<span class="string">'break'</span>, <span class="string">'FH'</span>],</span><br><span class="line">        [<span class="string">'continue'</span>, <span class="string">'FH'</span>],</span><br><span class="line">        [<span class="string">'P'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'B'</span>: [</span><br><span class="line">        [<span class="string">'B'</span>, <span class="string">'or'</span>, <span class="string">'B'</span>],</span><br><span class="line">        [<span class="string">'B'</span>, <span class="string">'and'</span>, <span class="string">'B'</span>],</span><br><span class="line">        [<span class="string">'!'</span>, <span class="string">'B'</span>],</span><br><span class="line">        [<span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'&lt;'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'&gt;'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'&lt;='</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'&gt;='</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'=='</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'!='</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'true'</span>, ],</span><br><span class="line">        [<span class="string">'false'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'E'</span>: [</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'+'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'-'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'*'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'E'</span>, <span class="string">'/'</span>, <span class="string">'E'</span>],</span><br><span class="line">        [<span class="string">'L'</span>, ],</span><br><span class="line">        [<span class="string">'('</span>, <span class="string">'B'</span>, <span class="string">')'</span>],</span><br><span class="line">        [<span class="string">'num'</span>, ],</span><br><span class="line">        [<span class="string">'id'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'L'</span>: [</span><br><span class="line">        [<span class="string">'L'</span>, <span class="string">'['</span>, <span class="string">'E'</span>, <span class="string">']'</span>, ],</span><br><span class="line">        [<span class="string">'id'</span>, ],</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">'FH'</span>: [</span><br><span class="line">        [<span class="string">';'</span>, ],</span><br><span class="line">        [<span class="string">';'</span>, <span class="string">'FH'</span>, ],</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">start = <span class="string">'P'</span></span><br><span class="line">compiler.write_productions_to_file(start, productions)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;程序功能描述&quot;&gt;&lt;a href=&quot;#程序功能描述&quot; class=&quot;headerlink&quot; title=&quot;程序功能描述&quot;&gt;&lt;/a&gt;程序功能描述&lt;/h1&gt;&lt;p&gt;​        本次实验中，我用python3.5实现了一个简单的类C语言代码块文法的编译器前端，具有以下
      
    
    </summary>
    
      <category term="编译原理" scheme="http://wang22ti.com/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
    
  </entry>
  
  <entry>
    <title>《操作系统》课程设计-基于Linux0.11的多级队列进程调度算法</title>
    <link href="http://wang22ti.com/2018/06/21/%E3%80%8A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1-%E5%9F%BA%E4%BA%8ELinux0-11%E7%9A%84%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/"/>
    <id>http://wang22ti.com/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/</id>
    <published>2018-06-20T17:51:03.000Z</published>
    <updated>2018-07-03T11:48:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>​        只有真正的研读linux源代码，才能对操作系统有直观具体的认识；只有真正的修改linux源代码，才能对操作系统的某些方面有深刻的理解与掌握。因此，我选择linux内核中进程调度相关代码，在仔细研究之后对其做出合理正确修改，从而达到实验的目的。</p><h1 id="使用bochs修改、编译、运行linux-0-11"><a href="#使用bochs修改、编译、运行linux-0-11" class="headerlink" title="使用bochs修改、编译、运行linux-0.11"></a>使用bochs修改、编译、运行linux-0.11</h1><p>由于此前没有对linux内核进行系统地学习，所以本部分完全按照文献[1]中步骤进行，旨在熟悉linux内核的结构。唯一需要补充的是，为了完美修改文件bootsect.s中在系统引导中的输出，46和msg1是需要被同步修改的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">! Print some inane message  </span><br><span class="line">mov    ah,#0x03        ! read cursor pos  </span><br><span class="line">xor    bh,bh  </span><br><span class="line">int    0x10  </span><br><span class="line">mov    cx,#46  </span><br><span class="line">mov    bx,#0x0007        ! page 0, attribute 7 (normal)  </span><br><span class="line">mov    bp,#msg1  </span><br><span class="line">mov    ax,#0x1301        ! write string, move cursor  </span><br><span class="line">int    0x10</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">msg1:  </span><br><span class="line">.byte 13,10  </span><br><span class="line">.ascii &quot;Loading system ...this is from wang22ti&quot;  </span><br><span class="line">.byte 13,10,13,10  </span><br><span class="line">.org 508</span><br></pre></td></tr></table></figure><p>输出如下，符合预期。</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image1.png" alt="image1"></p><h1 id="Hack-linux0-11"><a href="#Hack-linux0-11" class="headerlink" title="Hack linux0.11"></a>Hack linux0.11</h1><p>​    使用bochs进行内核的学习，一方面编辑体验较差，另一方面操作繁琐，需要反复备份，因此很多时间浪费在与操作系统无关的操作上。所幸有资料[2]中作者有效的工作，使得在linux环境下，内核的修改、编译、运行变得极为容易方便，从而让学习者能够真正把精力放在操作系统中。<br>    将下载的压缩包提取到linux虚拟机（比如Ubuntu）的任意位置，并使用目录linux-0.11-master下通过make命令对内核完成编译如下图所示：</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image2.png" alt="image2"></p><p>如果是第一次运行，可能会提示缺少软件，只需要通过命令sudo apt-get install qemu安装即可。之后通过make start命令，linux0.11就跑起来啦：</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image3.png" alt="image3"></p><p>实际上该程序的作者将制作软盘镜像、配置虚拟机的过程全部写在Makefile中，本质是在linux(ubuntu)虚拟机里面跑了一台linux0.11的虚拟机。所以直接使用gedit或者vs code等等编辑器修改源代码后再重复上述操作即可，所以以下均使用该版本的linux0.11进行学习。</p><h1 id="linux内核进程调度算法的阅读"><a href="#linux内核进程调度算法的阅读" class="headerlink" title="linux内核进程调度算法的阅读"></a>linux内核进程调度算法的阅读</h1><p>​    linux进程调度算法是在/kernel/sched.c中实现的，另外比较重要的声明在/include/linux/sched.h和/include/signal.h两个头文件中，其中最需要的关注的是sched.c中的task数组和schedule函数、sched.h中对task_struct的声明、signal.h中对signal常量的宏定义。</p><h2 id="task与sched-h"><a href="#task与sched-h" class="headerlink" title="task与sched.h"></a>task与sched.h</h2><p>​    该数组存放了所有进程的指针，定义语句为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> * <span class="title">task</span>[<span class="title">NR_TASKS</span>] = &#123;</span>&amp;(init_task.task), &#125;;</span><br></pre></td></tr></table></figure><p>其中NR_TASKS为number of tasks=64在sched.h中的宏定义，而init_task定义在sched.c中：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">union</span> task_union init_task = &#123;INIT_TASK,&#125;;</span><br></pre></td></tr></table></figure><p>其中INIT_TASK是一个超大的数组，宏定义在Sched.h中：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INIT_TASK \</span></span><br><span class="line"><span class="comment">/* state etc */</span>&#123; <span class="number">0</span>,<span class="number">15</span>,<span class="number">15</span>, \</span><br><span class="line"><span class="comment">/* signals */</span><span class="number">0</span>,&#123;&#123;&#125;,&#125;,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* ec,brk... */</span><span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* pid etc.. */</span><span class="number">0</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* uid etc */</span><span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* alarm */</span><span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* math */</span><span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* fs info */</span><span class="number">-1</span>,<span class="number">0022</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* filp */</span>&#123;<span class="literal">NULL</span>,&#125;, \</span><br><span class="line">&#123; \</span><br><span class="line">&#123;<span class="number">0</span>,<span class="number">0</span>&#125;, \</span><br><span class="line"><span class="comment">/* ldt */</span>&#123;<span class="number">0x9f</span>,<span class="number">0xc0fa00</span>&#125;, \</span><br><span class="line">&#123;<span class="number">0x9f</span>,<span class="number">0xc0f200</span>&#125;, \</span><br><span class="line">&#125;, \</span><br><span class="line"><span class="comment">/*tss*/</span>&#123;<span class="number">0</span>,PAGE_SIZE+(<span class="keyword">long</span>)&amp;init_task,<span class="number">0x10</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,(<span class="keyword">long</span>)&amp;pg_dir,\</span><br><span class="line"> <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"> <span class="number">0</span>,<span class="number">0</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>, \</span><br><span class="line"> _LDT(<span class="number">0</span>),<span class="number">0x80000000</span>, \</span><br><span class="line">&#123;&#125; \</span><br><span class="line">&#125;, \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>综上，就可以明白linux中进程task有哪些属性、它是如何被初始化的。struct task_struct中state表示task的状态；counter可以理解为剩余的时间片；priority当然是优先级；signal需要参考signal.h中的宏定义，简而言之是每一位都有特定含义的“位图（bitmap）”；alarm是根据时间片设定的可以执行的最后时间；pid是进程的进程号。其他的可以参考文献4，在此不做赘述。</p><h2 id="schedule"><a href="#schedule" class="headerlink" title="schedule()"></a>schedule()</h2><p>​    所有linux进程都是依靠这个函数调度，但是实际上却不长：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">schedule</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i,next,c;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> ** <span class="title">p</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* check alarm, wake up any interruptible tasks that have got a signal */</span></span><br><span class="line"><span class="comment">// 遍历所有非空task指针</span></span><br><span class="line"><span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line"><span class="keyword">if</span> (*p) &#123;</span><br><span class="line"><span class="comment">// 如果alarm超过了jiffies（系统从开机到现在的时间，单位为10ms）</span></span><br><span class="line"><span class="keyword">if</span> ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;</span><br><span class="line">(*p)-&gt;signal |= (<span class="number">1</span>&lt;&lt;(SIGALRM<span class="number">-1</span>));</span><br><span class="line">(*p)-&gt;alarm = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 如果是可以就绪的task，设置状态为TASK_RUNNING</span></span><br><span class="line"><span class="keyword">if</span> (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;</span><br><span class="line">(*p)-&gt;state==TASK_INTERRUPTIBLE)</span><br><span class="line">(*p)-&gt;state=TASK_RUNNING;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* this is the scheduler proper: */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">c = <span class="number">-1</span>;</span><br><span class="line">next = <span class="number">0</span>;</span><br><span class="line">i = NR_TASKS;</span><br><span class="line">p = &amp;task[NR_TASKS];</span><br><span class="line"><span class="comment">// 保证next是counter最大的那一个</span></span><br><span class="line"><span class="keyword">while</span> (--i) &#123;</span><br><span class="line"><span class="keyword">if</span> (!*--p)</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="keyword">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)</span><br><span class="line">c = (*p)-&gt;counter, next = i;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (c) <span class="keyword">break</span>;</span><br><span class="line"><span class="comment">// counter与优先级正线性相关</span></span><br><span class="line"><span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line"><span class="keyword">if</span> (*p)</span><br><span class="line">(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; <span class="number">1</span>) +</span><br><span class="line">(*p)-&gt;priority;</span><br><span class="line">&#125;</span><br><span class="line">switch_to(next);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中除了变量声明，第一部分就是确定在本次正式调度之前，有哪些task是可以被调度的；第三部分switch_to(next);就是开始执行数组task中序号为next的进程；而第二部分要做的就是在可以被调度的task中选一个，将它的序号赋给next。linux0.11本质上选的是优先权最高的，所以其调度算法被称为基于时间片的优先级调度算法。 </p><h1 id="linux0-11进程调度算法的修改"><a href="#linux0-11进程调度算法的修改" class="headerlink" title="linux0.11进程调度算法的修改"></a>linux0.11进程调度算法的修改</h1><h2 id="随机调度算法"><a href="#随机调度算法" class="headerlink" title="随机调度算法"></a>随机调度算法</h2><p>​    为了验证hack linux的有效性，为正式修改进行实践经验的积累，先参照文献[4]将内核调度算法修改为基于时间片的随机调度算法。与原算法不同之处均已标注如下，其核心思想在于将jiffies作为随机数，在可调度的task中随机选择一个作为next。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//random*****************************************************************</span></span><br><span class="line"><span class="keyword">int</span> sum, rand, n;</span><br><span class="line"><span class="keyword">int</span> no[NR_TASKS];</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sum = <span class="number">0</span>;</span><br><span class="line">n = <span class="number">0</span>;</span><br><span class="line">next = <span class="number">0</span>;</span><br><span class="line">i = NR_TASKS;</span><br><span class="line">p = &amp;task[NR_TASKS];</span><br><span class="line"><span class="keyword">while</span> (--i) &#123;</span><br><span class="line"><span class="keyword">if</span> (!*--p) &#123;</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; <span class="number">0</span>) &#123;</span><br><span class="line">sum++;</span><br><span class="line">no[n++] = i;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (sum) <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line"><span class="keyword">if</span> (*p)</span><br><span class="line">(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; <span class="number">1</span>) +</span><br><span class="line">(*p)-&gt;priority;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rand = jiffies % sum;</span><br><span class="line">next = no[rand];</span><br></pre></td></tr></table></figure><p>经测试，在随机调度算法系统运行正常如下。 </p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image4.png" alt="image4"></p><h2 id="FIFO算法"><a href="#FIFO算法" class="headerlink" title="FIFO算法"></a>FIFO算法</h2><p>​    由于linux0.11中没有给出队列的数据结构（也有可能是我不知道），所以在sched.c中实现顺序队列结构queue_t以及对应的函数int init_queue(queue_t <em>queue)、void destroy_queue(queue_t </em>queue)、int is_empty_queue(queue_t <em>queue)、int is_full_queue(queue_t </em>queue)、void clear_queue(queue_t <em>queue)、int in_queue(queue_t </em>queue, data_t x)、void print_queue(queue_t <em>queue)、int enter_queue(queue_t </em>queue, data_t x)、int leave_queue(queue_t <em>queue)、data_t get_queue_front(queue_t </em>queue)、data_t get_queue_rear(queue_t *queue)。之所以没有新建头文件queue.h一方面是由于需要修改Makefile文件增加了无关工作量，另一方面更重要的是不方便在实验报告中描述。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> <span class="keyword">data_t</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">data_t</span> data[NR_TASKS]; <span class="comment">//用数组作为队列的储存空间</span></span><br><span class="line">    <span class="keyword">int</span> front,rear; <span class="comment">//指示队头位置和队尾位置的指针</span></span><br><span class="line">&#125;<span class="keyword">queue_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">init_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="built_in">queue</span> = (<span class="keyword">queue_t</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">queue_t</span>));</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">queue</span>-&gt;front = <span class="built_in">queue</span>-&gt;rear = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destroy_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> != <span class="literal">NULL</span>) <span class="built_in">free</span>(<span class="built_in">queue</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">is_empty_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">queue</span>-&gt;front == <span class="built_in">queue</span>-&gt;rear ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">is_full_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> ( ((<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS) == <span class="built_in">queue</span>-&gt;front ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;front = <span class="built_in">queue</span>-&gt;rear = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">in_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>, <span class="keyword">data_t</span> x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS; i &lt; (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS; i = (i + <span class="number">1</span>) % NR_TASKS) &#123;</span><br><span class="line"><span class="keyword">if</span> (x == <span class="built_in">queue</span>-&gt;data[i]) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS; i &lt; (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS; i = (i + <span class="number">1</span>) % NR_TASKS) &#123;</span><br><span class="line">printk(<span class="string">"%d "</span>, <span class="built_in">queue</span>-&gt;data[i]);</span><br><span class="line">&#125;</span><br><span class="line">printk(<span class="string">"\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">enter_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>, <span class="keyword">data_t</span> x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_full_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;rear = (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;data[<span class="built_in">queue</span>-&gt;rear] = x;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">leave_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"><span class="built_in">queue</span>-&gt;front = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">data_t</span> get_queue_front(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">queue</span>-&gt;data[(<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">data_t</span> get_queue_rear(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">queue</span>-&gt;data[<span class="built_in">queue</span>-&gt;rear];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了验证我写的顺序队列是有效的，同时为了多级队列积累实践经验，所以先实现基于时间片的FIFO调度算法。</p><p>在修改sched.c之前，要学会初始化一个全局的队列。由于linux在运行完boot相关的程序后运行/init/main.c完成内核的初始化，同时如下图注意到进程调度的初始化是由main函数中的sched_init();语句完成的：</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image5.png" alt="image5"></p><p>所以除了在sched.c中声明队列外，还需要在函数void sched_init(void)中调用函数int init_queue(queue_t *queue)完成对队列的初始化如下图，其中queue用在FIFO算法中，queue1和queue2用在多级队列中，以下不再赘述。</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image6.png" alt="image6"></p><p>接下来，同在随机调度部分相似，修改调度算法如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//FIFO***********************************************************************</span></span><br><span class="line"><span class="keyword">int</span> front_index = get_queue_front(&amp;task_queue);</span><br><span class="line">p = &amp;task[front_index];</span><br><span class="line">leave_queue(&amp;task_queue);</span><br><span class="line"></span><br><span class="line">i = NR_TASKS;</span><br><span class="line">p = &amp;task[NR_TASKS];</span><br><span class="line"><span class="keyword">while</span> (--i) &#123;</span><br><span class="line"><span class="keyword">if</span> (!*--p) &#123;</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (((*p)-&gt;state == TASK_RUNNING) &amp;&amp;</span><br><span class="line">(*p)-&gt;counter &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">!in_queue(&amp;task_queue, i) &amp;&amp;</span><br><span class="line">!is_full_queue(&amp;task_queue)) &#123;</span><br><span class="line">enter_queue(&amp;task_queue, i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// if (!is_empty_queue(&amp;task_queue)) &#123;print_queue(&amp;task_queue);&#125;</span></span><br><span class="line">next = get_queue_front(&amp;task_queue);</span><br></pre></td></tr></table></figure><p>由于只有在时间片结束或者进程结束才会调用函数schedule，所以直接让队首task出队，然后让所有就绪进程入队，最后调度队首task即可。经测试，在随机调度算法系统运行正常如下，其中会在队列非空时打印队列的进程号pid和时间片counter。进程号为1、2的进程应该是完成对系统的初始化。 </p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image7.png" alt="image7"></p><p>进一步运行ls命令，发现进程号为4的进程多次被调度，可以推测其作用为接受标准输入；而进程号为5、6、7的进程可能是bash处理输入命令的进程；进程号为3的进程应该是一个定时的检测函数，每个一段时间会被调度一次。 </p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image8.png" alt="image8"></p><h2 id="多级反馈队列算法"><a href="#多级反馈队列算法" class="headerlink" title="多级反馈队列算法"></a>多级反馈队列算法</h2><p>​        在上述积累的基础上，可以比较容易地实现基于时间片的两级队列调度算法。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// multi-queue****************************************************************</span></span><br><span class="line"><span class="comment">// 队首进程出队，task_queue1的优先级要高于task_queue2</span></span><br><span class="line"><span class="keyword">int</span> front_index1 = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">int</span> front_index2 = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;</span><br><span class="line">front_index1 = get_queue_front(&amp;task_queue1);</span><br><span class="line">p = &amp;task[front_index1];</span><br><span class="line">leave_queue(&amp;task_queue1);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;</span><br><span class="line">front_index2 = get_queue_front(&amp;task_queue2);</span><br><span class="line">p = &amp;task[front_index2];</span><br><span class="line">leave_queue(&amp;task_queue2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在所有就绪的task中，如果非此前的队首task，入task_queue1并置时间片为优先级；否则入task_queue2并置时间片为优先级5倍</span></span><br><span class="line">i = NR_TASKS;</span><br><span class="line">p = &amp;task[NR_TASKS];</span><br><span class="line"><span class="keyword">while</span> (--i) &#123;</span><br><span class="line"><span class="keyword">if</span> (!*--p) &#123;</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (((*p)-&gt;state == TASK_RUNNING) &amp;&amp;</span><br><span class="line">(*p)-&gt;counter &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">!in_queue(&amp;task_queue1, i) &amp;&amp;</span><br><span class="line">!in_queue(&amp;task_queue2, i) &amp;&amp;</span><br><span class="line">!is_full_queue(&amp;task_queue1)</span><br><span class="line">)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (front_index2 == i ||front_index1 == i) &#123;</span><br><span class="line">enter_queue(&amp;task_queue2, i);</span><br><span class="line">(*p)-&gt;counter = <span class="comment">//((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line">(*p)-&gt;priority * <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">enter_queue(&amp;task_queue1, i);</span><br><span class="line">(*p)-&gt;counter = <span class="comment">//((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line">(*p)-&gt;priority;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调度下一个task，task_queue1的优先级要高于task_queue2，如果两个队列均空就调度默认task</span></span><br><span class="line">next = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;</span><br><span class="line">next = get_queue_front(&amp;task_queue1);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;</span><br><span class="line">next = get_queue_front(&amp;task_queue2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;printk(<span class="string">"1:\t"</span>); print_queue(&amp;task_queue1);&#125;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;printk(<span class="string">"2:\t"</span>); print_queue(&amp;task_queue2);&#125;</span><br></pre></td></tr></table></figure><p>和FIFO部分相同，对多级队列调度算法进行测试如下。</p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image9.png" alt="image9"></p><p><img src="/2018/06/21/《操作系统》课程设计-基于Linux0-11的多级队列进程调度算法/image10.png" alt="image10"></p><p>可见很好的完成了多级队列的调度，队列1具有高优先级，其中的任务在时间片结束时若没有执行完则进入队列2且具有5倍的时间片。 </p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>​        本次实验中，通过对于linux0.11内核的阅读与修改，让我对操作系统的运行方法有了较为直观鲜明的认识，同时进一步熟悉了随机、FIFO和多级队列三种算法。这一方面提高了我的编程能力，另一方面更重要的是激发了探索的热情，这必将为我今后的学习带来取之不尽的财富。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] Windows下用Bochs编译运行Linux-0.11</p><p><a href="https://blog.csdn.net/u014688145/article/details/50575588" target="_blank" rel="noopener">https://blog.csdn.net/u014688145/article/details/50575588</a></p><p>[2] hack linux </p><p><a href="https://github.com/yuanxinyu/Linux-0.11" target="_blank" rel="noopener">https://github.com/yuanxinyu/Linux-0.11</a></p><p>[3] linux0.11相关进程数据结构</p><p><a href="http://www.cppblog.com/jake1036/archive/2010/11/13/133530.html" target="_blank" rel="noopener">http://www.cppblog.com/jake1036/archive/2010/11/13/133530.html</a></p><p>[4] 俞露. 基于Linux随机进程调度算法的实现[J]. 福建电脑,2013,29(02):108-109.</p><h1 id="附录：实验源码"><a href="#附录：实验源码" class="headerlink" title="附录：实验源码"></a>附录：实验源码</h1><p>​        本次实验中修改过的文件包括/kernel/sched.c和/init/main.c，为保证完整性将两者全部复制如下。</p><h2 id="sched-c"><a href="#sched-c" class="headerlink" title="sched.c"></a>sched.c</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  linux/kernel/sched.c</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  (C) 1991  Linus Torvalds</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 'sched.c' is the main kernel file. It contains scheduling primitives</span></span><br><span class="line"><span class="comment"> * (sleep_on, wakeup, schedule etc) as well as a number of simple system</span></span><br><span class="line"><span class="comment"> * call functions (type getpid(), which just extracts a field from</span></span><br><span class="line"><span class="comment"> * current-task</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/kernel.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sys.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/fdreg.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;asm/system.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;asm/io.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;asm/segment.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _S(nr) (1&lt;&lt;((nr)-1))</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _BLOCKABLE (~(_S(SIGKILL) | _S(SIGSTOP)))</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_task</span><span class="params">(<span class="keyword">int</span> nr,struct task_struct * p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i,j = <span class="number">4096</span>-<span class="keyword">sizeof</span>(struct task_struct);</span><br><span class="line"></span><br><span class="line">printk(<span class="string">"%d: pid=%d, state=%d, "</span>,nr,p-&gt;pid,p-&gt;state);</span><br><span class="line">i=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (i&lt;j &amp;&amp; !((<span class="keyword">char</span> *)(p+<span class="number">1</span>))[i])</span><br><span class="line">i++;</span><br><span class="line">printk(<span class="string">"%d (of %d) chars free in kernel stack\n\r"</span>,i,j);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_stat</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;NR_TASKS;i++)</span><br><span class="line"><span class="keyword">if</span> (task[i])</span><br><span class="line">show_task(i,task[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LATCH (1193180/HZ)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">mem_use</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">int</span> <span class="title">timer_interrupt</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">int</span> <span class="title">system_call</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">union</span> task_union &#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> <span class="title">task</span>;</span></span><br><span class="line"><span class="keyword">char</span> <span class="built_in">stack</span>[PAGE_SIZE];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">union</span> task_union init_task = &#123;INIT_TASK,&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">long</span> <span class="keyword">volatile</span> jiffies=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">long</span> startup_time=<span class="number">0</span>;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">current</span> = &amp;(<span class="title">init_task</span>.<span class="title">task</span>);</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">last_task_used_math</span> = <span class="title">NULL</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> * <span class="title">task</span>[<span class="title">NR_TASKS</span>] = &#123;</span>&amp;(init_task.task), &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">long</span> user_stack [ PAGE_SIZE&gt;&gt;<span class="number">2</span> ] ;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line"><span class="keyword">long</span> * a;</span><br><span class="line"><span class="keyword">short</span> b;</span><br><span class="line">&#125; stack_start = &#123; &amp; user_stack [PAGE_SIZE&gt;&gt;<span class="number">2</span>] , <span class="number">0x10</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// queue</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> <span class="keyword">data_t</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">data_t</span> data[NR_TASKS]; <span class="comment">//用数组作为队列的储存空间</span></span><br><span class="line">    <span class="keyword">int</span> front,rear; <span class="comment">//指示队头位置和队尾位置的指针</span></span><br><span class="line">&#125;<span class="keyword">queue_t</span>;</span><br><span class="line"><span class="keyword">queue_t</span> task_queue;</span><br><span class="line"><span class="keyword">queue_t</span> task_queue1;</span><br><span class="line"><span class="keyword">queue_t</span> task_queue2;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">init_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="built_in">queue</span> = (<span class="keyword">queue_t</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">queue_t</span>));</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">queue</span>-&gt;front = <span class="built_in">queue</span>-&gt;rear = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">destroy_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> != <span class="literal">NULL</span>) <span class="built_in">free</span>(<span class="built_in">queue</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">is_empty_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">queue</span>-&gt;front == <span class="built_in">queue</span>-&gt;rear ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">is_full_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> ( ((<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS) == <span class="built_in">queue</span>-&gt;front ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;front = <span class="built_in">queue</span>-&gt;rear = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">in_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>, <span class="keyword">data_t</span> x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS; i &lt; (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS; i = (i + <span class="number">1</span>) % NR_TASKS) &#123;</span><br><span class="line"><span class="keyword">if</span> (x == <span class="built_in">queue</span>-&gt;data[i]) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS; i &lt; (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS; i = (i + <span class="number">1</span>) % NR_TASKS) &#123;</span><br><span class="line"><span class="comment">// printk("%d ", queue-&gt;data[i]);</span></span><br><span class="line"><span class="keyword">int</span> index = <span class="built_in">queue</span>-&gt;data[i];</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> ** <span class="title">p</span> = &amp;<span class="title">task</span>[<span class="title">index</span>];</span></span><br><span class="line">printk(<span class="string">"%d - %d\t"</span>, (*p)-&gt;pid, (*p)-&gt;counter);</span><br><span class="line">&#125;</span><br><span class="line">printk(<span class="string">"\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">enter_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>, <span class="keyword">data_t</span> x)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_full_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;rear = (<span class="built_in">queue</span>-&gt;rear + <span class="number">1</span>) % NR_TASKS;</span><br><span class="line">    <span class="built_in">queue</span>-&gt;data[<span class="built_in">queue</span>-&gt;rear] = x;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">leave_queue</span><span class="params">(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"><span class="built_in">queue</span>-&gt;front = (<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">data_t</span> get_queue_front(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">queue</span>-&gt;data[(<span class="built_in">queue</span>-&gt;front + <span class="number">1</span>) % NR_TASKS];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">data_t</span> get_queue_rear(<span class="keyword">queue_t</span> *<span class="built_in">queue</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span> == <span class="literal">NULL</span> || is_empty_queue(<span class="built_in">queue</span>)) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">queue</span>-&gt;data[<span class="built_in">queue</span>-&gt;rear];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  'math_state_restore()' saves the current math information in the</span></span><br><span class="line"><span class="comment"> * old math state array, and gets the new ones from the current task</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">math_state_restore</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (last_task_used_math == current)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">__asm__(<span class="string">"fwait"</span>);</span><br><span class="line"><span class="keyword">if</span> (last_task_used_math) &#123;</span><br><span class="line">__asm__(<span class="string">"fnsave %0"</span>::<span class="string">"m"</span> (last_task_used_math-&gt;tss.i387));</span><br><span class="line">&#125;</span><br><span class="line">last_task_used_math=current;</span><br><span class="line"><span class="keyword">if</span> (current-&gt;used_math) &#123;</span><br><span class="line">__asm__(<span class="string">"frstor %0"</span>::<span class="string">"m"</span> (current-&gt;tss.i387));</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">__asm__(<span class="string">"fninit"</span>::);</span><br><span class="line">current-&gt;used_math=<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  'schedule()' is the scheduler function. This is GOOD CODE! There</span></span><br><span class="line"><span class="comment"> * probably won't be any reason to change this, as it should work well</span></span><br><span class="line"><span class="comment"> * in all circumstances (ie gives IO-bound processes good response etc).</span></span><br><span class="line"><span class="comment"> * The one thing you might take a look at is the signal-handler code here.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *   NOTE!!  Task 0 is the 'idle' task, which gets called when no other</span></span><br><span class="line"><span class="comment"> * tasks can run. It can not be killed, and it cannot sleep. The 'state'</span></span><br><span class="line"><span class="comment"> * information in task[0] is never used.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">schedule</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i,next,c;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> ** <span class="title">p</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* check alarm, wake up any interruptible tasks that have got a signal */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line"><span class="keyword">if</span> (*p) &#123;</span><br><span class="line"><span class="keyword">if</span> ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;</span><br><span class="line">(*p)-&gt;signal |= (<span class="number">1</span>&lt;&lt;(SIGALRM<span class="number">-1</span>));</span><br><span class="line">(*p)-&gt;alarm = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;</span><br><span class="line">(*p)-&gt;state==TASK_INTERRUPTIBLE)</span><br><span class="line">(*p)-&gt;state=TASK_RUNNING;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* this is the scheduler proper: */</span></span><br><span class="line"><span class="comment">// default*************************************************************************</span></span><br><span class="line"><span class="comment">/*while (1) &#123;</span></span><br><span class="line"><span class="comment">c = -1;</span></span><br><span class="line"><span class="comment">next = 0;</span></span><br><span class="line"><span class="comment">i = NR_TASKS;</span></span><br><span class="line"><span class="comment">p = &amp;task[NR_TASKS];</span></span><br><span class="line"><span class="comment">while (--i) &#123;</span></span><br><span class="line"><span class="comment">if (!*--p)</span></span><br><span class="line"><span class="comment">continue;</span></span><br><span class="line"><span class="comment">if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)</span></span><br><span class="line"><span class="comment">c = (*p)-&gt;counter, next = i;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">if (c) break;</span></span><br><span class="line"><span class="comment">for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span></span><br><span class="line"><span class="comment">if (*p)</span></span><br><span class="line"><span class="comment">(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line"><span class="comment">(*p)-&gt;priority;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//random*************************************************************************</span></span><br><span class="line"><span class="comment">/*int sum, rand, n;</span></span><br><span class="line"><span class="comment">int no[NR_TASKS];</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">while (1) &#123;</span></span><br><span class="line"><span class="comment">sum = 0;</span></span><br><span class="line"><span class="comment">n = 0;</span></span><br><span class="line"><span class="comment">next = 0;</span></span><br><span class="line"><span class="comment">i = NR_TASKS;</span></span><br><span class="line"><span class="comment">p = &amp;task[NR_TASKS];</span></span><br><span class="line"><span class="comment">while (--i) &#123;</span></span><br><span class="line"><span class="comment">if (!*--p) &#123;</span></span><br><span class="line"><span class="comment">continue;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; 0) &#123;</span></span><br><span class="line"><span class="comment">sum++;</span></span><br><span class="line"><span class="comment">no[n++] = i;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">if (sum) break;</span></span><br><span class="line"><span class="comment">for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span></span><br><span class="line"><span class="comment">if (*p)</span></span><br><span class="line"><span class="comment">(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line"><span class="comment">(*p)-&gt;priority;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">rand = jiffies % sum;</span></span><br><span class="line"><span class="comment">next = no[rand];*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//FIFO*************************************************************************</span></span><br><span class="line"><span class="comment">/*int front_index = get_queue_front(&amp;task_queue);</span></span><br><span class="line"><span class="comment">p = &amp;task[front_index];</span></span><br><span class="line"><span class="comment">leave_queue(&amp;task_queue);</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">i = NR_TASKS;</span></span><br><span class="line"><span class="comment">p = &amp;task[NR_TASKS];</span></span><br><span class="line"><span class="comment">while (--i) &#123;</span></span><br><span class="line"><span class="comment">if (!*--p) &#123;</span></span><br><span class="line"><span class="comment">continue;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">if (((*p)-&gt;state == TASK_RUNNING) &amp;&amp;</span></span><br><span class="line"><span class="comment">(*p)-&gt;counter &gt; 0 &amp;&amp;</span></span><br><span class="line"><span class="comment">!in_queue(&amp;task_queue, i) &amp;&amp;</span></span><br><span class="line"><span class="comment">!is_full_queue(&amp;task_queue)) &#123;</span></span><br><span class="line"><span class="comment">enter_queue(&amp;task_queue, i);</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">if (!is_empty_queue(&amp;task_queue)) &#123;print_queue(&amp;task_queue);&#125;</span></span><br><span class="line"><span class="comment">next = get_queue_front(&amp;task_queue);*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// multi-queue*************************************************************************</span></span><br><span class="line"><span class="keyword">int</span> front_index1 = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">int</span> front_index2 = <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;</span><br><span class="line">front_index1 = get_queue_front(&amp;task_queue1);</span><br><span class="line">p = &amp;task[front_index1];</span><br><span class="line">leave_queue(&amp;task_queue1);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;</span><br><span class="line">front_index2 = get_queue_front(&amp;task_queue2);</span><br><span class="line">p = &amp;task[front_index2];</span><br><span class="line">leave_queue(&amp;task_queue2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">i = NR_TASKS;</span><br><span class="line">p = &amp;task[NR_TASKS];</span><br><span class="line"><span class="keyword">while</span> (--i) &#123;</span><br><span class="line"><span class="keyword">if</span> (!*--p) &#123;</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (((*p)-&gt;state == TASK_RUNNING) &amp;&amp;</span><br><span class="line">(*p)-&gt;counter &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">!in_queue(&amp;task_queue1, i) &amp;&amp;</span><br><span class="line">!in_queue(&amp;task_queue2, i) &amp;&amp;</span><br><span class="line">!is_full_queue(&amp;task_queue1)</span><br><span class="line">)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (front_index2 == i ||front_index1 == i) &#123;</span><br><span class="line">enter_queue(&amp;task_queue2, i);</span><br><span class="line">(*p)-&gt;counter = <span class="comment">//((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line">(*p)-&gt;priority * <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">enter_queue(&amp;task_queue1, i);</span><br><span class="line">(*p)-&gt;counter = <span class="comment">//((*p)-&gt;counter &gt;&gt; 1) +</span></span><br><span class="line">(*p)-&gt;priority;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">next = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;</span><br><span class="line">next = get_queue_front(&amp;task_queue1);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;</span><br><span class="line">next = get_queue_front(&amp;task_queue2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue1)) &#123;printk(<span class="string">"1:\t"</span>); print_queue(&amp;task_queue1);&#125;</span><br><span class="line"><span class="keyword">if</span> (!is_empty_queue(&amp;task_queue2)) &#123;printk(<span class="string">"2:\t"</span>); print_queue(&amp;task_queue2);&#125;</span><br><span class="line">switch_to(next);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_pause</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">current-&gt;state = TASK_INTERRUPTIBLE;</span><br><span class="line">schedule();</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sleep_on</span><span class="params">(struct task_struct **p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">tmp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!p)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">if</span> (current == &amp;(init_task.task))</span><br><span class="line">panic(<span class="string">"task[0] trying to sleep"</span>);</span><br><span class="line">tmp = *p;</span><br><span class="line">*p = current;</span><br><span class="line">current-&gt;state = TASK_UNINTERRUPTIBLE;</span><br><span class="line">schedule();</span><br><span class="line"><span class="keyword">if</span> (tmp)</span><br><span class="line">tmp-&gt;state=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">interruptible_sleep_on</span><span class="params">(struct task_struct **p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">tmp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!p)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">if</span> (current == &amp;(init_task.task))</span><br><span class="line">panic(<span class="string">"task[0] trying to sleep"</span>);</span><br><span class="line">tmp=*p;</span><br><span class="line">*p=current;</span><br><span class="line">repeat:current-&gt;state = TASK_INTERRUPTIBLE;</span><br><span class="line">schedule();</span><br><span class="line"><span class="keyword">if</span> (*p &amp;&amp; *p != current) &#123;</span><br><span class="line">(**p).state=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">goto</span> repeat;</span><br><span class="line">&#125;</span><br><span class="line">*p=<span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">if</span> (tmp)</span><br><span class="line">tmp-&gt;state=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">wake_up</span><span class="params">(struct task_struct **p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (p &amp;&amp; *p) &#123;</span><br><span class="line">(**p).state=<span class="number">0</span>;</span><br><span class="line">*p=<span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * OK, here are some floppy things that shouldn't be in the kernel</span></span><br><span class="line"><span class="comment"> * proper. They are here because the floppy needs a timer, and this</span></span><br><span class="line"><span class="comment"> * was the easiest way of doing it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> * <span class="title">wait_motor</span>[4] = &#123;</span><span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>&#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span>  mon_timer[<span class="number">4</span>]=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> moff_timer[<span class="number">4</span>]=&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> current_DOR = <span class="number">0x0C</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ticks_to_floppy_on</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> nr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> selected;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> mask = <span class="number">0x10</span> &lt;&lt; nr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (nr&gt;<span class="number">3</span>)</span><br><span class="line">panic(<span class="string">"floppy_on: nr&gt;3"</span>);</span><br><span class="line">moff_timer[nr]=<span class="number">10000</span>;<span class="comment">/* 100 s = very big :-) */</span></span><br><span class="line">cli();<span class="comment">/* use floppy_off to turn it off */</span></span><br><span class="line">mask |= current_DOR;</span><br><span class="line"><span class="keyword">if</span> (!selected) &#123;</span><br><span class="line">mask &amp;= <span class="number">0xFC</span>;</span><br><span class="line">mask |= nr;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (mask != current_DOR) &#123;</span><br><span class="line">outb(mask,FD_DOR);</span><br><span class="line"><span class="keyword">if</span> ((mask ^ current_DOR) &amp; <span class="number">0xf0</span>)</span><br><span class="line">mon_timer[nr] = HZ/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (mon_timer[nr] &lt; <span class="number">2</span>)</span><br><span class="line">mon_timer[nr] = <span class="number">2</span>;</span><br><span class="line">current_DOR = mask;</span><br><span class="line">&#125;</span><br><span class="line">sti();</span><br><span class="line"><span class="keyword">return</span> mon_timer[nr];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">floppy_on</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> nr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">cli();</span><br><span class="line"><span class="keyword">while</span> (ticks_to_floppy_on(nr))</span><br><span class="line">sleep_on(nr+wait_motor);</span><br><span class="line">sti();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">floppy_off</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> nr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">moff_timer[nr]=<span class="number">3</span>*HZ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_floppy_timer</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> mask = <span class="number">0x10</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span> ; i&lt;<span class="number">4</span> ; i++,mask &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (!(mask &amp; current_DOR))</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line"><span class="keyword">if</span> (mon_timer[i]) &#123;</span><br><span class="line"><span class="keyword">if</span> (!--mon_timer[i])</span><br><span class="line">wake_up(i+wait_motor);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (!moff_timer[i]) &#123;</span><br><span class="line">current_DOR &amp;= ~mask;</span><br><span class="line">outb(current_DOR,FD_DOR);</span><br><span class="line">&#125; <span class="keyword">else</span></span><br><span class="line">moff_timer[i]--;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TIME_REQUESTS 64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">timer_list</span> &#123;</span></span><br><span class="line"><span class="keyword">long</span> jiffies;</span><br><span class="line"><span class="keyword">void</span> (*fn)();</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">timer_list</span> * <span class="title">next</span>;</span></span><br><span class="line">&#125; timer_list[TIME_REQUESTS], * next_timer = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">void add_timer(long jiffies, void (*fn)(void))</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">timer_list</span> * <span class="title">p</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!fn)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">cli();</span><br><span class="line"><span class="keyword">if</span> (jiffies &lt;= <span class="number">0</span>)</span><br><span class="line">(fn)();</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (p = timer_list ; p &lt; timer_list + TIME_REQUESTS ; p++)</span><br><span class="line"><span class="keyword">if</span> (!p-&gt;fn)</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">if</span> (p &gt;= timer_list + TIME_REQUESTS)</span><br><span class="line">panic(<span class="string">"No more time requests free"</span>);</span><br><span class="line">p-&gt;fn = fn;</span><br><span class="line">p-&gt;jiffies = jiffies;</span><br><span class="line">p-&gt;next = next_timer;</span><br><span class="line">next_timer = p;</span><br><span class="line"><span class="keyword">while</span> (p-&gt;next &amp;&amp; p-&gt;next-&gt;jiffies &lt; p-&gt;jiffies) &#123;</span><br><span class="line">p-&gt;jiffies -= p-&gt;next-&gt;jiffies;</span><br><span class="line">fn = p-&gt;fn;</span><br><span class="line">p-&gt;fn = p-&gt;next-&gt;fn;</span><br><span class="line">p-&gt;next-&gt;fn = fn;</span><br><span class="line">jiffies = p-&gt;jiffies;</span><br><span class="line">p-&gt;jiffies = p-&gt;next-&gt;jiffies;</span><br><span class="line">p-&gt;next-&gt;jiffies = jiffies;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">sti();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_timer</span><span class="params">(<span class="keyword">long</span> cpl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> beepcount;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">sysbeepstop</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (beepcount)</span><br><span class="line"><span class="keyword">if</span> (!--beepcount)</span><br><span class="line">sysbeepstop();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cpl)</span><br><span class="line">current-&gt;utime++;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">current-&gt;stime++;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (next_timer) &#123;</span><br><span class="line">next_timer-&gt;jiffies--;</span><br><span class="line"><span class="keyword">while</span> (next_timer &amp;&amp; next_timer-&gt;jiffies &lt;= <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">void</span> (*fn)(<span class="keyword">void</span>);</span><br><span class="line"></span><br><span class="line">fn = next_timer-&gt;fn;</span><br><span class="line">next_timer-&gt;fn = <span class="literal">NULL</span>;</span><br><span class="line">next_timer = next_timer-&gt;next;</span><br><span class="line">(fn)();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (current_DOR &amp; <span class="number">0xf0</span>)</span><br><span class="line">do_floppy_timer();</span><br><span class="line"><span class="keyword">if</span> ((--current-&gt;counter)&gt;<span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">current-&gt;counter=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (!cpl) <span class="keyword">return</span>;</span><br><span class="line">schedule();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_alarm</span><span class="params">(<span class="keyword">long</span> seconds)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> old = current-&gt;alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (old)</span><br><span class="line">old = (old - jiffies) / HZ;</span><br><span class="line">current-&gt;alarm = (seconds&gt;<span class="number">0</span>)?(jiffies+HZ*seconds):<span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> (old);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_getpid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;pid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_getppid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;father;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_getuid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;uid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_geteuid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;euid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_getgid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;gid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_getegid</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> current-&gt;egid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_nice</span><span class="params">(<span class="keyword">long</span> increment)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (current-&gt;priority-increment&gt;<span class="number">0</span>)</span><br><span class="line">current-&gt;priority -= increment;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sched_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">desc_struct</span> * <span class="title">p</span>;</span></span><br><span class="line">init_queue(&amp;task_queue);</span><br><span class="line">init_queue(&amp;task_queue1);</span><br><span class="line">init_queue(&amp;task_queue2);</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">sizeof</span>(struct sigaction) != <span class="number">16</span>)</span><br><span class="line">panic(<span class="string">"Struct sigaction MUST be 16 bytes"</span>);</span><br><span class="line">set_tss_desc(gdt+FIRST_TSS_ENTRY,&amp;(init_task.task.tss));</span><br><span class="line">set_ldt_desc(gdt+FIRST_LDT_ENTRY,&amp;(init_task.task.ldt));</span><br><span class="line">p = gdt+<span class="number">2</span>+FIRST_TSS_ENTRY;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;NR_TASKS;i++) &#123;</span><br><span class="line">task[i] = <span class="literal">NULL</span>;</span><br><span class="line">p-&gt;a=p-&gt;b=<span class="number">0</span>;</span><br><span class="line">p++;</span><br><span class="line">p-&gt;a=p-&gt;b=<span class="number">0</span>;</span><br><span class="line">p++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* Clear NT, so that we won't have troubles with that later on */</span></span><br><span class="line">__asm__(<span class="string">"pushfl ; andl $0xffffbfff,(%esp) ; popfl"</span>);</span><br><span class="line">ltr(<span class="number">0</span>);</span><br><span class="line">lldt(<span class="number">0</span>);</span><br><span class="line">outb_p(<span class="number">0x36</span>,<span class="number">0x43</span>);<span class="comment">/* binary, mode 3, LSB/MSB, ch 0 */</span></span><br><span class="line">outb_p(LATCH &amp; <span class="number">0xff</span> , <span class="number">0x40</span>);<span class="comment">/* LSB */</span></span><br><span class="line">outb(LATCH &gt;&gt; <span class="number">8</span> , <span class="number">0x40</span>);<span class="comment">/* MSB */</span></span><br><span class="line">set_intr_gate(<span class="number">0x20</span>,&amp;timer_interrupt);</span><br><span class="line">outb(inb_p(<span class="number">0x21</span>)&amp;~<span class="number">0x01</span>,<span class="number">0x21</span>);</span><br><span class="line">set_system_gate(<span class="number">0x80</span>,&amp;system_call);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="main-c"><a href="#main-c" class="headerlink" title="main.c"></a>main.c</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  linux/init/main.c</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  (C) 1991  Linus Torvalds</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __LIBRARY__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * we need this inline - forking from kernel space will result</span></span><br><span class="line"><span class="comment"> * in NO COPY ON WRITE (!!!), until an execve is executed. This</span></span><br><span class="line"><span class="comment"> * is no problem, but for the stack. This is handled by not letting</span></span><br><span class="line"><span class="comment"> * main() use the stack at all after fork(). Thus, no function</span></span><br><span class="line"><span class="comment"> * calls - which means inline code for fork too, as otherwise we</span></span><br><span class="line"><span class="comment"> * would use the stack upon exit from 'fork()'.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Actually only pause and fork are needed inline, so that there</span></span><br><span class="line"><span class="comment"> * won't be any messing with the stack from main(), but we define</span></span><br><span class="line"><span class="comment"> * some others too.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">static inline fork(void) __attribute__((always_inline));</span><br><span class="line">static inline pause(void) __attribute__((always_inline));</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> _syscall0(<span class="keyword">int</span>,fork)</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> _syscall0(<span class="keyword">int</span>,pause)</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> _syscall1(<span class="keyword">int</span>,setup,<span class="keyword">void</span> *,BIOS)</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> _syscall0(<span class="keyword">int</span>,sync)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/tty.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/head.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;asm/system.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;asm/io.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stddef.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdarg.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/fs.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> printbuf[<span class="number">1024</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">int</span> <span class="title">vsprintf</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">blk_dev_init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">chr_dev_init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">hd_init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">floppy_init</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">mem_init</span><span class="params">(<span class="keyword">long</span> start, <span class="keyword">long</span> end)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">long</span> <span class="title">rd_init</span><span class="params">(<span class="keyword">long</span> mem_start, <span class="keyword">int</span> length)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">long</span> <span class="title">kernel_mktime</span><span class="params">(struct tm * tm)</span></span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">long</span> startup_time;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This is set up by the setup-routine at boot-time</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> EXT_MEM_K (*(unsigned short *)0x90002)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DRIVE_INFO (*(struct drive_info *)0x90080)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ORIG_ROOT_DEV (*(unsigned short *)0x901FC)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Yeah, yeah, it's ugly, but I cannot find how to do this correctly</span></span><br><span class="line"><span class="comment"> * and this seems to work. I anybody has more info on the real-time</span></span><br><span class="line"><span class="comment"> * clock I'd be interested. Most of this was trial and error, and some</span></span><br><span class="line"><span class="comment"> * bios-listing reading. Urghh.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CMOS_READ(addr) (&#123; \</span></span><br><span class="line">outb_p(<span class="number">0x80</span>|addr,<span class="number">0x70</span>); \</span><br><span class="line">inb_p(<span class="number">0x71</span>); \</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BCD_TO_BIN(val) ((val)=((val)&amp;15) + ((val)&gt;&gt;4)*10)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">time_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tm</span> <span class="title">time</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">time.tm_sec = CMOS_READ(<span class="number">0</span>);</span><br><span class="line">time.tm_min = CMOS_READ(<span class="number">2</span>);</span><br><span class="line">time.tm_hour = CMOS_READ(<span class="number">4</span>);</span><br><span class="line">time.tm_mday = CMOS_READ(<span class="number">7</span>);</span><br><span class="line">time.tm_mon = CMOS_READ(<span class="number">8</span>);</span><br><span class="line">time.tm_year = CMOS_READ(<span class="number">9</span>);</span><br><span class="line">&#125; <span class="keyword">while</span> (time.tm_sec != CMOS_READ(<span class="number">0</span>));</span><br><span class="line">BCD_TO_BIN(time.tm_sec);</span><br><span class="line">BCD_TO_BIN(time.tm_min);</span><br><span class="line">BCD_TO_BIN(time.tm_hour);</span><br><span class="line">BCD_TO_BIN(time.tm_mday);</span><br><span class="line">BCD_TO_BIN(time.tm_mon);</span><br><span class="line">BCD_TO_BIN(time.tm_year);</span><br><span class="line">time.tm_mon--;</span><br><span class="line">startup_time = kernel_mktime(&amp;time);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">long</span> memory_end = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">long</span> buffer_memory_end = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">long</span> main_memory_start = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">drive_info</span> &#123;</span> <span class="keyword">char</span> dummy[<span class="number">32</span>]; &#125; drive_info;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span><span class="comment">/* This really IS void, no error here. */</span></span></span><br><span class="line"><span class="function"></span>&#123;<span class="comment">/* The startup routine assumes (well, ...) this */</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Interrupts are still disabled. Do necessary setups, then</span></span><br><span class="line"><span class="comment"> * enable them</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"> ROOT_DEV = ORIG_ROOT_DEV;</span><br><span class="line"> drive_info = DRIVE_INFO;</span><br><span class="line">memory_end = (<span class="number">1</span>&lt;&lt;<span class="number">20</span>) + (EXT_MEM_K&lt;&lt;<span class="number">10</span>);</span><br><span class="line">memory_end &amp;= <span class="number">0xfffff000</span>;</span><br><span class="line"><span class="keyword">if</span> (memory_end &gt; <span class="number">16</span>*<span class="number">1024</span>*<span class="number">1024</span>)</span><br><span class="line">memory_end = <span class="number">16</span>*<span class="number">1024</span>*<span class="number">1024</span>;</span><br><span class="line"><span class="keyword">if</span> (memory_end &gt; <span class="number">12</span>*<span class="number">1024</span>*<span class="number">1024</span>) </span><br><span class="line">buffer_memory_end = <span class="number">4</span>*<span class="number">1024</span>*<span class="number">1024</span>;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (memory_end &gt; <span class="number">6</span>*<span class="number">1024</span>*<span class="number">1024</span>)</span><br><span class="line">buffer_memory_end = <span class="number">2</span>*<span class="number">1024</span>*<span class="number">1024</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">buffer_memory_end = <span class="number">1</span>*<span class="number">1024</span>*<span class="number">1024</span>;</span><br><span class="line">main_memory_start = buffer_memory_end;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> RAMDISK</span></span><br><span class="line">main_memory_start += rd_init(main_memory_start, RAMDISK*<span class="number">1024</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">mem_init(main_memory_start,memory_end);</span><br><span class="line">trap_init();</span><br><span class="line">blk_dev_init();</span><br><span class="line">chr_dev_init();</span><br><span class="line">tty_init();</span><br><span class="line">time_init();</span><br><span class="line">sched_init();</span><br><span class="line">buffer_init(buffer_memory_end);</span><br><span class="line">hd_init();</span><br><span class="line">floppy_init();</span><br><span class="line">sti();</span><br><span class="line">move_to_user_mode();</span><br><span class="line"><span class="keyword">if</span> (!fork()) &#123;<span class="comment">/* we count on this going ok */</span></span><br><span class="line">init();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *   NOTE!!   For any other task 'pause()' would mean we have to get a</span></span><br><span class="line"><span class="comment"> * signal to awaken, but task0 is the sole exception (see 'schedule()')</span></span><br><span class="line"><span class="comment"> * as task 0 gets activated at every idle moment (when no other tasks</span></span><br><span class="line"><span class="comment"> * can run). For task0 'pause()' just means we go check if some other</span></span><br><span class="line"><span class="comment"> * task can run, and if not we return here.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">for</span>(;;) pause();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">printf</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *fmt, ...)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">va_list args;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line">va_start(args, fmt);</span><br><span class="line">write(<span class="number">1</span>,printbuf,i=<span class="built_in">vsprintf</span>(printbuf, fmt, args));</span><br><span class="line">va_end(args);</span><br><span class="line"><span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> * argv_rc[] = &#123; <span class="string">"/bin/sh"</span>, <span class="literal">NULL</span> &#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> * envp_rc[] = &#123; <span class="string">"HOME=/"</span>, <span class="literal">NULL</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> * argv[] = &#123; <span class="string">"-/bin/sh"</span>,<span class="literal">NULL</span> &#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> * envp[] = &#123; <span class="string">"HOME=/usr/root"</span>, <span class="literal">NULL</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> pid,i;</span><br><span class="line"></span><br><span class="line">setup((<span class="keyword">void</span> *) &amp;drive_info);</span><br><span class="line">(<span class="keyword">void</span>) open(<span class="string">"/dev/tty0"</span>,O_RDWR,<span class="number">0</span>);</span><br><span class="line">(<span class="keyword">void</span>) dup(<span class="number">0</span>);</span><br><span class="line">(<span class="keyword">void</span>) dup(<span class="number">0</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"hello, i am wangzitai\n"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d buffers = %d bytes buffer space\n\r"</span>,NR_BUFFERS,</span><br><span class="line">NR_BUFFERS*BLOCK_SIZE);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Free mem: %d bytes\n\r"</span>,memory_end-main_memory_start);</span><br><span class="line"><span class="keyword">if</span> (!(pid=fork())) &#123;</span><br><span class="line">close(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (open(<span class="string">"/etc/rc"</span>,O_RDONLY,<span class="number">0</span>))</span><br><span class="line">_exit(<span class="number">1</span>);</span><br><span class="line">execve(<span class="string">"/bin/sh"</span>,argv_rc,envp_rc);</span><br><span class="line">_exit(<span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (pid&gt;<span class="number">0</span>)</span><br><span class="line"><span class="keyword">while</span> (pid != wait(&amp;i))</span><br><span class="line"><span class="comment">/* nothing */</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> ((pid=fork())&lt;<span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Fork failed in init\r\n"</span>);</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!pid) &#123;</span><br><span class="line">close(<span class="number">0</span>);close(<span class="number">1</span>);close(<span class="number">2</span>);</span><br><span class="line">setsid();</span><br><span class="line">(<span class="keyword">void</span>) open(<span class="string">"/dev/tty0"</span>,O_RDWR,<span class="number">0</span>);</span><br><span class="line">(<span class="keyword">void</span>) dup(<span class="number">0</span>);</span><br><span class="line">(<span class="keyword">void</span>) dup(<span class="number">0</span>);</span><br><span class="line">_exit(execve(<span class="string">"/bin/sh"</span>,argv,envp));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> (pid == wait(&amp;i))</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n\rchild %d died with code %04x\n\r"</span>,pid,i);</span><br><span class="line">sync();</span><br><span class="line">&#125;</span><br><span class="line">_exit(<span class="number">0</span>);<span class="comment">/* NOTE! _exit, not exit() */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;​        只有真正的研读linux源代码，才能对操作系统有直观具体的认识；只有真正的修改linux源代码，才能对操作系统的某些方面有
      
    
    </summary>
    
      <category term="操作系统" scheme="http://wang22ti.com/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
  </entry>
  
</feed>
